{"pages":[{"title":"文章分类","text":"1 1.1 1.2234","link":"/categories/index.html"}],"posts":[{"title":"6.S081-LAB1 Xv6 and Unix utilities","text":"Contents# Tools Preparation Boot xv6 Utilities sleep Optional:uptime pingpong primes find xargs TEST REFERENCES Tools Preparation# 我是在Mac OS上搭建了实验环境。 首先安装Mac的开发者套件：$ xcode-select -install再安装包管理工具Homebrew:$ /usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"若在此之前已经安装过上述，直接跳到这步，安装RISC-V编译工具链$ brew tap riscv/riscv$ brew install riscv-tools然后配置环境，将下述这一行添加到~/.bashrc配置文件当中:PATH=$PATH:/usr/local/opt/riscv-gnu-toolchain/bin最后安装模拟器QEMU:$ brew install qemu耐心等待即可。 上述步骤完成后，可以通过下述步骤检查实验环境是否搭建成功。$ riscv64-unknown-elf-gcc --versionriscv64-unknown-elf-gcc (GCC) 9.2.0$ qemu-system-riscv64 --versionQEMU emulator version 4.1.0安装无错的话应当能够编译并运行xv6:# int the xv6 directory$ make qemu# ... lots of output ...init: starting sh$ Boot xv6# 克隆xv6的源码仓库至本地:$ git clone git://github.com/mit-pdos/xv6-riscv-fall19.git$ cd xv6-riscv-fall19切换到util分支:$ git checkout util已经编写好了Makefile，可以直接编译:$ make运行xv6:$ make qemu Utilities# sleep# Implement the UNIX program sleep for xv6, your sleep should pause for a user-specified number of ticks(A tick is a notion of time defined by the xv6 kernel, namely the time between two interrupts from the timer chip). Your solution should be in the file user/sleep.c. 1234567891011121314151617#include \"kernel/types.h\"#include \"user/user.h\"intmain(int argc, char *argv[]){ if(argc < 2){ fprintf(2, \"Usage:sleep number\\n\"); exit(); } if(sleep(atoi(argv[1])) < 0){ fprintf(2, \"failed to sleep %s ticks.\\n\", argv[1]); exit(); } exit();} Optional:uptime# Write an uptime program that prints the uptime in terms of ticks using the uptime system call. 1234567891011#include \"kernel/types.h\"#include \"user/user.h\"intmain(int argc, char *argv[]){ uint64 uptime_ticks; uptime_ticks = uptime(); printf(\"%d clock tick interrupts have occured since start.\\n\", uptime_ticks); exit();} pingpong# Write a program that uses UNIX system calls to “ping-pong” a byte between two processes over a pair of pipes, one for each direction. The parent sends by writing a byte to parent_fd[1] and the child receives it by reading from parent_fd[0]. After receiving a byte from parent, the child responds with its own byte by writing to chlid_fd[1], which the parent then reads. Your solution should be in the file user/pingpong.c. 了解Pipe是什么就不会有难度，注意文件描述符的关开。 12345678910111213141516171819202122232425262728293031323334353637383940414243#include \"kernel/types.h\"#include \"user/user.h\"intmain(int argc, char *argv[]){ int parent_fd[2], child_fd[2]; int pid; char buf[2]; pipe(parent_fd); pipe(child_fd); if(fork() == 0){ // child process. close(parent_fd[1]); close(child_fd[0]); pid = getpid(); read(parent_fd[0], buf, 1); if(buf[0] == 'i'){ printf(\"%d: received ping\\n\", pid); } write(child_fd[1], \"o\", 1); close(parent_fd[0]); close(child_fd[1]); }else{ // parent process. close(parent_fd[0]); close(child_fd[1]); pid = getpid(); write(parent_fd[1], \"i\", 1); read(child_fd[0], buf, 1); if(buf[0] == 'o'){ printf(\"%d: received pong\\n\", pid); } close(parent_fd[1]); close(child_fd[0]); } exit();} primes# Write a concurrent version of prime sieve using pipes. This idea is due to Doug Mcllroy, inventor of Unix pipe. The picture halfway down this page and the surrounding text explain how to do it. Your solution should be in the file user/primes.c. 需要认真阅读链接给的小论文Bell Labs and CSP Threads，文中所提到的例子，基于著名的埃式素数筛选算法，做过算法的肯定都知道这个，有趣的是，文中的模型通过Pipe与多进程实现了一个素数筛子，给了一张图，简单明了： 伪代码表示即为： 123456p = get a number from left neighborprint ploop: n = get a number from left neighbor if (p does not divide n) send n to right neighbor 我的第一版本实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#include \"kernel/types.h\"#include \"user/user.h\"static int pipeline_root[2];voidutil(int* p, int* k){ p[0] = k[0]; p[1] = k[1];}voidsieve(){ int n, k; int pipeline_left[2], pipeline_right[2]; util(pipeline_right, pipeline_root);loop: util(pipeline_left, pipeline_right); close(pipeline_left[1]); if((read(pipeline_left[0], &n, sizeof(int))) 0){ if(k % n){ write(pipeline_right[1], &k, sizeof(int)); } } close(pipeline_left[0]); close(pipeline_right[1]); wait(); exit();}intmain(int argc, char *argv[]){ int i; pipe(pipeline_root); if(fork() == 0){ sieve(); }else{ // parent root process feeding numbers. close(pipeline_root[0]); for(i = 2; i","link":"/2020/07/04/6-S081-LAB1-Xv6-and-Unix-utilities/"},{"title":"About me and the blog","text":"Welcome~(｡•ᴗ-)_#关于我# 电子科技大学学生 主要从事Java后端、Python数据挖掘与分析 热爱编程、骑行、刷剧、看电影、喝奶茶，业余时间也喜欢学习与深度学习相关的知识 关于该博客# 基于hexo与icarus构建 Hexo：A fast,simple and powerful frameworkIcarus：A simple, delicate, and modern theme for the static site generator Hexo 记录学习笔记与总结，骑行经历 Tips# 如果你在浏览博文中有任何疑问，欢迎与我交流，或者留言给我 如果你也想构建自己的技术博客，但是在对照官方文档给出的构建方式进行构建时产生任何bug或者疑问，也可以留言给我 如果你也曾和我一样，是一个计算机小白，想入行cs，却苦于不知该如何入手，也欢迎向我提问~","link":"/2019/09/30/About-me-and-the-blog/"},{"title":"HashMap+ConcurrentHashMap+同步HashMap","text":"文章目录:# 一、概述 二、Hash算法概述 三、红黑树原理 四、HashMap源码分析 内部Node结点 putVal方法 获取散列桶索引值的方法 整个put方法流程图 为什么自己定义的类作为键值需要重写hashCode()以及equals()方法？ get方法 resize方法 计算新的散列表容量以及实际能容纳的键值对的数量的阈值 对一个给定值p，如何计算相应的小于P的2的幂的最大值？如何计算大于p的2的幂的最小值？ 需要改变位置的键值对放置到散列桶中 五、同步容器SynchronizedMap 六、使用了“魔法”的并发容器ConcurrentHashMap “黑魔法”sun.misc.Unsafe Volatile table element access 多线程环境下初始化散列表initTable() putVal helpTransfer[to do] addCount[to do] 参考资料 一、概述# 二、Hash表概念回顾# 【1】哈希表：根据设定的哈希函数H(key)和处理冲突的方法将一组关键字映像到一个有限的连续的地址集（区间）上，并以关键字在地址集中的“像”作为记录在表中的存储位置，这种表便称为哈希表，这一映像过程称为哈希造表或散列，所得存储位置称为哈希地址或散列地址。 常见的几种哈希函数的构造方法： 直接定址法：取关键字或关键字的某个线性函数值为哈希地址。即： *H(key)=key或H(key)=a·key+b* 数字分析法：假设关键字是以r为基的数，并且哈希表中可能出现的关键字都是事先知道的，则可取关键字的若干数位组成哈希地址。 平方取中法：取关键字平方后的中间几位为哈希地址。 折叠法：将关键字分割成位数相同的几部分，然后取这几部分的叠加和作为哈希地址。 除留取余法：取关键字被某个不大于哈希表表长m的数p除后所得余数为哈希地址，通常取素数，因为使用素数会降低发生哈希冲突的概率。即： *H(key)=key MOD p,p 随机数法：选择一个随机函数，取关键字的随机函数值作为它的哈希地址，即: *H(key)=random(key),random为随机函数* 处理冲突的方法： 开放定址法： *H'=(H(key)+d) MOD m* 再哈希法： *H=RH(key)* 链地址法：将所有关键字为同义词的记录存储在同一线性链表中。假设某哈希函数产生的哈希地址在区间[0,m-1]上，则设立一个指针型向量： *Chain ChainHash[m]* 其每个分量的初始状态都为空指针，凡哈希地址为i的记录都插入到头指针为`ChainHash[i]`的链表中。 # 三、红黑树原理 ## 红黑树概念及性质 >【2】红黑树：红黑树是一颗每个节点都带有颜色属性的二叉查找树，在每个节点的属性除了1个key和3个指针：parent,lchild,rchild之外，还具有额外的color属性，要求每个节点为红色或黑色。在二叉查找树的一般要求之外，同时增加了如下的额外定义： >1. 节点是红色或黑色。 >2. 根节点是黑色。 >3. 每个叶节点（NIL节点，空结点）是黑色的。 >4. 每个红色节点的两个子节点都是黑色（从每个叶子到根的所有路径上不能有两个连续的红色节点）。 >5. **从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。** 红黑树是近似平衡的二叉查找树（不同于平衡二叉树的完美平衡），同样，相较于平衡二叉树使用四种旋转操作来实现完美平衡，红黑树通过左旋、右旋以及节点的变色来满足红黑树的性质，实现近似平衡。其中，左旋以及右旋操作与平衡二叉树完全一致。不同的点在于，红黑树还需要对颜色进行变换。其次，红黑树在我的理解当中可以看作2-3树的变形，设计红黑树的作者使用颜色巧妙地改造了2-3树，从而使得2-3树能够通过二叉树的方式进行算法设计， 其实自己一开始写了一版自己的，但是后来我搜索了红黑树，找到了一些博客，发现自己写的那一版就是shit，因此这里推荐阅读它们的，更好懂，更形象： 30张图带你彻底理解红黑树 四、HashMap源码分析#内部Node结点#这一部分没有什么注意的点，就是简单的链表的形式。 putVal方法#put方法会调用内部的putval方法，putval方法的方法签名为：final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict)可以看到在调用内部putVal方法时，已经通过hash(key)计算出了键的hash值： 12345678public V put(K key, V value) { return putVal(hash(key), key, value, false, true);}static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);} 该哈希算法调用键的hashCode()方法得到初步hash值并且将高16位与低16位进行异或得到最终的hash值，为什么要这么做？不能够直接使用键本身的hash值吗？在JDK8中的源码注释是这样解释的： 【注3】Because the table uses power-of-two masking, sets of hashes that vary only in bits above the current mask will always collide. (Among known examples are sets of Float keys holding consecutive whole numbers in small tables.) So we apply a transform that spreads the impact of higher bits downward. 解释得很清楚，由于hashMap散列桶的个数总是2的幂，并且hashMap使用其作为掩码实现快速除留取余的求散列桶索引的算法（在Hash算法概述当中，提到了通常使用素数作为散列桶的个数，而这里使用2的幂的原因稍后会给出答案），因此，对于那些哈希值的二进制1分布在掩码以上的位的时候，那么就必然会发生冲突，在很极端的条件下，假设此刻hashMap散列桶的数量为16，此时插入12个键的hash值都为16的倍数的不同键值对，若直接使用该hash值除留取余，那么该12个键值对都会发生冲突。对上面引用的JDK源码注释给出的例子的解释:并且，在注释中给出了一个更有说服力的例子，那就是使用浮点数作为键，但是浮点数都用来存储整数（误，这里说法不太对，大概是那么个意思），不如回想浮点数在计算中的编码方式，通常都是遵循IEEE754标准：因此，若散列表大小较小，那么基本上大多数浮点数键都会发生冲突，导致大量的键值对堆积在一个散列桶中，严重影响查找性能。但是通过让高位与低位异或产生hash值就能显著消除这种现象的发生，换而言之，这个操作就是为了使hash值分布更均匀，减少哈希冲突的产生从而提高查找性能。 获取散列桶索引值的方法:在上面也提到了，得到键的hash值之后还要通过除留取余法得到该键值对对应的散列桶索引，JDK8使用的方式是： `(n-1) & hash`其中n为散列表大小，在hashMap中始终为2的幂，为什么要求是2的幂，其实就是为了更快速地除留取余（相较于除法使用多个寄存器以及多条指令，这种方式仅仅需要一条指令，仅消耗一个指令周期的时间），其次，也方便后续hashMap的扩容`resize()`。 整个put方法流程图：在上述图中有两处注释点（并非参考资料注释）： 注1：此处与源码略有差异，这里简化了流程； 注2：此处阈值指的是将链表转换为红黑树的阈值，默认为8； 注3：此处阈值指的是散列表大小*装载因子。比如初始散列表大小为16，装载因子为0.75，则该阈值为12； 为什么自己定义的类作为键值需要重写hashCode()以及equals()方法？：因为hashMap使用键的hashCode方法获取hash值以计算散列桶索引，而当散列桶索引发生冲突的时候将比较键对象内存地址或者调用equals方法来判断是否是同一个键值： 123if (p.hash == hash && ((k = p.key) == key || (key != null && key.equals(k)))){ e = p;} get方法#逻辑很简单，可见有时候重写hashCode()方法和equals()方法有多么重要： 123456789101112131415161718192021 final Node getNode(int hash, Object key) { Node[] tab; Node first, e; int n; K k; if ((tab = table) != null && (n = tab.length) > 0 && (first = tab[(n - 1) & hash]) != null) {// 检查第一个结点是否就是要查找的结点，同样比较内存地址或者调用equals方法 if (first.hash == hash && // always check first node ((k = first.key) == key || (key != null && key.equals(k)))) return first; if ((e = first.next) != null) { // 若是树结点，则调用红黑树的查找方法 if (first instanceof TreeNode) return ((TreeNode)first).getTreeNode(hash, key); // 否则就逐个比较链表上的结点是否是要找的结点 do { if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k)))) return e; } while ((e = e.next) != null); } } return null; } resize方法#当达到散列表阈值之后需要对散列表进行扩容，这部分代码很长，因此将其分为两部分： 计算新的散列表容量以及实际能容纳的键值对的数量的阈值； 需要改变位置的键值对放置到散列桶中； 1.计算新的散列表容量以及实际能容纳的键值对的数量的阈值：这部分代码如下： 12345678910111213141516171819202122232425262728293031 final Node[] resize() { Node[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; // 【1】 if (oldCap > 0) { if (oldCap >= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } else if ((newCap = oldCap = DEFAULT_INITIAL_CAPACITY) newThr = oldThr 0) // initial capacity was placed in threshold newCap = oldThr; 【3】 else { // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; ......} 关于上面这段代码，三种情况： [1]：调用resize时，hashMap中有键值对映射，并且已经达到当前容量的阈值。并且，若此时散列表的容量已达到MAXIMUM_CAPACITY(2^30)，那么此时已经无法在扩容，只能无视装载因子的设定，将阈值提升至Integer.MAX_VALUE。否则，就将容量与阈值都增加到原来的两倍。 [2]：此时是指定了容量的HashMap的初始化(e.g:new HashMap(20))，也就是此时散列表还为null，但是前面提到了，HashMap要求散列表的容量必须为2的幂，那么这里指定20为初始容量应该报错才对，其实不然，在HashMap中会调用tableSizeFor(int cap)方法计算大于20的最小的2的幂，该函数引用了《Hackers Delight》中的一个算法来计算最接近你所给定的值的2的幂，后面会提到。 [3]：此时是未指定容量的HashMap的初始化(e.g:new HashMap())，于是会使用默认的初始容量16。 【注4】【注5】对一个给定值p，如何计算相应的小于P的2的幂的最大值？如何计算大于p的2的幂的最小值？在此之前不妨考虑这样一个问题：对任意一个数n=2^k(k=1,2,3…)，其二进制形式都会是这样的：000…010000..000(其中1后面有k个0),如何快速将1后面的0全部变为1？不妨可以这样考虑：若你之前不太明白HashMap中采用的算法的话，看到上面这个图，你也必然已经恍然大悟了。将上面的算法推广到一般情况，给定任意一个数，上面的算法显然也是适用的，因为该算法依靠的是最高位的1，无论后面数位是1还是0，进行⌈log2(k)⌉次运算之后，必然已经将最高位之后的位全部变为1了。 下面我们再来看HashMap中的算法，源码如下： 123456789static final int tableSizeFor(int cap) { int n = cap - 1; n |= n >>> 1; n |= n >>> 2; n |= n >>> 4; n |= n >>> 8; n |= n >>> 16; return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;} 这时候再看这个算法是不是就已经很简单了，但是还有部分细节： 为什么开始要减一？若cap本身就是2的幂，那么若直接移位运算，将最高位后面的0全部变为1，最后再加1，得到的结果将是2倍cap，这显然不对，应该就是cap才对，那么减去1就能完美解决这个问题。 为什么进行了5次无符号右移并异或的运算？很简单，HashMap将散列表的最大容量限定为2^30次方，那么最多只需要⌈log2(30)⌉=5次就能完成目标了。 为什么最后要加1？额…如果你有这样的疑惑，说明你还没看懂。 到这里，对于上面“对一个给定值p，如何计算相应的小于P的2的幂的最大值？如何计算大于p的2的幂的最小值？”的问题就完美解决啦~ 2. 需要改变位置的键值对放置到散列桶中。 这部分代码如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849...... if (oldTab != null) { for (int j = 0; j < oldCap; ++j) { Node e; if ((e = oldTab[j]) != null) { // 消除旧散列表的对结点的引用 oldTab[j] = null; 【1】 if (e.next == null) newTab[e.hash & (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode)e).split(this, newTab, j, oldCap); else { // preserve order Node loHead = null, loTail = null; Node hiHead = null, hiTail = null; Node next; 【2】 do { next = e.next; if ((e.hash & oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); 【3】 if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; } 上面这部分代码值得注意得就是3个点： [1]：该散列桶中只有一个键值对，则根据新的散列表容量直接重新计算相应的散列索引并放入即可； [2]：这部分将该散列桶中链表的每个结点划分为两类，一类是loHead(lowerHead)，这部分在扩容后的散列表中散列索引不变，另一类是hiHead(HigherHead)，这部分在扩容后的散列表中散列索引发生了变化)； [3]：结束了划分之后，就将两个链表各自放在新散列表中的相应位置。 对第[2]部分的详细解释：e.hash & oldCap 做了什么？对第[3]部分的详细解释：明白了第[2]部分在做什么，第三部分其实就是把loHead放入索引相同的位置，把hiHead放入新的索引（因为hiHead连接的结点键的hash值都是扩容后增加的那一位为1的结点） 五、同步HashMap#同步容器基本上就是对线程不安全的容器进行了再次封装，【注6】这种技术通常可认为是实例封闭机制(Instance Confinement)。Collections类提供了包装器工厂方法，以HashMap的工厂方法为例：Collections.synchronizedMap(new HashMap())，看到这样的形式就基本上能猜测，这里应用了装饰器设计模式的思想，(注：浅谈装饰器设计模式)事实也的确是这样，在Collections类中有一个内部类SynchronizedMap，该内部类就是Collections为我们提供的装饰器类，它与HashMap暴露相同的接口，并且对该装饰器接口的调用最终会委派到内部你所传入的Map的相同接口上。 1234// 工厂方法返回被装饰的对象public static Map synchronizedMap(Map m) { return new SynchronizedMap(m);} 而同步容器在并发的场景下能保证线程安全，但是吞吐量也是很低，因为其内部仅使用了一把锁，并且使用了重量级锁：Java对象监视器（Monitor）,在同一时刻仅仅允许一个线程对同步容器进行操作，无论是读操作，还是写操作： 1final Object mutex; // Object on which to synchronize 专门使用一个Object作为互斥锁，非常重量级、大范围、粗粒度地加锁： 123public V put(K key, V value) { synchronized (mutex) {return m.put(key, value);}} 六、使用了“魔法”的ConcurrentHashMap#首先，声明！在ConcurrentHashMap中有许多与HashMap相同的原理就不再赘述！同步容器在并发环境下仅仅能保证线程安全，但是性能非常差，实际上，即便是小白都能对同步容器的性能进行优化，而并发包中的ConcurrentHashMap在保证线程安全性上采用了CAS+synchronized的组合，并且降低锁的粒度与范围，从而提高ConcurrentHashMap在并发环境下的吞吐量，提高性能。 “黑魔法”sun.misc.Unsafe#关于Unsafe类，建议阅读： 【基本功】Java魔法类：Unsafe应用解析 Java Magic. Part 4: sun.misc.Unsafe 关于CAS(Compare and set),建议阅读： 《现代操作系统》，机械工业出版社； 《深入理解Java虚拟机-JVM高级特性与最佳实践》第二版，机械工业出版社。第13章，线程安全与锁优化的非阻塞同步，或者说乐观锁。 简而言之，CAS是一种非阻塞同步方式，也可以看作是乐观锁。【注7】CAS指令需要3个操作数，分别是内存位置（V）、旧的预期值（A）和新值（B），CAS指令执行时，当且仅当V符合旧预期值A时，处理器用新值B更新V的值，否则它就不执行更新，并且由于其通常依赖于与平台相关的处理器CAS指令（例如XCHG），因此虽然没有使用锁，但由于其具有原子性，不可被中断，就对CAS方法本身来说，是线程安全的。（注：关于CAS，这里有个小插曲，见：） Volatile table element access#由ConcurrentHashMap提供的散列表元素访问函数，保证多处理器环境下的内存可见性与原子性。以casTabAt方法为例（其它方法都是相同的原理）： 123456private static final sun.misc.Unsafe U;// 直接将该Node放置在散列表的索引i处static final boolean casTabAt(Node[] tab, int i, Node c, Node v) { return U.compareAndSwapObject(tab, ((long)i","link":"/2019/12/05/HashMap-ConcurrentHashMap-同步HashMap/"},{"title":"Java I/O结合装饰器设计模式的一点理解","text":"@[TOC](Java I/O库结合装饰器设计模式的一点理解) 一、概述#关于I/O库使用的设计模式-装饰器模式# 《Thinking in Java》: 装饰器模式使用分层对象来动态透明地向单个对象中添加责任。装饰器指定包装在最初地对象周围地所有对象都具有相同的基本接口。某些事物是可装饰的，可以通过将其它类包装在这个可装饰对象的四周，从而将功能分层，这使得对装饰器的使用是透明的——无论对象是否被装饰，你都拥有一个可以向对象发送的公共消息集。 Java I/O库实际是很多功能的组合，所以使用装饰器设计模式。至于装饰器设计模式，在我的另外一篇笔记中也进行了学习，这里就不再赘述。 装饰器模式在I/O库中的实际应用#就以字节输入流系列为例:InputStream是一个抽象类，在装饰器设计模式当中，充当了抽象构件的角色，它为所有被修饰的对象提供通用接口，通过查看源码也能知道这点。 FilterInputStream继承自InputStream，充当装饰角色(Decorator)，该类应当持有一个构件角色对象的实例，在FilterInputStream中含有一个输入流对象的保护成员： 1protected volatile InputStream in; 通过给构造方法传递InputStream子类对象的引用就可以初始化该保护成员，该保护成员其实就是JDK文档中I/O部分提到的underlying stream，详细可自己查看JDK文档。 FilterInputStream只有一个子类BufferedInputStream，其充当了具体装饰角色(Concrete Decorator)，给具体构件提供额外的功能（如我们所知，BufferedInputStream给输入流提供了缓冲功能，减少了I/O次数)。 FileInputStream等则充当的是具体构件角色，可以把具体构件角色的对象传递给具体装饰器角色，如之前所示，其内部的保护成员in会被初始化，指向该具体构件角色的对象。典型的： 1BufferedInputStream bis = new BufferedInputStream(new FileInputStream(file)); BufferedInputStream实现原理简述#通过上面的分析我们知道BufferedInputStream实际就是一个装饰器，它为输入流提供了缓冲功能，实际上就是内置了一个字节数组buf，默认大小是8192，大小也可以自己指定，除此之外，在BufferedInputStream中还提供了其它一些比较关键的保护成员（指的是对于缓冲功能实现相对比较重要）： 1234567891011121314151617181920protected volatile byte buf[]; /** * The index one greater than the index of the last valid byte in * the buffer.This value is always in the range 0 through buf.length; * elements buf[0] through buf[count-1] contain buffered input data obtained from the underlying * input stream. */protected int count;/** * The current position in the buffer. This is the index of the next * character to be read from the buf array. * This value is always in the range 0 through count. If it is less * than count, then buf[pos] is the next byte to be supplied as input; * if it is equal to count, then the next read or skip operation will require * more bytes to be read from the contained input stream. */protected int pos;protected int markpos = -1;protected int marklimit; 其中两个比较关键的字段count和pos已经给出了注释，注释来源于JDK源代码的注释，count和pos其实就是两个指针，count指向buf中最后一个有效字节之后的那个位置，而pos指向buf中下一个要读取的位置（即pos处还未被读取)。 buf缓冲数组中的数据则来源于underlying stream即之前被初始化的in，在BufferedInputStream中还增加了一个私有函数fill()，该函数实际上就是完成了从输入流到缓冲数组的数据的读取，其功能依赖于count,pos,mark等指针，每当pos>=count(这说明buf中的有效数据已经读取完毕)就会调用fill()方法，往buf数组中填充数据，若buf中除了有效数据还有位置，则会紧接着有效位置填充来自于in的数据。 那么为什么BufferedInputStream能够有效减少I/O次数，从而提高性能呢？因为buf数组的存在，每一次其内部的输入流in调用read()方法，实际上都会读写很多个字节的数据，并且将其缓冲在buf数组当中，因此当调用BufferedInputStream的read方法时实际上就是从buf数组中读数据，但是如果我们直接使用输入流的read方法，那么每一次读取都要付出昂贵的磁盘IO的代价。因此，显然，从内存中读数据要比从磁盘上读数据快得多（通常每次读取可能会少上数十或者上百个时钟周期）。 I/O库流的分类#可以划分为字符流和字节流。字符流包括Reader，Writer及其子类，字节流包括InputStream，OutputStream及其子类，一般读取文本文件可以用字符流，图像等其它文件则可以使用字节流。 二、简单使用方式#字符流#控制台输入#1BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); 因为System.in是InputStream类型，而BufferedReader需要接受Reader类型，因此需要InputStreamReader来进行字节流与字符流之间的转换，实际上InputStreamReader内置了一个解码器(Decoder)，因此可以指定字符集来对字节流进行解码。 读取文本文件#12345678910public class Main { public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new FileReader(\"test.txt\")); int c; while ((c = br.read()) != -1) { System.out.print((char) c); } br.close(); }} 因为close()方法声明抛出了IOException异常，必须对其处理，这里选择继续向上层调用栈抛出。 向文件写入文本#1234567public class Main { public static void main(String[] args) throws IOException { BufferedWriter bw = new BufferedWriter(new FileWriter(\"write_in.txt\")); bw.write(\"感谢您看我的博客文章！\"); bw.close(); }} 字节流#复制文件#12345678910111213public class Main { public static void main(String[] args) throws IOException { BufferedInputStream bis = new BufferedInputStream(new FileInputStream(\"test.jpg\")); BufferedOutputStream bos= new BufferedOutputStream(new FileOutputStream(\"test_copy4.jpg\")); byte[] bytes=new byte[1024]; int len; // 读取的有效字节数 while((len=bis.read(bytes))!=-1){ bos.write(bytes,0,len); // 将有效字节续写在文件后 } bos.close(); bis.close(); }}","link":"/2019/10/11/Java-I-O结合装饰器设计模式的一点理解/"},{"title":"MIT-6.828-LAB1 Booting a PC","text":"文章目录# Part 1:PC Bootstrap Exercise 2 Key point My answer for exercise 2 Part 2:The Boot Loader Exercise 3 Key point My answer for exercise 3 Exercise 4,5,6 Key point My answer for exercise 4 My answer for exercise 5 My answer for exercise 6 Part 3：The Kernel Exercise 7 Key point My answer for exercise 7 Exercise 8 My answer for exercise 8 GDB debugging process for exercise 8.3 Exercise 9 My answer for exercise 9 Exercise 10 Key point My answer for exercise 10 Exercise 11,12 My answer for exercise 11,12 参考资料 Part 1:PC Bootstrap# Exercise 2#Key point# When the BIOS runs, it sets up an interrupt descriptor table and initializes various devices such as the VGA display. This is where the “Starting SeaBIOS” message you see in the QEMU window comes from.After initializing the PCI bus and all the important devices the BIOS knows about, it searches for a bootable device such as a floppy, hard drive, or CD-ROM. Eventually, when it finds a bootable disk, the BIOS reads the boot loader from the disk and transfers control to it. 什么是实模式real mode?什么是保护模式protected mode？它们的区别是什么？根据MIT官方文档的指示，参阅其给出的pc-asm-book.pdf的1.2.6等： In real mode,a selector value is a paragragh number of physical memory.In protected mode,a selector value is an index into a descriptor table.In both modes, programs are divided into segments. In real mode, these segments are at fixed positions in physical memory and the selector value denotes the paragraph number of the beginning of the segment. In protected mode, the segments are not at fixed positions in physical memory. In fact, they do not have to be in memory at all!Protected mode uses a technique called virtual memory. My answer for exercise 2#注：下面会涉及到许多IO端口号，我查询了Wiki百科，找到I/O_PORTS，该页面简单介绍了各地址范围的I/O端口的作用，在其底部的外部链接中Boch’s map of I/O ports to functions中则是各I/O端口的详细说明，当然也可以参考Mit给的参考文档Phil Storrs I/O Ports Description,但是不太详细 12345cli # 屏蔽了所有中断cld # 操作方向标志位DF,使DF复位为0mov $0x8f,%eax # 0x8f 1000 1111out %al,$0x70 # 将%al中的一个字节写入0x70端口in $0x71,%al # 从IO端口0x71读取一个字节 该IO端口0x70是一个CMOS RAM/RTC(Real Time Clock),通过查询上面所说的页面可以发现，0x8f表明其禁止了NMI中断，并且选择了CMOS register number为0xf 123in 0x92,%al # 从0x92端口读取一个字节or $0x2,%al # 将上面读出的字节的第二位设置为1,激活A20地址线out %al,$0x92 # 将该字节重新写入0x92端口 查阅得知，0x92是PS/2 system control port A，并且激活A20地址线，关于A20，建议阅读Quora:What is the A20 gate in a CPU，通过该回答大致了解到A20是为了向后兼容8086等时仅有20条地址线的情况，并且在操作系统需要进入到protected mode时，A20 Gate应当被使能,但是值得注意的是此时仍然工作在实模式下。 12lidtw %cs:0x6ab8 # 加载IDT的24位基地址和16位限长值到IDTR寄存器lgdtw %cs:0x6a74 # 加载GDT的24位基地址和16位限长值到GDTR寄存器 因为是lidtw，随后这两行仍然是16bit操作数，参考x86-lidt and lgdt可知，若为16位操作数，那么lidt(lgdt)会将16位限长值与24位基地址加载到寄存器IDTR(GDTR),建议阅读百度百科：中断描述符表IDT以及Wiki:GDT,因此简单来说，这两行就是加载IDT和GDT。 123mov %cr0,%eaxor $0x1,%eax # 将%cr0寄存器中的值的最低位设置为1mov %eax,%cr0 # 处理器进入Protected mode 上面三行很显然是将%cr0寄存器中的值的最低位设置为1，参阅Wiki:Control register发现，这个操作就是使处理器进入Protected mode。 123456789ljmpl $0x8,$0xfd18f # 这里这样跳转是x86加载GDT之后的硬性规定mov $0x10,%eaxmov %eax,%ds # 设置段寄存器mov %eax,%es # ~mov %eax,%ss # ~mov %eax,%fs # ~mov %eax,%gs # ~mov %ecx,%eaxjmp *%edx # 间接跳转 同样参阅Wiki:GDT，能了解到，加载了GDT之后，必须通过长跳转（far jump)来重新加载段寄存器，也就是DS,ES,SS,FS,GS。 从jmp *%edx开始，后面的汇编代码就是很类似于C语言编译后的汇编代码，并且后续汇编代码极其之长，但是通过si单步调试，发现基本都是很类似的结构，例如我把后续汇编代码截取了一部分，会发现二者很相似。 123456789101112131415161718192021222324252627282930313233=> 0xf34c2: push %ebx=> 0xf34c3: sub $0x2c,%esp=> 0xf34c6: movl $0xf5b5c,0x4(%esp)=> 0xf34ce: movl $0xf447b,(%esp)=> 0xf34d5: call 0xf099e=> 0xf099e: lea 0x8(%esp),%ecx=> 0xf09a2: mov 0x4(%esp),%edx=> 0xf09a6: mov $0xf5b58,%eax=> 0xf09ab: call 0xf0574=> 0xf0574: push %ebp => 0xf0575: push %edi=> 0xf0576: push %esi=> 0xf0577: push %ebx => 0xf0578: sub $0xc,%esp=> 0xf057b: mov %eax,0x4(%esp)=> 0xf057f: mov %edx,%ebp=> 0xf0581: mov %ecx,%esi => 0xf0583: movsbl 0x0(%ebp),%edx # 这里开始到ret都是重复代码=> 0xf0587: test %dl,%dl => 0xf0589: je 0xf0758=> 0xf058f: cmp $0x25,%dl=> 0xf0592: jne 0xf0741=> 0xf0741: mov 0x4(%esp),%eax=> 0xf0745: call 0xefc70=> 0xefc70: mov %eax,%ecx=> 0xefc72: movsbl %dl,%edx => 0xefc75: call *(%ecx) => 0xefc65: mov %edx,%eax=> 0xefc67: mov 0xf693c,%dx=> 0xefc6e: out %al,(%dx) # 向0x402端口写入一字节(0x53)=> 0xefc6f: ret => 0xefc77: ret 上面这段汇编代码在ret尚未执行时的完整栈结构如下所示： 至于为什么我会画出栈？因为我想尝试读懂，结果发现是我想多了。为什么栈是从0x7000地址处开始？因为在整个汇编代码的起始处，%esp寄存器就被赋值为0x7000。 1234567891011121314151617181920=> 0xf074a: mov %ebp,%ebx=> 0xf074c: jmp 0xf0750=> 0xf0750: lea 0x1(%ebx),%ebp => 0xf0753: jmp 0xf0583=> 0xf0583: movsbl 0x0(%ebp),%edx # 这里开始是重复代码=> 0xf0587: test %dl,%dl => 0xf0589: je 0xf0758=> 0xf058f: cmp $0x25,%dl=> 0xf0592: jne 0xf0741=> 0xf0741: mov 0x4(%esp),%eax=> 0xf0745: call 0xefc70 => 0xefc70: mov %eax,%ecx) => 0xefc72: movsbl %dl,%edx => 0xefc75: call *(%ecx)=> 0xefc65: mov %edx,%eax => 0xefc67: mov 0xf693c,%dx=> 0xefc6e: out %al,(%dx) # 向向0x402端口写入一字节(0x65)=> 0xefc6f: ret => 0xefc77: ret 可以看到随后一段汇编代码，出现了大量的重复，并且最后也是向0x402端口（注：这里out %al,(%dx)的语法我并不是很了解，但是通过输出寄存器的值，此时%dx当中的确都是0x402。后面有大量的代码都会重复这一段，但是我能力有限，无法知道这一段的具体含义，但是根据MIT在这部分的描述： When the BIOS runs, it sets up an interrupt descriptor table and initializes various devices such as the VGA display. 我只能够猜测这一段就是初始化各种BIOS已知的设备。 Part 2:The Boot Loader# Exercise 3#Key point# When the BIOS finds a bootable floppy or hard disk, it loads the 512-byte boot sector into memory at physical addresses 0x7c00 through 0x7dff, and then uses a jmp instruction to set the CS:IP to 0000:7c00, passing control to the boot loader.(注：0x7c00-0x7dff为512字节，也就是说BIOS将Boot sector加载到0x7c00为起始地址的连续512个字节，并且随后跳转到0x7c00去执行Boot Sector中的代码) Like the BIOS load address, these addresses are fairly arbitrary - but they are fixed and standardized for PCs.The boot loader consists of one assembly language source file, boot/boot.S, and one C source file, boot/main.cThe boot loader must perform two main functions: the boot loader switches the processor from real mode to 32-bit protected mode, because it is only in this mode that software can access all the memory above 1MB in the processor’s physical address space. the boot loader reads the kernel from the hard disk by directly accessing the IDE disk device registers via the x86’s special I/O instructions. My answer for exercise 3#在这部分当中给出了四个问题需要回答： At what point does the processor start executing 32-bit code? What exactly causes the switch from 16- to 32-bit mode? What is the last instruction of the boot loader executed, and what is the first instruction of the kernel it just loaded? Where is the first instruction of the kernel? How does the boot loader decide how many sectors it must read in order to fetch the entire kernel from disk? Where does it find this information? 通过对Part A的汇编代码的仔细研读，再理解boot/boot.S这个文件也就不难了，并且代码中还给了注释，只有一个注意的点： 12345678910111213141516171819 # Enable A20: # For backwards compatibility with the earliest PCs, physical # address line 20 is tied low, so that addresses higher than # 1MB wrap around to zero by default. This code undoes this.seta20.1: inb $0x64,%al # Wait for not busy testb $0x2,%al jnz seta20.1 movb $0xd1,%al # 0xd1 -> port 0x64 outb %al,$0x64seta20.2: inb $0x64,%al # Wait for not busy testb $0x2,%al jnz seta20.2 movb $0xdf,%al # 0xdf -> port 0x60 outb %al,$0x60 这一段，直接看注释就能知道它的作用是使能A20 Gate，为切换到保护模式做准备，查询端口表，0x64号端口的bit 1位置的含义是： 0064: KB controller read status (ISA, EISA)bit 1 = 1 input buffer full (input 60/64 has data for 8042) 再查向0x64端口写入0xd1和0xdf有什么作用： D1 dbl: write output port. next byte written to 0060will be written to the 804x output port; the original IBM AT and many compatibles use bit 1 of the output port to control the A20 gate.DF sngl enable address line A20 (HP Vectra only???) 由此，上面这段代码就是检测input buffer直到其空闲，然后使能A20 Gate。 通过该文件，能够回答第一个问题： 123456789101112# Switch from real to protected mode, using a bootstrap GDT# and segment translation that makes virtual addresses# identical to their physical addresses, so that the# effective memory map does not change during the switch.lgdt gdtdescmovl %cr0, %eaxorl $CR0_PE_ON, %eaxmovl %eax, %cr0# Jump to next instruction, but in 32-bit code segment.# Switches processor into 32-bit mode.ljmp $PROT_MODE_CSEG, $protcseg 从ljmp $PROT_MDOE_CSEG, $protcseg开始，由于设置了%cr0控制寄存器，使得处理器从实模式切换为保护模式，开始执行32-bit code。 随后，进入bootmain()，我们来深究一下bootmain这个函数： 1readseg((uint32_t) ELFHDR, SECTSIZE*8, 0); 首先，从第一个扇区(sector)读取ELF中的Program Header，（此处建议参考由Mit推荐的参考页面Wiki:Executable and Linkable Format），读取SECTSIZE * 8个字节的数据，并且将其加载到物理内存地址0x10000，为什么是0x10000，在注释的解释是scratch space，直译的话不知道是什么鬼，google translate给的翻译是“暂存空间”，这样就合理多了。 1234567// is this a valid ELF?if (ELFHDR->e_magic != ELF_MAGIC) goto bad;// load each program segment (ignores ph flags)ph = (struct Proghdr *) ((uint8_t *) ELFHDR + ELFHDR->e_phoff);eph = ph + ELFHDR->e_phnum; 随后校验所读取的ELF是否有效，有效则计算Program Header的起始地址，以及结束地址，以便后续遍历Program Header并且将每一段（segment)加载到内存当中，因此下面这段代码就是这样的功能,将ph->p_offset出开始的ph->p_memsz个字节读取到以ph->p_pa为起始地址的物理内存地址上： 1234for (; ph < eph; ph++) // p_pa is the load address of this segment (as well // as the physical address) readseg(ph->p_pa, ph->p_memsz, ph->p_offset); 然后我们进入readseg，来看看它是如何做到将扇区的内容加载到内存中的： 1234uint32_t end_pa;end_pa = pa + count;// round down to sector boundarypa &= ~(SECTSIZE - 1); 首先，计算物理内存地址的结束地址（这里实际上是结束地址的下一个地址）,并且将物理内存地址的起始地址向下舍入到sector boundary(若SECTSIZE是512，其实也就等价于pa & 0xffffffe0,那它为什么要这么写，因为这么写有强大的兼容性啊，无论是对32位机器还是64位机器都是适用的。 1offset = (offset / SECTSIZE) + 1; 然后将需要读取的字节数，转换为扇区编号。 123456789while (pa < end_pa) { // Since we haven't enabled paging yet and we're using // an identity segment mapping (see boot.S), we can // use physical addresses directly. This won't be the // case once JOS enables the MMU. readsect((uint8_t*) pa, offset); pa += SECTSIZE; offset++;} 遍历加载每个扇区的内容，注意这里的注释，在此时，页表机制还没加载，因此，这里不是使用虚拟内存，而是直接的物理内存地址。其次，这里出现了readsect函数，该函数是Exercise 3要求必须完全弄懂的函数，下面就进入readsect来看看它到底做了什么： 123456789101112131415161718192021222324252627voidwaitdisk(void){ // wait for disk reaady while ((inb(0x1F7) & 0xC0) != 0x40) /* do nothing */;}void readsect(void *dst, uint32_t offset){ // wait for disk to be ready waitdisk(); outb(0x1F2, 1); // count = 1 outb(0x1F3, offset); outb(0x1F4, offset >> 8); outb(0x1F5, offset >> 16); outb(0x1F6, (offset >> 24) | 0xE0); outb(0x1F7, 0x20); // cmd 0x20 - read sectors // wait for disk to be ready waitdisk(); // read a sector insl(0x1F0, dst, SECTSIZE/4);} readsect和waitdisk直接与硬件交互，向设备端口写入数据，同样查询之前的端口表，这里用到的端口梳理如下： 因此，waitdisk中期待从0x1F7端口读出的一字节与0xC0相与的结果为0x40，也就是drive is ready，等待硬盘准备完毕。后续outb(0x1F2, 1);选择需要读取的扇区数量为1，outb(0x1F3, offset);选择扇区编号，向0x1F4,0x1F5,0x1F6写入的数据应该是操作disk选择相应的柱面、磁道等，然后outb(0x1F7, 0x20);读取扇区数据，随后等待磁盘准备完毕，再从磁盘数据读取到指定的物理内存地址dst。 12345678910111213static inline voidinsl(int port, void *addr, int cnt){ asm volatile(\"cld\\n\\trepne\\n\\tinsl\" 7cc9: 8b 7d 08 mov 0x8(%ebp),%edi 7ccc: b9 80 00 00 00 mov $0x80,%ecx 7cd1: ba f0 01 00 00 mov $0x1f0,%edx 7cd6: fc cld 7cd7: f2 6d repnz insl (%dx),%es:(%edi) // read a sector insl(0x1F0, dst, SECTSIZE/4);} insl直接采用了在c中嵌入汇编代码的形式，前三条mov指令准备函数参数，最核心的就是repnz insl (%dx),%es:(%edi)，通过查阅Mit给的i386.pdf： REPNE/REPNZ ── Repeat while not equal or not zeroThe primitive string operations operate on one element of a string. A string element may be a byte, a word, or a doubleword. The string elements are addressed by the registers ESI and EDI. After every primitive operation ESI and/or EDI are automatically updated to point to the next element of the string. If the direction flag is zero, the index registers are incremented; if one, they are decremented. The amount of the increment or decrement is 1, 2, or 4 depending on the size of the string element. 简而言之，被该指令修饰的指令能够自动重复执行，直到相应的结束条件被满足，这样你也能理解为什么先要执行cld使direction flag复位为0，为的是使index register增长而不是减小，这样就能够将数据按照物理内存地址从到大存放了，虽然能猜出来它做了什么，但是这里对insl的具体语意仍然存疑，只能用GDB调试了。 由于直接看C代码能看懂绝大部分了，因此，这里不按照官方文档提示的将断点打在0x7c00，vi boot.asm打开obj/boot.asm文件，:?insl找到insl函数，可以看到for循环是从0x7d51开始的，readseg定义在0x7cdc，readsect定义在0x7c7c，而insl的第一条指令定义在0x7cc9处，由于我的目的是了解insl函数的具体过程，因此将断点打在0x7cc9处，然后单步运行至第一条repnz insl (%dx),%es:(%edi)前，输出寄存器内容: 然后执行第一次repnz insl (%dx),%es:(%edi),再次输出寄存器内容： 很明显了，insl指令将4个字节的数据从扇区读出来到0x1f0端口，然后将其存放到以%edi为起始物理内存地址的地方，然后将%edi寄存器中的数据加4，%ecx寄存器中的数据减1，并且会检测%ecx寄存器中是否为0，若为0，则达到了repnz终止的条件，换而言之，若的确是这样，那么该指令就会执行128次，因为初始时%ecx寄存器值为128（恰巧，insl函数的第三个参数就是128，都对上了！），为了验证的确将数据复制了，输出以0x10000为起始地址的10个双字的数据，再执行9条指令，再次输出寄存器内容以及内存信息： 此时repnz insl (%dx),%es:(%edi)已经执行了10次，应当再执行118次就会终止，si 117验证： 从上面的结果完全证明了我的猜测是正确的。后续就是执行相同的循环来读取扇区内容到内存，就不再赘述。 为了找出Boot Loader执行的最后一条指令以及Kernel执行的第一条指令，将断点打在readseg处，随后经过调试，可以发现，执行了4次之后，再单步调试，然后可以找到bootmain最后执行的代码((void (*)(void)) (ELFHDR->e_entry))();对应的汇编代码： 然后能找到bootmain最后执行的代码对应的汇编代码的入口 然后继续向下调试，发现最终进入了kern/entry.S。 那么从call *0x10018一直到jmp *%eax之间的指令做了什么呢？ 1movw $1234,0x472 不是很确定这条指令做什么的，不过在entry.S中有注释是warm kernel? 12mov $0x110000,%eaxmov %eax,%cr3 不妨再回去看一看Wiki:Control register，或者如果你看过mit给的xv6-book.pdf,那么你就明白，0x110000即为entrypgdir的物理地址，它与虚拟内存的实现息息相关。 123mov %cr0,%eaxor $0x80010001,%eaxmov %eax,%cr0 同样参考Wiki页面，明白了吗，这段代码设置了%cr0控制寄存器的PE,WP,PG位，即开启Protected Mode,Write Protect以及Paging,也就是开启了Paging功能，能够将物理地址映射为虚拟地址 Exercise 3到这里基本告一段落，下面是我对四个问题的解答（若有误烦请指正）： 从ljmp $PROT_MDOE_CSEG, $protcseg开始，由于设置了%cr0控制寄存器，使得处理器从实模式切换为保护模式，开始执行32-bit code。 Boot loader执行的最后一条指令应该是call *0x10018,加载内核之后的第一条指令应该是movl $0x1234,0x472 内核的第一条指令位于kern/entry.S Boot loader通过ELF的Program Header中存储的各种信息，例如p_paddr,p_memsz,p_offset等可以确定需要加载多少sector。 Exercise 4,5,6#key point# An ELF binary starts with a fixed-length ELF header, followed by a variable-length program header listing each of the program sections to be loaded. The C definitions for these ELF headers are in inc/elf.h. The program sections we’re interested in are: .text: The program’s executable instructions. .rodata: Read-only data, such as ASCII string constants produced by the C compiler. (We will not bother setting up the hardware to prohibit writing, however.) .data: The data section holds the program’s initialized data, such as global variables declared with initializers like int x = 5; My answer for exercise 4#关于C指针的练习我就不写了。但是按照文档要求，反汇编了一下 obj/kern/kernel,obj/boot/boot.out,obj/kern/kernel三个文件: 将kernel的代码加载到物理内存地址0x100000对应于虚拟地址0xf0100000。 与kernel不同，boot程序运行时还没有虚拟内存，页面等机制，因此，虚拟地址就是物理内存地址。 这个就是Kernel的Program Header,LOAD标识的segment会被加载到内存当中。 My answer for exercise 5#将Makefrag中的boot loader的link address修改为0x7c2d,然后make clean清除之前的编译信息，make重新编译后，再用GDB调试，发现这次，程序会一直卡在ljmp指令上无法运行了： My answer for exercise 6#问题是： Reset the machine (exit QEMU/GDB and start them again). Examine the 8 words of memory at 0x00100000 at the point the BIOS enters the boot loader, and then again at the point the boot loader enters the kernel. Why are they different? What is there at the second breakpoint? 其实很好解释，参考exercise 4反汇编的kernel的.text节，当boot loader进入kernel的时候，此时0x100000起始的物理内存空间已经被加载了内核代码，而当BIOS进入boot loader时，BIOS只是将boot loader的代码加载到了0x7c00起始的物理内存空间，并且此时还运行在real mode之下，那么这时候输出0x100000内存地址的内容，当然是0，不妨验证一下： Part 3：The Kernel# Exercise 7#Key point# Many machines don’t have any physical memory at address 0xf0100000, so we can’t count on being able to store the kernel there. Instead, we will use the processor’s memory management hardware to map virtual address 0xf0100000 (the link address at which the kernel code expects to run) to physical address 0x00100000 (where the boot loader loaded the kernel into physical memory). This way, although the kernel’s virtual address is high enough to leave plenty of address space for user processes, it will be loaded in physical memory at the 1MB point in the PC’s RAM, just above the BIOS ROM.In fact, in the next lab, we will map the entire bottom 256MB of the PC’s physical address space, from physical addresses 0x00000000 through 0x0fffffff, to virtual addresses 0xf0000000 through 0xffffffff respectively. You should now see why JOS can only use the first 256MB of physical memory.For now, we’ll just map the first 4MB of physical memory. My answer for exercise 7#事实上，在exercise3当中，通过对%cr0控制寄存器各bit作用的说明，就已经知道movl %eax, %cr0这条指令最终设置了PE,WP,PG位，最重要的是启用了Paging功能，能够将虚拟地址映射到物理地址，按照exercise 7的要求，进行gdb调试。 可以发现，在这一行开启了Paging功能之后，0xf0100000虚拟内存地址被映射到了物理地址0x100000，倘若我们注释掉movl %eax, %cr0，很显然，此时没有开启Paging，没有映射关系，那么此时一定无法执行后续指令，不妨验证一下： 可以看到注释了那一行之后，直接导致qemu出错终止了！ Exercise 8#My answer for exercise 8#修改为（然后make qemu可以验证输出结果）: 123num = getuint(&ap, lflag);base = 8;goto number; Explain the interface between printf.c and console.c. Specifically, what function does console.c export? How is this function used by printf.c? printf.c调用了console.c中定义的cputchar(int c)，用它输出字符c到屏幕上。 Explain the following from console.c: crt_pos指向字符当前位置（相对于屏幕而言的），CRT_COLS为一行能容纳字符的大小，CRT_SIZE是整个屏幕能容纳的字符。当屏幕上的字符已经满了的时候（比如整个屏幕都是文字的时候，你再打字，是不是最上面一行就会消失并且下面空出了一行，这里就是做这种操作），因此memmove(crt_buf, crt_buf + CRT_COLS, (CRT_SIZE - CRT_COLS) * sizeof(uint16_t))给我的感觉很像“滑动窗口”的感觉，简而言之就是屏幕将crt_buf+CRT_COLS起始处的(CRT_SIZE-CRT_COLS)个字符显示出来，后续for循环不断执行crt_buf[i] = 0x0700 | ' ';将最后新出现的一行填充上空格(这里0x0700是用来控制字符的样式的，这里0x0700是黑底白字，但因为是空格，不会有效果），这时候crt_pos应该在屏幕的最后位置，于是crt_pos -= CRT_COLS;将其移动到最后一行的开头处。 For the following questions you might wish to consult the notes for Lecture 2. These notes cover GCC’s calling convention on the x86.Trace the execution of the following code step-by-step: 3.1:In the call to cprintf(), to what does fmt point? To what does ap point? fmt指向格式字符串”x %d, y %x, z %d\\n”（这部分存储在ELF Header的.rodata当中，因此在实际进程中，其内存地址不在栈中，而是在text and data那一部分),ap指向x，也即存储的是x的地址。 3.2:List (in order of execution) each call to cons_putc, va_arg, and vcprintf. For cons_putc, list its argument as well. For va_arg, list what ap points to before and after the call. For vcprintf list the values of its two arguments. 直接将代码添加在kern/init.c当中，为了方便查看obj/kern/kernel.asm时找到我们添加的代码，在代码中使用”exercise8_for_lab1:”标记好，然后在cons_putc,vcprintf以及va_arg的函数入口地址处打上断点（注：由于编译器的优化，会将getint和getuint优化成inline function，因此必须取消这种优化才便于调试，将static删除），调试过程见下方GDB调试过程。以下为完整答案： （题目略）代码输出结果是”He110 Worldentering test_backtrace 5”,因为57616的16进制表示为0xe110,而由于x86是小端机器，因此unsigned int i=0x00646c72中的i在内存中（内存地址从小到大）为”72 6c 64 00”,查询ASCII表可知结果对应为”rld\\0”。相反如果是大端机器，则需要内存中布局不变，那么就需把代码改成unsigned int i=0x726c6400,而57616不需要改变。 （题目略）按照8.3的方法添加代码，执行make qemu，我的结果是”x=3 y=1600”。按照调试8.3的经验，1600(0x640)应该是紧接着3所在的内存地址处的值,验证见下图,可以看到0x3处紧邻的0x640即为y的输出值: （题目略）x86完全使用栈来传递函数参数，并且从上面的调试过程我们能发现，x86的函数入栈是从右向左入栈的，而6则让我们想一想若将参数传递改成从左向右（即按照参数的声明顺序），需要改动什么才能实现可变数量的参数。关键问题在于若参数数量不确定，那么被调用函数就没办法在栈中顺利找到传递给它的固定参数值（因为偏移量是不确定的），或许可以在参数都入栈之后，再由编译器在其后存储上实际调用过程中添加的可变参数的数量的值，这样就能够确定偏移量了，额…感觉我的办法有点笨，不过也没有办法验证。 Challenge Enhance the console to allow text to be printed in different colors.事实上，在前面我们发现console.c中就有设置字符样式的代码，通过改变字符的高16位，来提示CGA字符的样式，默认是c |= 0x0700;，尝试将其改为c |= 0x0600，结果如下，成功改变颜色！ GDB debugging process for exercise 8.3#在kernel.asm中找到添加的代码，其地址为0xf01000d3。 验证0xf0101872处是格式字符串。 然后查看传递给vcprintf的参数，可以看到为0xf0101872以及0xf010ffd4,8.3.1解决！ 将断点打在0xf0100300即可找到第一个cons_putc函数的入口处。 发现传递给cons_putc的参数值为0x78,显然，即为字符’x’! 由于va_arg是一个宏定义，没办法打断点，只能够将断点打在getuint和getint函数上，然后会发现，每一个va_arg对应的汇编代码大概都是这样，很明显，将ap的值加4后又赋值给ap,例如开始ap为0xf010ffd4,那么通过va_arg宏，ap改变为0xf010ffd8。 后续都是重复过程，就不再赘述。 Exercise 9#My answer for exercise 9#回想之前几个exercise，应该在entry.S当中初始化栈，结合obj/kern/kernel.asm以及inc/memlayout.h还有inc/mmu.h很容易找到答案：在0xf0100034处mov $0xf0110000,%esp初始化内核栈，对应于entry.S中的mov $(bootstacktop),%esp,并且在inc/mmu.h中定义了PGSIZE=4096,在inc/memlayout.h中定义了内核栈的大小KSTKSIZE=8*PGSIZE即2^15即0x8000,因此内核栈的内存区域为0xf0110000~0xf0108000. Exercise 10#Key point# The ebp (base pointer) register, in contrast, is associated with the stack primarily by software convention. On entry to a C function, the function’s prologue code normally saves the previous function’s base pointer by pushing it onto the stack, and then copies the current esp value into ebp for the duration of the function. If all the functions in a program obey this convention, then at any given point during the program’s execution, it is possible to trace back through the stack by following the chain of saved ebp pointers and determining exactly what nested sequence of function calls caused this particular point in the program to be reached. This capability can be particularly useful, for example, when a particular function causes an assert failure or panic because bad arguments were passed to it, but you aren’t sure who passed the bad arguments. A stack backtrace lets you find the offending function. My answer for exercise 10#test_backtrace定义在地址0xf0100040,将断点打在此处，然后调试即可。下图是该递归函数进入到第二层的栈结构，可以得出以下结论，每一层都需要8个字的空间，即8*4=32字节。正如官方文档所说，每个函数调用入口都会保存调用者的栈帧地址%ebp（被调用者保存寄存器）,因此能够轻松地向上回溯到需要的地方，拿到想要的值: Exercise 11,12#My answer for exercise 11 and 12#因为在kern/entry.S中能发现，内核初始化内核栈时，首先执行了mov $0,%ebp，因此，栈顶保存的%ebp的值为0，这就是终止条件。代码实现很简单。 在kern/kdebug.c中添加的代码为(其中N_SLINE定义在stab.h当中）： 123stab_binsearch(stabs,&lline,&rline,N_SLINE,addr); if(lline > rline)return -1; info->eip_line = stabs[lline].n_desc; 下面就是完整的实现，有两个注意点： 此时不能使用malloc函数，因为还没实现呢！ 注意uintptr_t等价于uint32_t，查看inc/type.h就能发现，二者是等价的。 1234567891011121314151617int mon_backtrace(int argc, char **argv, struct Trapframe *tf){ // Your code here. struct Eipdebuginfo eipInfo; uintptr_t ebp = read_ebp(),*t; int count = 0; while(ebp != 0){ t = (uintptr_t*)ebp; if(debuginfo_eip((uintptr_t)t[1],&eipInfo) >= 0){ cprintf(\"ebp %x eip %x args %08x %08x %08x %08x %08x\\n\", ebp, t[1],t[2],t[3],t[4],t[5],t[6]); cprintf(\"\\t%s:%d: %.*s+%d\\n\",eipInfo.eip_file,eipInfo.eip_line,eipInfo.eip_fn_namelen,eipInfo.eip_fn_name,eipInfo.eip_fn_addr); ++count; } ebp=t[0]; } return count;} 最后别忘了在kern/monitor.c当中添加上该指令： 12345static struct Command commands[] = { { \"help\", \"Display this list of commands\", mon_help }, { \"kerninfo\", \"Display information about the kernel\", mon_kerninfo }, { \"mon_backtrace\", \"Display the stack frame\", mon_backtrace },}; 参考资料# 【1】：Intel 80386 Reference Programmer’s Manual【2】：xv6 - a simple, Unix-like teaching operating system - Reference Book【3】：PC Assembly Language.Paul A. Carter【4】：Boch’s map of I/O ports to functions【5】：Phil Storrs I/O Ports Description【6】：Quora:What is the A20 gate in a CPU【7】：x86-lidt and lgdt【8】：Wiki:GDT【9】：Wiki:Control register【10】：Wiki:Executable and Linkable Format【11】：Phil Storrs PC Hardware book - Understanding the CMOS【12】：《Computer Systems: A Programmer’s Perspective (3rd Edition)》.Randal E.Bryant / David O’Hallaron.【13】：《Modern Opeation Systems (Fourth Edition)》.Andrew S.Tanenbaum / Herbert Bos.","link":"/2019/12/28/MIT-6-828-LAB1-Booting-a-PC/"},{"title":"Lightweight JSON Parser Based on C -- cJSON","text":"Contents# Quick start build run cJSON with test.c be familiar to call flow with test.c Core data structure Construtor normal constructor reference item constructor Destructor Special data sturcture based on core DS Array construction of array insert detach iteration Object construction of object insert detach Parser core API string parser number parser array parser object parser REFERENCES Quick start# build#将cJSON项目克隆至本地：git clone https://github.com/DaveGamble/cJSON.git cjson进入cjson目录创建build文件夹：mkdir build进入build文件夹：cd buildcmake构建项目：cmake ..随后返回上一级目录，可以选择编译项目，也可以选择将cJSON安装到用户本地环境： make编译整个项目，构建动态链接库，编译测试代码 make install编译整个项目并将头文件、源文件以及动态链接库等复制到本地环境 make uninstall删除安装在本地的cJSON环境 make clean清除编译信息 run cJSON with test.c#直接make就能够得到test.c相应的可执行文件cJSON_test 也可以自己手动编译：gcc cJSON.c test.c -o cJSON_test 然后直接执行该二进制可执行文件即可执行test.c中的代码：./cJSON_test Be familiar with call flow with test.c#快速了解一个项目，跑一跑测试demo是目前我认为的最行之有效的方法。 以test.c的一段代码以及相应的结果为例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344// array of recordstruct record fields[2] = { { \"zip\", 37.7668, -1.223959e+2, \"\", \"SAN FRANCISCO\", \"CA\", \"94107\", \"US\" }, { \"zip\", 37.371991, -1.22026e+2, \"\", \"SUNNYVALE\", \"CA\", \"94085\", \"US\" }};// our array of \"records\"root = cJSON_CreateArray();for (i = 0; i < 2; i++){ cJSON_AddItemToArray(root, fld = cJSON_CreateObject()); cJSON_AddStringToObject(fld, \"precision\", fields[i].precision); cJSON_AddNumberToObject(fld, \"Latitude\", fields[i].lat); cJSON_AddNumberToObject(fld, \"Longitude\", fields[i].lon); cJSON_AddStringToObject(fld, \"Address\", fields[i].address); cJSON_AddStringToObject(fld, \"City\", fields[i].city); cJSON_AddStringToObject(fld, \"State\", fields[i].state); cJSON_AddStringToObject(fld, \"Zip\", fields[i].zip); cJSON_AddStringToObject(fld, \"Country\", fields[i].country);}if (print_preallocated(root) != 0) { cJSON_Delete(root); exit(EXIT_FAILURE);}cJSON_Delete(root); 通过运行并且比对结果，可以知道5点： cJSON的核心数据结构就是struct cJSON； cJSON_CreateArray()系列API能够初始化相应的数据结构； cJSON_AddItemToArray()系列API能够为初始化的数据结构填充数据； print_preallocated()解析数据结构并且将其打印； cJSON_Delete()释放数据结构占用的堆内存； 因此，从上述5点依次出发，就能逐渐对整个项目代码有初步的了解。 Core data structure# 核心数据结构为struct cJSON： 1234567891011121314151617181920// file:cJSON.htypedef struct cJSON{ struct cJSON *next; struct cJSON *prev; struct cJSON *child; // The type of the item. int type; // The item's string, if type == cJSON_String and type == cJSON_Raw. char *valuestring; // Writing to valueint is DEPRECATED, use cJSON_SetNumberValue instead. int valueint; // The item's number, if type == cJSON_Number. double valuedouble; // The item's name string, if this item is the child of, or is in the list of subitems of an object. char *string;} 核心数据结构组织示例如下： 123456789101112131415161718+----+|NODE| *root NODE+----+ | ^ v |+----+ +----+ | ^ | ^ v | v |+----+ +----+ | ^ v | +----+ +----+ 很清晰，若把每一对{}看作一个结点，那么从root NODE开始，第二级包括了并列的3个结点，而第二级结点中，又有两个结点带下一级结点，以此类推，得到的json结构如下（示意图）： 123456789101112131415{ { {}, { {}, {}, {} } }, {}, { {}, {} }} 这样的数据结构的设计，正好符合json的嵌套结构，并且链表+子链表的结构（个人感觉很像三叉树的变形），对于后续json解析算法的实现以及实现array都非常方便。 Constructor# Normal constructor#以cJSON *cJSON_CreateRaw(const char *raw);为例： 123456789101112131415161718192021222324252627// Internal constructor.static cJSON *cJSON_New_Item(const internal_hooks * const hooks){ cJSOn* node = (cJSON*)hooks->allocate(sizeof(cJSON)); if(node) { memset(node, '\\0', sizeof(cJSON)); } return node;}CJSON_PUBLIC(cJSON *) cJSON_CreateRaw(const char *raw){ cJSON *item = cJSON_New_Item(&global_hooks); if(item) { item->type = cJSON_Raw; item->valuestring = (char*)cJSON_strdup((const unsigned char*)raw, &global_hooks); if(!item->valuestring) { cJSOn_Delete(item); return NULL; } } return item;} cJSON_CreateRaw调用内部构造器cJSON_New_Item创建cJSON结构体，并且分配堆内存，同时将分配的内存初始化为’\\0’，随后cJSON_CreateRaw将创建的item类型设置为cJSON_Raw。 同理，其它create系列API内部都会调用cJSON_New_Item创建cJSON结构体，并且设置上相应的类型。 reference item constructor#以cJSON *cJSON_CreateObjectReference(const cJSON *child);为例： 1234567891011121314151617// helper function to cast away const.static void* cast_away_const(const void* string){ return (void*)string;}CJSON_PUBLIC(cJSON *) cJSON_CreateObjectReference(const cJSON *child){ cJSON *item = cJSON_New_Item(&global_hooks); if (item != NULL) { item->type = cJSON_Object | cJSON_IsReference; item->child = (cJSON*)cast_away_const(child); } return item;} 这个引用构造器构建模型如下所示： 1234+----+ child +---------------+|NODE| -----> |REFERENCED NODE|+----+ +---------------+(type: NODE type | cJSON_IsReference) 即创建一个间接结点来引用制定的结点或数据。 Destructor# Destructor将cJSON占用的堆内存释放。API接口为void cJSON_Delete(cJSON *item); 在去查看源码的实现之前，不妨自己先思考自己会怎么实现这个接口。考虑到cJSON的数据结构，我们应当从最底层的最后一个结点开始释放内存，才能够防止内存泄漏的情况发生。有了这样的思路，我们就能快速写一个大概的框架出来： 1234567891011121314151617181920212223242526272829303132// temporary implemention of cJSON destructor.CJSON_PUBLIC(void) cJSON_Delete(cJSON *item){ // Avoid null pointer exception. if(item == NULL)return; // free next Node if the item has one. if(item->next != NULL) { cJSON_Delete(item->next); } // free child node if the item has one. if(item->child != NULL) { cJSON_Delete(item->child); } // free valuestring if the item has allocated memory for it. if(item->valuestring != NULL) { free(item->valuestring); } // free string if the item has allocated memory for it. if(item->string != NULL){ free(item->string); } // free the item itself. free(item);} 这便是简单的实现思路，直接递归解决，这里以core data structure的json结点结构为例子，为便于理解，将其编号如下： 123456789101112131415161718+-------+|NODE(1)| *root NODE+-------+ | ^ v |+-------+ +-------+ | ^ | ^ v | v |+-------+ +-------+ | ^ v | +-------+ +--------+ 按照上面的递归算法，那么在上述的结构中，调用： 1cJSON_Delete(root); 结点释放的顺序为：(8)->(7)->(4)->(3)->(11)->(10)->(9)->(6)->(5)->(2)->(1). 再看cJSON源代码的实现： 12345678910111213141516171819202122CJSON_PUBLIC(void) cJSON_Delete(cJSON *item){ cJSON *next = NULL; while (item != NULL) { next = item->next; if (!(item->type & cJSON_IsReference) && (item->child != NULL)) { cJSON_Delete(item->child); } if (!(item->type & cJSON_IsReference) && (item->valuestring != NULL)) { global_hooks.deallocate(item->valuestring); } if (!(item->type & cJSON_IsReference) && (item->string != NULL)) { global_hooks.deallocate(item->string); } global_hooks.deallocate(item); item = next; }} CJSON的作者的实现思路是有child结点的就立即释放，并且作者的这种实现方式的最大递归深度显然为层数（即json的嵌套层数），而我的递归思路的最大递归深度显然为根结点到叶结点（即没有next和child结点）的最长路径，因此，从递归栈的花费来看，作者的这种实现思路是要优于我的。甚至在极端情况下，我的这种实现方式很可能栈溢出。 仍然以上面的json结构为例，按照CJSON作者的思路，结点释放顺序为：(5)->(9)->(10)->(11)->(6)->(2)->(3)->(7)->(8)->(4)->(1). 如果仍然采用我的实现思路，那么最终修饰一下细节之后的完整实现应该为： 1234567891011121314151617181920212223242526// final implemention of cJSON destructor of mine.CJSON_PUBLIC(void) cJSON_Delete(cJSON *item){ if (item == NULL)return; if (item->next != NULL) { cJSON_Delete(item->next); } if (!(item->type & cJSON_IsReference) && (item->child != NULL)) { cJSON_Delete(item->child); } if (!(item->type & cJSON_IsReference) && (item->valuestring != NULL)) { global_hooks.deallocate(item->valuestring); } if (!(item->type & cJSON_IsReference) && (item->string != NULL)) { global_hooks.deallocate(item->string); } global_hooks.deallocate(item);} Special data structure based on core DS# Array# construction of array#在core data structure的基础之上，cJSON还提供了array的实现，数据结构为带头结点的双向链表： 1234567 child next+-----+ ----> +----+ ----> +----+ ----> +----+ ----> +----+ ----> NULL|Array| |NODE| prev |NODE| |NODE| |NODE|+-----+ ----- +----+ child = item; item->prev = item; item->next = NULL; } else { // append to the array's end. array->child->prev->next = item; item->prev = array->child->prev; array->child->prev = item; } // which means that insertion success. return 1;} 比对cJSON作者的实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// Utility for array list handling.static void suffix_object(cJSON *prev, cJSON *item){ prev->next = item; item->prev = prev;}static cJSON_bool add_item_to_array(cJSON *array, cJSON *item){ cJSON *child = NULL; if ((item == NULL) || (array == NULL) || (array == item)) { return false; } child = array->child; if (child == NULL) { // list is empty, start new one. array->child = item; item->prev = item; item->next = NULL; } else { // append to the end. if (child->prev) { suffix_object(child->prev, item); array->child->prev = item; } else { while (child->next) { child = child.next; } suffix_object(child, item); array->child->prev = item; } } return true;} 可以看到主要在于当array中非空的时候，插入新结点的时候，有一点区别： cJSON的作者增加的情况是，当array的第一个元素的prev指针未指向末尾元素的时候，需要遍历一遍链表，从而找到末尾元素，随后再执行新结点的插入。 QUESTION：但是我目前没有想通在什么情况下第一个元素的prev指针没有指向末尾元素？因为我们执行插入时，一定会将第一个元素的prev指针指向末尾元素，那么就应该不会存在上面cJSON作者所考虑的这种情况啊。或许是删除结点后有可能导致这种情况的发生吗？ detach#考虑array元素的删除API，在cJSON的实现中，call flow如下： 1234567cJSON_DeleteItemFromArray | VcJSON_DetachItemFromArray | VcJSON_DetachItemViaPointer(array, get_array_item(array, (size_t)which)) 考虑自己自己来实现cJSON_DetachItemViaPointer(cJSON *root, cJSON *target)与cJSON *get_array_item(cJSON *array, size_t which)： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556static cJSON *get_array_item(cJSON *array, size_t which){ if(array == NULL || array->child == NULL || which < 0) { return NULL; } size_t i = 0; cJSON *head = array->child; while(i < which && head->next != NULL) { i++; head = head->next; } if (i == which) { return head; } // which means that 'which' > 'size of this array'. return NULL;}// Detach this item from the array but DO NOT free its memory.CJSON_PUBLIC(cJSON *) cJSON_DetachItemViaPointer(cJSON *root, cJSON *target){ if (root == NULL || target == NULL) { return NULL; } // not the first element. if (target != root->child) { target->prev->next = target->next; } // not the last element. if (target->next != NULL) { target->next->prev = target->prev; } // finally, we should reconnect head node if the detached target was first element before. if (root->child == target) { root->child = target->next; } target->prev = NULL; target->next = NULL; return target;} iteration#获取array item，cJSON提供了CJSON_PUBLIC(cJSON *) cJSON_GetArrayItem(const cJSON *array, int index); 因此迭代获取array item最直观的是： 12345// time complexity:O(n^2).for(int i = 0; i < cJSON_GetArraySize(array); i++){ cJSON_GetArrayItem(array, i);} 由于cJSON_GetArrayItem底层调用get_array_item，由于array数据结构采用链表来实现，get_array_item获取元素也需要遍历一遍array，因此总的时间复杂度为O(n^2)。 根据cJSON作者给出的参考文档： Because an array is stored as a linked list, iterating via index is inefficient(O(n^2)), so you can iterate over an array using the cJSON_ArrayForEach macro in O(n) time complexity. 12// iteration macro.#define cJSON_ArrayForEach(element, array) for(element = (array != NULL) ? (array)->child : NULL; element != NULL; element = element->next) 使用该宏来对array进行迭代，时间复杂度显然为O(n)。 Object# construction of Object#参考上述内容自己先实现API： CJSON_PUBLIC(cJSON *) cJSON_CreateObject(void); CJSON_PUBLIC(cJSON *) cJSON_CreateObjectReference(const cJSON *object);1234567891011121314151617181920212223242526272829CJSON_PUBLIC(cJSON *) cJSON_CreateObject(void){ cJSON *object = cJSON_New_Item(&global_hooks); if (object != NULL) { object->type = cJSON_Object; } return object;}CJSON_PUBLIC(cJSON *) cJSON_CreateObjectReference(const cJSON *object){ if (object == NULL) { return NULL; } cJSON *ref = cJSON_New_Item(&global_hooks); if (ref != NULL) { ref->type = cJSON_Object; ref->child = (cJSON*)cast_away_const(child); } return ref;} insert#cJSON底层提供了接口cJSON_bool add_item_to_object(cJSON * const object, const char * const string, cJSON * const item, const internal_hooks * const hooks, const cJSON_bool constant_key);接口实现（源码）： 123456789101112131415161718192021222324252627282930313233343536static cJSON_bool add_item_to_object(cJSON * const object, const char * const string, cJSON * const item, const internal_hooks * const hooks, const cJSON_bool constant_key){ char *new_key = NULL; int new_type = cJSON_Invalid; if ((object == NULL) || (string == NULL) || (item == NULL) || (object == item)) { return false; } if (constant_key) { new_key = (char*)cast_away_const(string); new_type = item->type | cJSON_StringIsConst; } else { new_key = (char*)cJSON_strdup((const unsigned char*)string, hooks); if (new_key == NULL) { return false; } new_type = item->type & ~cJSON_StringIsConst; } if (!(item->type & cJSON_StringIsConst) && (item->string != NULL)) { hooks->deallocate(item->string); } item->string = new_key; item->type = new_type; return add_item_to_array(object, item);} detach#同Array一样，cJSON也提供了detach的APICJSON_PUBLIC(cJSON *) cJSON_DetachItemFromObject(cJSON *object, const char *string); 123456CJSON_PUBLIC(cJSON *) cJSON_DetachItemFromObject(cJSON *object, const char *string){ cJSON *to_detach = cJSON_GetObjectItem(object, string); return cJSON_DetachItemViaPointer(object, to_detach);} 关键的是实现CJSON_PUBLIC(cJSON *) cJSON_GetObjectItem(cJSON *object, const char * const string);底层调用的static cJSON *get_object_item(const cJSON * const object, const char * const name, const cJSON_bool case_sensitive);根据函数参数的提示，尝试自己来实现一遍： 123456789101112131415161718192021222324252627282930static cJSON *get_object_item(const cJSON * const object, const char * const name, const cJSON_bool case_sensitive){ if (object == NULL || name == NULL) { return NULL; } cJSON *item = object->child; if (case_sensitive) { while (item != NULL && item->string != NULL && strcmp(name, item->string) != 0) { item = item->next; } } else { while (item != NULL && item->string != NULL && case_insensitive_strcmp((const unsigned char*)name, (const unsigned char*)(item->string)) != 0) { item = item->next; } } if (item == NULL || item->string == NULL) { return NULL; } return item;} Parser# 对于以\\0（值等价于0）结尾的字符串，直接通过cJSON_Parse来解析。 1cJSON *json = cJSON_Parse(string); 同样的，不管以\\0结尾与否，都可以通过cJSON_ParseWithLength来解析。 1cJSON *json = cJSON_ParseWithLength(string, buffer_length); 它们将会解析该json字符串并将其组织成json树（例如上面提到的那些例子），解析成功后返回的json树能够通过cJSON_Delete来销毁。 若解析过程中出错，可以通过cJSON_GetErrorPtr来得到出错的位置，但是该函数并不是线程安全的，在多线程的场景下，会产生竞争，因此，最好搭配return_parse_end使用cJSON_ParseWithOpts。 如果想要对解析有更高的掌控度，可以直接调用cJSON_ParseWithOpts(const char *value, const char **return_parse_end, cJSON_bool require_null_terminated);其中，return_parse_end指向被解析的字符串的末尾或者发生错误时的位置。在解析产生错误的场景下，相较于cJSON_GetErrorPtr，这种方式是线程安全的。 除此之外，也可以直接调用最底层的接口CJSON_PUBLIC(cJSON *) cJSON_ParseWithLengthOpts(const char *value, size_t buffer_length, const char **return_parse_end, cJSON_bool require_null_terminated)。 core API#来看核心的API实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576CJSON_PUBLIC(cJSON *) cJSON_ParseWithLengthOpts(const char *value, size_t buffer_length, const char **return_parse_end, cJSON_bool require_null_terminated){ parse_buffer buffer = {0, 0, 0, 0, {0, 0, 0}}; cJSON *item = NULL; global_error.json = NULL; global_error.position = 0; if (value == NULL || buffer_length == 0) { goto fail; } buffer.content = (const unsigned char*)value; buffer.length = buffer_length; buffer.offset = 0; buffer.hooks = global_hooks; item = cJSON_New_Item(&global_hooks); if (item == NULL) { goto fail; } if (!parse_value(item, buffer_skip_whitespace(skip_utf8_bom(&buffer)))) { goto fail; } if (require_null_terminated) { buffer_skip_whiltespace(&buffer); if ((buffer.offset >= buffer.length) || buffer_at_offset(&buffer)[0] != '\\0) { goto fail; } } if (return_parse_end) { *return_parse_end = (const char*)buffer_at_offset(&buffer); } return item;fail: if (item != NULL) { cJSON_Delete(item); } if (value != NULL) { error local_error; local_error.json = (const unsigned char*)value; local_error.position = 0; if (buffer.offset < buffer.length) { local_error.position = buffer.offset; } else if (buffer.length > 0) { local_error.position = buffer.length - 1; } if (return_parse_end != NULL) { *return_parse_end = (const char*)local_error.json + local_error.position; } global_error = local_error; } return NULL;} 几个关键的数据结构： 123456789101112131415typedef struct{ const unsigned char *json; size_t position;}error;static error global_error = { NULL, 0};typedef struct{ const unsigned char *content; size_t length; size_t offset; size_t depth; internal_hooks hooks;} parse_buffer; 首先来看skip_utf8_bom： 1234567891011121314static parse_buffer *skip_utf8_bom(parse_buffer * const buffer){ if ((buffer == NULL) || (buffer->content == NULL) || (buffer->offset != 0)) { return NULL; } if (can_access_at_index(buffer, 4) && (strncmp((const char*)buffer_at_offset(buffer), \"\\xEF\\xBB\\xBF\", 3) == 0)) { buffer->offset += 3; } return buffer;} 实际上就是某些编辑器编辑UTF8编码的文件时，会自动在文件的最开始插入三个隐藏字符”\\xEF\\xBB\\xBF”，例如windows系统自带的记事本。 【百度百科-BOM】BOM,(Byte Order Mark)，字节顺序标记，出现在文本文件头部，Unicode编码标准中用于标识文件是采用哪种格式的编码。类似WINDOWS自带的记事本等软件，在保存一个以UTF-8编码的文件时，会在文件开始的地方插入三个不可见的字符（0xEF 0xBB 0xBF，即BOM）。它是一串隐藏的字符，用于让记事本等编辑器识别这个文件是否以UTF-8编码。 再看buffer_skip_whitespace： 123456789101112131415161718192021222324static parse_buffer *buffer_skip_whitespace(parse_buffer * const buffer){ if (buffer == NULL || buffer->content == NULL) { return NULL; } if (cannot_access_at_index(buffer, 0)) { return buffer; } while (can_access_at_index(buffer, 0) && (buffer_at_offset(buffer)[0] offset++; } if (buffer->offset == buffer->length) { buffer->offset--; } return buffer;} 实际上就是跳过从buffer->offset开始的可能存在的“空格”（在这里的编码中ASCII编码小于等于32的字符都被视作为空格）。 最后看parse_value： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// Parser core - when encountering text, process appropriately.static cJSON_bool parse_value(cJSON * const item, parse_buffer * const input_buffer){ if ((input_buffer == NULL) || (input_buffer->content == NULL)) { return false; } // parse the different types of values. // null. if (can_read(input_buffer, 4) && strncmp((const char*)buffer_at_offset(input_buffer), \"null\", 4) == 0) { item->type = cJSON_NULL; input_buffer->offset += 4; return true; } // false. if (can_read(input_buffer, 5) && strncmp((const char*)buffer_at_offset(input_buffer), \"false\", 5) == 0) { item->type = cJSON_False; input_buffer->offset += 5; return true; } // true. if (can_read(input_buffer, 4) && strncmp((const char*)buffer_at_offset(input_buffer), \"true\", 4) == 0) { item->type = cJSON_True; item->valueint = 1; input_buffer->offset += 4; return true; } // string. if (can_access_at_index(input_buffer, 0) && (buffer_at_offset(input_buffer)[0] == '\\\"')) { return parse_string(item, input_buffer); } // number. if (can_access_at_index(input_buffer, 0) && (buffer_at_offset(input_buffer)[0] == '-') || ((buffer_at_offset(input_buffer)[0] >= '0') && (buffer_at_offset(input_buffer)[0] | B | --------------------> | C | | ||+---+| | | | | | | ----- | |+-----+ +-----+ +-----+ +-----+ | | | | ^ ^ ^ | | | | | | | else| | | |else | -------------------------- | | | | | 'b'||'f'||'n'||'r'||'t'||'\\\"'||'\\\\'||'/' | | | | --------------------------------------------------------------------- | | | +-----+ sequence_length == 0 | | | |+---+| ||BAD|| | --- |+---+| content) < input_buffer->length) && *end != '\\\"') { if (*end == '\\\\') { // avoid the character '\\' is the last character in the string. if (!((size_t)(end + 1 - input_buffer->content) < input_buffer->length)) { goto fail; } skip_size++; } end++; } // verify legality. if (!((size_t)(end - input_buffer->content) < input_buffer->length) || *end != '\\\"') { goto fail; } // note that we should annlocate one more bytes for '\\0' so that // the string could be terminated normally. alloc_size = (size_t)(end - buffer_at_offset(input_buffer)) - skip_size; output = (unsigned char *)input_buffer->hooks.allocate(alloc_size); if (output == NULL) { goto fail; } // start parsing. output_p = output; while(string_p < end) { if (*string_p != '\\\\') { *output_p++ = *string_p++; } else { size_t sequence_length = 2; switch(string_p[1]) { case 'b': *output_p++ = '\\b'; break; case 'f': *output_p++ = '\\f'; break; case 'n': *output_p++ = '\\n'; break; case 'r': *output_p++ = '\\r'; break; case 't': *output_p++ = '\\t'; break; case '\\\"': case '\\\\': case '/': *output_p++ = string_p[1]; break; case 'u': sequence_length = utf16_literal_to_utf8(input_pointer, end, &output_p); if (sequence_length == 0) { goto fail; } break; default: goto fail; } output_p += sequence_length; } } // ensure that the string was terminated normally. *output_p = '\\0'; item->type = cJSON_String; item->valuestring = (char*)output; input_buffer->offset = (size_t)(end - input_buffer->content) + 1; return true;fail: // correct offset. if (string_p != NULL) { input_buffer->offset = (size_t)(string_p - input_buffer->content); } // free memory when necessary. if (output != NULL) { input_buffer->hooks.deallocate(output); } return false;} 为了不浪费内存，首先对输入的字符串进行了预处理，校验了合法性，计算了实际需要分配的内存大小。因此，这里的实现并没有非常直观地对应于状态转换图。 number parser#在源码实现上并没有太多细节，直接调用标准库函数strtod将字符串转换为浮点数，类型为double。 array parser#同上，状态转换图简单总结如下： 12345678 -------- | | | | ','+-----+ +-----+ | +-----+ |+---+| '[' | | | A | -------------> || F |||+---+| | | |+---+|+-----+ +-----+ +-----+ 其中起始状态为S，最终状态为F，还有一个中间状态A。 考虑自己来实现一个代码的基本骨架： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182static cJSON_bool parse_array(cJSON * const item, parse_buffer * const input_buffer){ if (item == NULL || input_buffer == NULL) { return false; } if (cannot_access_at_index(input_buffer, 0) && buffer_at_offset(input_buffer)[0] != '[') { goto fail; } input_buffer->offset++; buffer_skip_whitespace(input_buffer); if (can_access_at_index(input_buffer, 0) && buffer_at_offset(input_buffer)[0] == ']') { goto success; } // step back an character in front of the first element. // please see the two possibilities below. input_buffer->offset--; // gets here means that at least one element in this array. cJSON *head = NULL; cJSON *current_item = NULL; do { cJSON *new_item = cJSON_New_Item(&(input_buffer->hooks)); if (current_item == NULL) { goto fail; } if (head == NULL) { // first element; head = new_item; current_item = new_item; } else { current_item->next = new_item; new_item->prev = current_item; current_item = new_item; } // two possibilities: // 1. now buffer_at_offset(input_buffer) == ',' // 2. this is the first time to be here before first element, // in case that if we were not do something special before // the first element, the 'input_buffer->offset++' would // make an error. input_buffer->offset++; buffer_skip_whitespace(input_buffer); if (!parse_value(current_item, input_buffer)) { goto fail; } buffer_skip_whitespace(input_buffer); } while (can_access_at_index(input_buffer, 0) && (buffer_at_offset(input_buffer)[0] == ',')); // make sure that the array was terminated normally. if (cannot_access_at_index(input_buffer, 0) || buffer_at_offset(input_buffer)[0] != ']') { goto fail; }success: item->type = cJSON_Array; item->child = head; input_buffer->offset++; return true;fail: if (head != NULL) { cJSON_Delete(head); } return false;} 此时再去对比CJSON的源代码实现，实现思路基本问题不大，但是仍然有些细节没有注意到。例如，CJSON为了避免JSON解析过程中调用栈地无限叠加，在input_buffer中设置了字段depth来限制解析的最大深度，于是在CJSON的源码实现中，还加入了对input_buffer->depth的判断与修改。 object parser#事实上，有了上面array parser的经验，不用去看源码就知道object parser只需要在array parser的代码基础上稍加修改即可。 那么，有了上次对于array parser源代码的学习基础，这一次，自己先实现一遍，应该会与源代码的差异不大了： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697static cJSON_bool parse_object(cJSON * const item, parse_buffer * const input_buffer){ if (item == NULL || input_buffer == NULL || input_buffer->depth >= CJSON_NESTING_LIMIT) { return false; } input_buffer->depth++; // make sure that the object was started normally. if (cannot_access_at_index(input_buffer, 0) || buffer_at_offset(input_buffer) != '{') { goto fail; } input_buffer->offset++; buffer_skip_whitespace(input_buffer); if (can_access_at_index(input_buffer, 0) && (buffer_at_offset(input_buffer) == '}')) { goto success; } if (cannot_access_at_index(input_buffer, 0)) { input_buffer->offset--; goto fail; } // step back an character in front of the fist element. input_buffer->offset--; cJSON *head = NULL: cJSON *current_item = NULL; do{ cJSON *new_item = cJSON_New_Item(&(input_buffer->hooks)); if (new_item == NULL) { goto fail; } if (head == NULL) { head = new_item; current_item = new_item; } else { current_item->next = new_item; new_item->prev = current_item; current_item = new_item; } input_buffer->offset++; buffer_skip_whitespace(input_buffer); if (!parse_string(current_item, input_buffer)) { goto fail; } buffer_skip_whitespace(input_buffer); current_item->string = current_item->valuestring; current_item->valuestring = NULL; if (cannot_access_at_index(input_buffer, 0) || buffer_at_offset(input_buffer)[0] != ':') { goto fail; } // skip the character ':'. input_buffer->offset++; buffer_skip_whitespace(input_buffer); if (!parse_value(current_item, input_buffer)) { goto fail; } buffer_skip_whitespcae(input_buffer); } while (can_access_at_index(input_buffer, 0) || (buffer_at_offset(input_buffer)[0] == ',')); // make sure that the object was teminated normally. if (cannot_access_at_index(input_buffer, 0) || (buffer_at_offset(input_buffer)[0] != '}')) { goto fail; }success: input_buffer->depth--; input_buffer->offset++; item->type = cJSON_Object; item->child = head; return true;fail: if (head != NULL) { cJSON_Delete(head); } return false;} REFERENCES#[1] cJSON - DaveGamble","link":"/2020/05/01/Lightweight-JSON-Parser-Based-on-C-cJSON/"},{"title":"MIT-6.828-LAB2 Memory Management","text":"Contents# Part 1:Physical Page Management Exercise 1 Key Point Part 2:Virtual Memory Exercise 2,3 Key Point Exercise 4 Part 3:Kernel Address Space Exercise 5 Key Point Questions Challenge Code implemention for all exercises REFERENCES Part 1:Physical Page Management# Exercise 1#Key point#后续内容建议配合该图食用： 在LAB1做完之后，物理内存当中就已经被加载了内核代码以及数据了（.text Section,.data Section)。kern/init.c当中下一步就是调用mem_init()，通过LAB1的学习以及kern/pmap.c当中的mem_init以及boot_alloc函数的注释，能够了解到boot_alloc是在尚未划分物理页面时在kernel的.bss segment之后分配一个页面大小的内存空间作为kernel page directory,并且分配一定大小的内存空间作为Page Info arrays（该内存空间的大小取决于npages以及sizeof(struct PageInfo),并且还要按PGSIZE对齐）。因此在mem_init中，首先初始化了kernerl page directory，随后给Page Info arrays分配了内存空间，用来存储整个物理内存空间对应的页面信息(Page Information)，在exercise 1当中，最后就是调用page_init来初始化整个物理内存空间对应的页面信息，理解了上图，写出page_init以及整个exercise 1就不难了。 但是仍然有几个注意点： 记录一个页面信息时，将PageInfo中的pp_ref置为1并不是表明其in use或者could not allocate，实际上正确的方式就是忽略这个页面（但是由于C语言需要初始化，因此将pp_ref置为0，pp_link置为NULL即可），虽然将pp_ref置为1好像也不会出错，但是不建议这么做。 npages_basemem实际上低于1MB并且低于其中IO hole(在LAB1当中有解释！）的部分的物理页面的数量，而npages则是整个物理内存空间包含的物理页面的数量。 关于上图如何验证，事实上make qemu启动后在i386_detect_memory函数中会输出base=640K，然后你还会发现在该函数中有npages_basemem = basemem / (PGSIZE / 1024);事实上这就完美验证了！ 代码实现见Code implemention for all exercises. Part 2:Virtual Memory# Exercise 2,3#Key point#这一部分就是让我们认真阅读80386 programmer mannual.这部分基础知识就不再赘述。但是值得一提的是，在80386中，并不是没有segment translation的机制，只是在boot.S当中加载了全局描述符表，该GDT将所有的段寄存器的Base address都设置为0，段寄存器寻址上限设置为0xffff ffff，因此虚拟地址经过Segment translation之后与线性地址等价，对外表现为没有segment translation的机制，但是不能够说80386将segment translation机制禁用了。下面这个简单的示意图还是很重要的： 123456789 Selector +--------------+ +-----------+ ---------->| | | | | Segmentation | | Paging |Software | |-------->| |----------> RAM Offset | Mechanism | | Mechanism | ---------->| | | | +--------------+ +-----------+ Virtual Linear Physical 此外，就是exercise3提到的进入qemu monitor的快捷键在我这不顶用，根据这个老哥的博客fatsheep-mit6.828-lab2,这个是可行的。 1qemu-system-i386 -hda obj/kern/kernel.img -monitor stdio -gdb tcp::26000 -D qemu.log Exercise 4#无特殊注意事项，代码实现见Code implemention for all exercises. Part 3:Kernel Address Space# Exercise 5#Key point#完善mem_init()的虚拟内存映射代码即可。 1boot_map_region(kern_pgdir, UPAGES, PTSIZE, PADDR(pages), (PTE_U | PTE_P)); 将pages那部分内容映射到虚拟地址UPAGES处，这里的PTSIZE实际上与ROUNDUP(sizeof(struct PageInfo)*npages, PGSIZE)是等价的，虽然它们值不相等，但是都能通过校验函数。用PTSIZE可能是源于inc/memlayout.h中的示意图，使用另外一种是因为这是PageInfo实际分配的物理存储空间大小。 1boot_map_region(kern_pgdir, KSTACKTOP-KSTKSIZE, KSTKSIZE, PADDR(bootstack), (PTE_W | PTE_P)); 将内核栈映射到虚拟地址KSTACKTOP-KSTKSIZE处。 1boot_map_region(kern_pgdir, KERNBASE, -KERNBASE, 0, (PTE_W | PTE_P)); 将整个物理存储空间映射到KERNBASE之上，在32位机器上将-KERNBASE按照无符号数解释恰好就是2^32-KERNBASE。 代码实现见Code implemention for all exercises. Questions# 1.Assuming that the following JOS kernel code is correct,what type should variable x have,uintptr_t or physaddr_t? 1234mystery_t x;char* value = return_a_pointer();*value = 10;x = (mystery_t) value; 很显然，返回的是指针，必然是虚拟地址，因此x的类型是uintptr_t. 2.What entries (rows) in the page directory have been filled in at this point? What addresses do they map and where do they point? In other words, fill out this table as much as possible: 3.We have placed the kernel and user environment in the same address space. Why will user programs not be able to read or write the kernel’s memory? What specific mechanisms protect the kernel memory? 无论是Page directory entry还是Page table entry，其低12位的控制bit起到了访问控制（读/写）以及校验优先等级（privileged level）的作用。通过设置相应的bit位就能够控制user对page的访问权限。具体参阅Intel 80386 Reference Programmer’s Manual 4.What is the maximum amount of physical memory that this operating system can support? Why? JOS使用32位系统，并且通过mem_init的设置虚拟内存对物理内存的映射的代码，我们将物理内存从0开始映射到了KERNBASE之上，而KERNBASE是0xF000 0000，32位系统最大虚拟地址为0xFFFF FFFF，因此无论实际物理内存有多大，JOS最大也只能映射2GB的物理内存。从另外一个角度来看，JOS为Page Info分配了4MB的空间，每个struct PageIngo需要8字节空间，因此最多有4MB/8=512K个PageInfo对应于512K个Page，每个Page 4KB，因此最大物理内存空间为2GB。 5.How much space overhead is there for managing memory, if we actually had the maximum amount of physical memory? How is this overhead broken down? 倘若JOS映射了2GB的物理内存，那么就有2GB/4KB=512K个物理页面，每个物理页面对应于4 bytes的page table entry，因此这部分花销是512K*4=2MB。除此之外，还有4KB的Page directory以及4MB的Page Info，因此总的花销是2MB + 4MB + 4KB. 6.Revisit the page table setup in kern/entry.S and kern/entrypgdir.c. Immediately after we turn on paging, EIP is still a low number (a little over 1MB). At what point do we transition to running at an EIP above KERNBASE? What makes it possible for us to continue executing at a low EIP between when we enable paging and when we begin running at an EIP above KERNBASE? Why is this transition necessary? 在LAB1当中已经提到了，在jmp *%eax之后，EIP从高于KERNBASE的地址处开始执行。之所以这样可行是因为entrypgdir.c将虚拟地址[0, 4MB)还有[KERNBASE, KERNBASE+4MB)映射到了物理地址[0, 4MB)。之所以要将[0, 4MB)的虚拟地址空间也映射到物理地址[0, 4MB)是因为在开启Paging之后，entry.S中还有少许指令需要执行，当其执行完之后，就会进入C语言编写的代码来对内核进行初始化，而C实际上只支持虚拟内存，因此这种转移是必要的。 Challenges# Challenge! We consumed many physical pages to hold the page tables for the KERNBASE mapping. Do a more space-efficient job using the PTE_PS (“Page Size”) bit in the page directory entries. This bit was not supported in the original 80386, but is supported on more recent x86 processors. 查阅Intel® 64 and IA-32 Architectures Software Developer’s Manual。例如基于x86架构的IA-32处理器以及 Pentium II处理器都支持了在Page directory entry中PTE_PS位的设置。在同时设置了控制寄存器CR4的PSE flag以及Page direcotry entry中的PTE_PS flag之后，该Page directory entry实际上就存储了指向4MB物理页的指针（即22~31bit位）这时候实际上二级页表不会起作用。但值得注意的是，按照Intel参考文档的说明，若没有设置CR4的PSE flag，即便设置了PTE_PS flag物理页也只能是4KB，不会是4MB。 【Reference from volume 3-27】When the PSE flag in CR4 is set, both 4-MByte pages and page tables for 4-KBytepages can be accessed from the same page directory. If the PSE flag is clear, onlypage tables for 4-KByte pages can be accessed (regardless of the setting of the PSflag in a page-directory entry). 我们熟知的4KB页面大小的Page Directory Entry： 当设置了PSE flag以及PTE_PS flag之后，页面大小为4MB，这时的Page Directory Entry: 相应的linear address translation也与之前两级页表有所不同： 当页面大小是4MB时，二级页表就不起作用了，因此，不仅能够减少存储页面信息的开销，还能减少页表的开销。 Challenge! Extend the JOS kernel monitor with commands to: 实现了一个简单版本，代码比较丑陋，没有做到能对任何的参数都不会产生bug，仅限简单的参数校验。下方是核心showMappings函数，其它util工具函数参见github代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748int show_mappings(int argc, char **argv, struct Trapframe *tf){ // validate arguments amount // argc==3,which means that show pages information between argv[1] and argv[2]. // argc==4,which means that set all the pages with perm. // argc==5,which means that only set page argv[4] with perm. cprintf(\"debug-> argc :%d\\n\",argc); if(argc < 3){ cprintf(\"Invalid arguments.You should pass two virtual address:startVA endVA and optional permissions.\\n\"); return 0; } int32_t start = s2va(argv[1]), end = s2va(argv[2]) + 1, perm = 0, onlyTarget = 0; if(start == -1 || end == -1 || end < start){ cprintf(\"Invalid virual address was given.\\n\"); return 0; } // obtain optional perm. if(argc >= 4){ char *tmp = argv[3]; if(tmp[0] == '-')perm = -1; else{ while(*tmp){ perm = perm * 10 + (*tmp - '0'); ++tmp; } } } // obtain onlyTarget while argc==4 if(argc == 5){ onlyTarget = s2va(argv[4]); } uintptr_t u_start_align = ROUNDDOWN((uintptr_t)start, PGSIZE), u_end_align = ROUNDUP((uintptr_t)end, PGSIZE); pte_t *pte; cprintf(\"va@start: %08x va@end: %08x\\n\", u_start_align, u_end_align); for(;u_start_align < u_end_align; u_start_align += PGSIZE){ pte = pgdir_walk(kern_pgdir, (void *)u_start_align, 1); if(pte){ if(argc == 4)setPermissions(perm, pte); if(argc == 5 && (uintptr_t)onlyTarget == u_start_align)setPermissions(perm, pte); cprintf(\"va@page: %08x \", u_start_align); cprintf(\"pa@page: %08x @perm:PTE_P %d PTE_U %d PTE_W %d;\\n\", PTE_ADDR(*pte),lovelyValidate(*pte & PTE_P), lovelyValidate(*pte & PTE_U), lovelyValidate(*pte & PTE_W)); } } return 0;} 效果示意图： Code implemention for all exercises#See github:YanTang Qin- MIT6.828 REFERENCES#【1】 Intel 80386 Reference Programmer’s Manual【2】 Intel® 64 and IA-32 Architectures Software Developer’s Manual【3】 XV6 - a simple, Unix-like teaching operating system - Reference Book【4】 《Computer Systems: A Programmer’s Perspective (3rd Edition)》.Randal E.Bryant / David O’Hallaron.【5】 《Modern Opeation Systems (Fourth Edition)》.Andrew S.Tanenbaum / Herbert Bos.","link":"/2020/01/01/MIT-6-828-LAB2-Memory-Management/"},{"title":"Memory mountain for Principle of program locality","text":"一、存储器山的数据测量#存储器山的数据测量（包含我所测试的数据）#这一部分很简单，因为代码已经由CMU提供给大家了，大家只需要简单地修改代码，将结果输出到txt文件即可，然后再用MATLAB或者Python写一个脚本读取该txt文件，然后将结果绘制出来即可。 首先，将结果输出到文件，很简单，这个大家都会。不过这里还是有一个要注意的点，将修改的代码编译时，（由于我是在Linux系统上完成这个实验的），mountain.c这个文件中包含对另外两个自定义的头文件（“clock.h”以及“fcyc2.h）的引用，因此编译时需要执行： 1gcc -Og -o my_memory_mountain moutain.c clock.c fcyc2.c 然后会得到一个可执行文件 my_memory_mountain，然后直接执行./my_memory_moutain等待一段时间之后就会得到存储器山的测量结果了。以我自己所测量的结果为例： 首先是原始输出的数据：其中s1-s15为步长，128m是数据大小，表格结果为读吞吐量。为了便于后期脚本的数据读取与处理，将原始结果人工进行处理，结果如下： 二、存储器山的绘制#因为我Matlab用得不熟，所以这里是用python的第三方库pyecharts的Surface3D来绘制的存储器山，但是绘制出来的结果不是很理想，因为我看了很久文档都没有弄太明白如何设置颜色的渐变，或者是说将存储器上的不同区域着上不同的色。 其实从pyecharts的官方文档中，我只找到了一个设置颜色渐变的系列配置项，ItemStyleOpts，但是，我设置的时候老出问题，而且好像没有什么效果 先上python的代码（全局配置项当中的VisualMapOpts其实可以忽略，我当时是想设置颜色渐变的，但是没弄出来，所以把这一部分的代码去掉也是没有问题的）： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# author Morty# 2019-8-25# latest update 2019-11-17# python 3.6from pyecharts.charts import Surface3Dfrom pyecharts import options as opts class CreateMountain: def __init__(self): self.data_set = [] self.gragh = Surface3D() def data_process(self): with open(r\"C:\\Users\\54235\\Desktop\\m_data_set.txt\", \"r\") as f: data_set_origin = f.readlines() for line in data_set_origin: for index, item in enumerate(line.split(\"\\t\")[:-1], start=0): # index即为步长 # 【更新之后这段代码应当修改才对】 if index == 0: read_throughput = int(item[0:-1]) flag = item[-1] if flag == \"m\": read_throughput *= 1000000 elif flag == \"k\": read_throughput *= 1000 else: size = int(item) self.data_set.append([index, read_throughput, size]) def plot(self): self.data_process() self.gragh.add( # series name \"\", # 通过k*k循环展开测出来的数据集 data=self.data_set, # 三维图形的着色效果配置，realistic即为真实感渲染 shading=\"realistic\", # 图元配置项 itemstyle_opts=opts.ItemStyleOpts(), # 3D X坐标轴配置项 xaxis3d_opts=opts.Axis3DOpts( name=\"步长\", name_gap=40), # 3D Y坐标轴配置项 yaxis3d_opts=opts.Axis3DOpts( name=\"大小/B\", name_gap=40), # 3D Z坐标轴配置项 zaxis3d_opts=opts.Axis3DOpts( name=\"存储器读取速度MB/s\", name_gap=40), # 三维笛卡尔坐标系配置项 grid3d_opts=opts.Grid3DOpts( width=100, height=100, depth=100 ), ).set_global_opts( title_opts=opts.TitleOpts( title=\"Memory Mountain K*K Loop unrolling\", pos_left=\"center\", pos_top=90, ))).render() if __name__ == \"__main__\": c = CreateMountain() c.plot() 关于pyecharts，官方文档很友好，很容易阅读，中文文档的传送门：Pyecharts绘制结果如下：Tips:其实我对于这个绘制出来的结果非常的不自信，不知道是我设置的比例问题，还是因为我不会按照不同的区域来着色导致的视觉差的问题，同我理想当中的存储器山差距有点大，所以如果有热心的小伙伴知道我这是什么问题，或者说知道pyecharts怎么按照不同的区域来对曲面着色的话，请一定留言告诉我！我万分感激！ 【更新】2019/11/17 上面的问题解决了！其实这个问题早就解决了，只是一直忘了修改博客了。出现问题的原因在于大小/B的坐标轴，因为按照实际的大小（即测出来的真实值）作为坐标轴就会导致整个高速缓存紧缩在一起了，导致实际绘制渲染出来的图片与书本上的有所差异，其实想一想确实是自己蠢了，整个高速缓存的大小与内存相比无论如何都是没法比的，所以导致了上图那个90度直角的感觉，但是实际上仔细看还是能够看到存储器的分级的。如何解决？很简单，如果用真实的大小会导致缓存分级的部分紧缩在一堆，那么其实可以就用等间距的“假数据”把大小这个坐标轴给换掉，然后就能够突出缓存分级的区域了，最终效果图如下：","link":"/2019/11/17/Memory-mountain-for-Principle-of-program-locality/"},{"title":"MIT-6.828-LAB4 Preemptive Multitasking","text":"Contents# Part A : Multiprocessor Support and Cooperative Mutitasking Exercise 1 Exercise 2 Question Exercise 3 Exercise 4 Exercise 5 Question Exercise 6 : Round-Robin Scheduling Question Challenge : Extend More Complex Scheduling Policy Fixed-Priority Scheduler Exercise 7 Part B : Copy-on-Write Fork Exercise 8 Exercise 9 Exercise 10 Exercise 11 Exercise 12 Challenge : Implement Shared-Memory sfork Part C : Preemptive Multitasking and Inter-Process Communication(IPC) Exercise 13 Exercise 14 Exercise 15 TEST REFERENCES Part A:Multiprocessor Support and Cooperative Mutitasking# Exercise 1#在LAB4之前，所有的代码都是在同一个处理器上执行的，这个处理器一般叫做Bootstrap Processor(BSP)，BSP是哪个处理器是由BIOS和硬件共同决定的。在LAB4的一开始，我们要通过BSP来增加多处理器的支持，除了BSP之外的其它处理器一般叫做Application Processors(APs)。多处理器共享许多硬件资源，例如内存和I/O总线，但是也有许多硬件资源并不是共享的，例如LAPIC单元，TSS等寄存器，因此需要在BSP初始化好之后再初始化其它APs，当然，此时page等也不再需要初始化了（内存是共享的）。 在LAB4中的内存映射关系如下所示，可以和LAB3的内存映射关系对比来看: 代码很简单，值得注意的是，每个CPU都会调用一次mmio_map_region，因此base需要在每一次完成映射之后把值更新： 123456789101112void *mmio_map_region(physaddr_t pa, size_t size){ static uintptr_t base = MMIOBASE; size_t sizeUp = ROUNDUP(size, PGSIZE); if(sizeUp > (MMIOLIM - base))panic(\"reservation of mmio overflow MMIOLIM!\"); boot_map_region(kern_pgdir, base, sizeUp, pa, (PTE_PCD | PTE_PWT | PTE_W)); // test case in check_page below -check that they don't overlap-reminds me of that base is an static variable and // this function mmio_map_region might be invoked two or more times.See more details in check_page function below. base += sizeUp; return (void *)(base - sizeUp);} Exercise 2#BSP完成了初始化之后（kern/init.c:i386_init），就需要调用boot_aps来完成APs的初始化，这一部分的Control flow如下所示： 12345678+-----------------------+ +----------------------+| kern/init.c:i386_init |==>| kern/init.c:boot_aps |+-----------------------+ +----------------------+ | Pass control to kern/lapic.c:lapic_startap and switch to V the booted processor to execute rest code/instruction.+--------------------+ +------------------------------+| kern/init.c:mp_main|cpu_id, PADDR(code))之后，需要BSP不断自旋直到该APs初始化完毕的原因： 12345// kern/init.c:boot_aps// Start the CPU at mpentry_startlapic_startap(c->cpu_id, PADDR(code));// Wait for the CPU to finish some basic setup in mp_main()while(c->cpu_status != CPU_STARTED); 同样，这也是为什么在BSP执行boot_aps之前需要申请内核锁的原因： 12345678910111213141516171819voidmp_main(void){ // We are in high EIP now, safe to switch to kern_pgdir lcr3(PADDR(kern_pgdir)); cprintf(\"SMP: CPU %d starting\\n\", cpunum()); lapic_init(); env_init_percpu(); trap_init_percpu(); xchg(&thiscpu->cpu_status, CPU_STARTED); // tell boot_aps() we're up // Now that we have finished some basic setup, call sched_yield() // to start running processes on this CPU. But make sure that // only one CPU can enter the scheduler at a time! // lock_kernel(); sched_yield();} 从上面的代码可以看出，每个APs初始化完毕之后，使用xchg指令设置该CPU的状态为CPU_STARTED，来通知BSP该APs已经初始化完毕了，此时BSP就能够继续初始化下一个APs或者开始运行第一个User Environment，由于此时至少存在两个处理器是并行地运行，若不使用内核锁来确保同时只能有一个CPU执行一些关键的内核代码，就必然会产生并发错误，例如，在不使用内核锁的情况下，假设两个CPU同时进入了Scheduler，那么就可能导致两个CPU同时执行同一个User Environment的严重的并发错误，除此之外，创建Environment，分配Page等等都可能产生Race Condition，这显然不对。因此BSP在调用boot_aps之前必须申请kernel_lock，这样当所有APs还没初始化成功之前（即BSP的boot_aps还没返回之前）已完成初始化的APs都会被阻塞在mp_main的lock_kernel上，因为此时kernel_lock被BSP持有。 由于mpentry_start一开始将%DS，%ES，%SS设置为0，并且此时各种控制寄存器都尚未初始化，此时只能运行物理内存的低2^16字节地址上的代码，但是mpentry_start代码实际上属于内核代码，因此boot_aps才将mpentry_start这部分代码复制到MPENTRY_PADDR(0x7000)起始处（详情可看本文图 1-1）： 1memmove(code, mpentry_start, mpentry_end - mpentry_start); 正是需要将mpentry_start这部分代码复制到了MPENTRY_START的缘故，因此需要修改page_init，将mpentry_start这部分物理页标记为Not free，这也正是Exercise 2要我们做的： 1234567891011121314voidpage_init(void){ size_t i, extendedFree = PGNUM(PADDR(boot_alloc(0))); for(i = 0; i < npages; ++i){ pages[i].pp_ref = 0; if(i == 0 || (i >= npages_basemem && i < extendedFree) || i == PGNUM(MPENTRY_PADDR)){ pages[i].pp_link = NULL; }else{ pages[i].pp_link = page_free_list; page_free_list = &pages[i]; } }} Question# 1.Compare kern/mpentry.S side by side with boot/boot.S. Bearing in mind that kern/mpentry.S is compiled and linked to run above KERNBASE just like everything else in the kernel, what is the purpose of macro MPBOOTPHYS? Why is it necessary in kern/mpentry.S but not in boot/boot.S? In other words, what could go wrong if it were omitted in kern/mpentry.S? kern/mentry.S与boot/boot.S主要有以下两点区别： kern/mentry.S不需要使能A20； kern/mentry.S需要使用宏MPBOOTPHYS来计算它所引用的符号（symbol）的绝对地址而不是和boot/boot.S一样依赖于链接器（linker）。 正如前面所提到的，kern/mpentry.S实际上是内核代码，它们的地址都在KERNBASE之上，而mpentry.S作为APs的boot代码，运行在低地址，因此需要使用宏MPBOOTPHYS来计算绝对地址，随后执行mpentry.S时运行在实模式之下。 1#define MPBOOTPHYS(s) ((s) - mpentry_start + MPENTRY_PADDR) 但是在boot/boot.S这部分代码实际上是由BIOS直接加载到了物理地址0x7c00，因此不需要使用宏来计算绝对地址。简单来说就是kern/mpentry.S引用的符号对应的地址是虚拟地址，高于KERNBASE，因此若不使用MPBOOTPHYS计算绝对地址，直接把虚拟地址当成物理地址，那么必然会加载未知的物理内存数据，必然出错。 Exercise 3#每个CPU可以并行地进入Trap，因此必须需要为每个CPU设置独立的内核栈。 123456789static voidmem_init_mp(void){ uint32_t CPU_i = 0; for(;CPU_i < NCPU; ++CPU_i){ uintptr_t startVa = KSTACKTOP - CPU_i * (KSTKSIZE + KSTKGAP) - KSTKSIZE; boot_map_region(kern_pgdir, startVa, KSTKSIZE, PADDR(percpu_kstacks[CPU_i]), (PTE_W | PTE_P)); }} Exercise 4#由于每个CPU有着独立的内核栈，因此我们还需要修改每个CPU对应的TSS（Task State Segment）,并且将CPU对应的TSS descriptor写入到GDT中: 12345678910111213141516171819voidtrap_init_percpu(void){ // Setup a TSS so that we get the right stack when we trap to kernel. thiscpu->cpu_ts.ts_esp0 = KSTACKTOP - thiscpu->cpu_id * (KSTKSIZE + KSTKGAP); thiscpu->cpu_ts.ts_ss0 = GD_KD; thiscpu->cpu_ts.ts_iomb = sizeof(struct Taskstate); // Initialize the TSS slot of the gdt. gdt[(GD_TSS0 >> 3) + thiscpu->cpu_id] = SEG16(STS_T32A, (uint32_t)(&(thiscpu->cpu_ts)), sizeof(struct Taskstate) - 1, 0); gdt[(GD_TSS0 >> 3) + thiscpu->cpu_id].sd_s = 0; // Load the TSS selector (like other segment selectors, the // bottom three bits are special; we leave them 0) ltr(GD_TSS0 + 8 * thiscpu->cpu_id); // low 3 bits was special. // Load the IDT lidt(&idt_pd);} Exercise 5#从Exercise 2的讨论中，我们知道了在kern/init.c:i386_init中调用boot_aps之前BSP需要申请内核锁的原因是为了避免对内核一些关键资源的申请和分配产生错误，换而言之，后续从Kernel mode进入User mode时需要释放Kernel Lock，否则从一开始，所有的APs都会在mp_main中被阻塞，只有BSP一个CPU在做实际工作。另外，用户态也可以通过Trap陷入内核态，在执行关键内核代码之前，也需要申请Kernel Lock以避免并发错误。 因此，不考虑吞吐量和性能的前提条件下，在以下四个地方申请Kernel Lock或者释放Kernel Lock即可避免并发错误： In i386_init(), acquire the lock before the BSP wakes up the other CPUs. In mp_main(), acquire the lock after initializing the AP, and then call sched_yield() to start running environments on this AP. In trap(), acquire the lock when trapped from user mode. To determine whether a trap happened in user mode or in kernel mode, check the low bits of the tf_cs. In env_run(), release the lock right before switching to user mode. Do not do that too early or too late, otherwise you will experience races or deadlocks. 为什么在trap中可能需要申请Kernel Lock?在LAB3中我们设置的Trap Control Flow如下： 12345678+-----------------+ +------------------+ +-------------------------+ +---------------------------+|procedure or task|=>|processor hardware|=>|handler(kern/trapentry.S)|=>|_alltraps(kern/trapentry.S)|+-----------------+ +------------------+ +-------------------------+ +---------------------------+ | |+------------------+ +----------------------------+ +-------------------+ || handler function |tf_cs & 3) == 0){ panic(\":( Your kernel triger a page fault at va@0x%08x !Bad kernel\", fault_va); } // We've already handled kernel-mode exceptions, so if we get here, // the page fault happened in user mode. if(curenv->env_pgfault_upcall){ // exist env_pgfault_upcall. struct UTrapframe *utf; if(tf->tf_esp >= (UXSTACKTOP - PGSIZE) && tf->tf_esp tf_esp.We have to push a word // at the top of the trap-time stack as a scratch space. utf = (struct UTrapframe *)(tf->tf_esp - 4 - sizeof(struct UTrapframe)); }else{ utf = (struct UTrapframe *)(UXSTACKTOP- sizeof(struct UTrapframe)); } // 1.We have to check whether the environment allocate a page with permissions PTE_W for its exception // stack and whether the exception stack overflows. // 2.Set size to 1 is enough here,because the user environment exception stack's size is only on page, // user_mem_assert function will definitely fail as long as the utf's virtual address is already lower // than UXSTACKTOP-PGSIZE.Actually,any value between 1 and sizeof(struct UTrapFrame) is okay here. // 3.if user_mem_assert fail,this function will not return,just invoke env_destroy and sys_yield. user_mem_assert(curenv, (void *)utf, 1, PTE_W); // now we can construct UTrapFrame. utf->utf_esp = tf->tf_esp; utf->utf_eflags = tf->tf_eflags; utf->utf_eip = tf->tf_eip; utf->utf_regs = tf->tf_regs; utf->utf_err = tf->tf_err; utf->utf_fault_va = fault_va; // then branch to curenv->env_pgfault_upcall. curenv->env_tf.tf_eip = (uintptr_t)curenv->env_pgfault_upcall; // Don't forget set stack pointer. curenv->env_tf.tf_esp = (uintptr_t)utf; env_run(curenv); // never return. } // Destroy the environment that caused the fault. cprintf(\"[%08x] user fault va %08x ip %08x\\n\", curenv->env_id, fault_va, tf->tf_eip); print_trapframe(tf); env_destroy(curenv);} Exercise 10#主要完成恢复现场的工作，细节部分在Exercise 9中已经讨论，这里不再赘述： 123456789101112131415161718192021222324252627282930.text.globl _pgfault_upcall_pgfault_upcall: // Call the C page fault handler. pushl %esp // function argument: pointer to UTF movl _pgfault_handler, %eax call *%eax addl $4, %esp // pop function argument // Now the C page fault handler has returned and you must return // to the trap time state. // Push trap-time %eip onto the trap-time stack. movl 0x28(%esp), %eax // UTrapFrame.utf_eip subl $4, 0x30(%esp) // UTrapFrame.utf_esp - 4 movl 0x30(%esp), %edx // Set register %edx to UTrapFrame.utf_esp - 4 movl %eax, (%edx) addl $0x8, %esp // Set %esp to the end of struct PushRegs,see more details at inc/trap.h popal // Restore the trap-time registers.(struct PushRegs) addl $0x4, %esp // now we are located at trap-time eip,so we have to increment %esp with 4. popfl // Restore eflags register. popl %esp // Just restore the adjusted trap-time stack pointer. ret // We are now on the trap-time stack,since we have saved trap-time eip above // trap-time esp,ret instruction will pop this trap-time eip to register %eip // which known as PC at this time.Thus,we can return to re-execute the instruction // that faulted. Exercise 11#实现不难，篇幅有限，具体实现见Github:YanTang Qin的Master分支 Exercise 12#实现不难，篇幅有限，具体实现见Github:YanTang Qin的Master分支 Challenge : Implement Shared-Memory sfork#【注：我在实现这个时，已经完成了LAB4，所以我是用IPC测试的】除了User Normal Stack需要被标记为Copy-On-Write之外，实现上简单来想就只需要复制Address Space，并且把Parent Environment和Child Environment都标记上PTE_W权限应该就没问题了，但是除此之外，这里有一个trick，如果仅仅只是这样的实现，make run-pingpongs会发生死锁： 可以发现thisenv没有更新，最后Environment 1000不断尝试通过IPC向Environment 1001发送数据，同时，Environment 1000也标记自己需要接受数据，这必然产生死锁！其根本原因就在于sfork是共享内存的，也就意味着在pingpongs调用sfork时把thisenv指向了Child Environment之后，不管是在parent environment还是child environment中，thisenv都是一直指向Child Environment。 解决办法也很简单，修改lib/ipc.c中int32_t ipc_recv(envid_t *from_env_store, void *pg, int *perm_store)，在其调用完sys_ipc_recv之后修改thienv的指向就可以了： 1234567891011121314151617int32_tipc_recv(envid_t *from_env_store, void *pg, int *perm_store){ int error; if(!pg)pg = (void *)UTOP; // see more details in kern/syscall.c:sys_ipc_try_send and sys_ipc_recv. if((error = sys_ipc_recv(pg)) < 0){ if(from_env_store)*from_env_store = 0; if(perm_store)*perm_store = 0; return error; } thisenv = &envs[ENVX(sys_getenvid())]; // (*)for lab4's challenge sfork(). if(from_env_store)*from_env_store = thisenv->env_ipc_from; if(perm_store)*perm_store = thisenv->env_ipc_perm; return thisenv->env_ipc_value;} 对于普通fork，直接用thisenv不会出错，因为普通fork实现了Copy-On-Write机制，而sfork是共享内存，因此需要加上thisenv = &envs[ENVX(sys_getenvid())]才能确保IPC机制的正确性，但是不使用IPC时，parent environment调用sfork之后，thisenv指针也同样指向child environment，对此我没想到好的解决办法，因为是完全共享内存的，但是每次使用thisenv时，通过系统调用sys_getenvid来获得当前环境指针的方式是绝对不会出错的。 修改之后make run-pingpongs不再死锁，正常运行： 篇幅有限，sfork的具体实现见Github:YanTang Qin的Master分支。 Part C : Preemptive Multitasking and Inter-Process Communication(IPC)# Exercise 13#让JOS支持时钟中断，这样即便某个Environment没有自愿放弃CPU，也能够响应时钟中断从而Scheduler能够调度其它Environment运行，以防出现“饿死”的现象。 实现不难，篇幅有限，具体实现见Github:YanTang Qin的Master分支 但是千万记得要修改sched_halt()被注释掉的sti指令，这个疏漏导致我后来花了一个小时来排除bug！ Exercise 14#内核代码需要对时钟中断进行处理，调用之前实现的sched_yield即可： 1234if(tf->tf_trapno == (IRQ_OFFSET + IRQ_TIMER)){ lapic_eoi(); sched_yield();} Exercise 15#JOS实现IPC的方式是发送页面以及在struct Env中预留的一个可以存放需要传送的env_ipc_value： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657static intsys_ipc_try_send(envid_t envid, uint32_t value, void *srcva, unsigned perm){ struct Env *receiverEnv, *currentEnv; int32_t error, leastPerm = (PTE_U | PTE_P); // obtain current environment. envid2env(0, &currentEnv, 0); assert(currentEnv); // Environment envid doesn't currently exist. if((error = envid2env(envid, &receiverEnv, 0)) < 0)return error; // Envid is not currently blocked in sys_ipc_recv or another enviironment managed to send first. if(!receiverEnv->env_ipc_recving)return -E_IPC_NOT_RECV; // Need to send page currently mapped at 'srcva'. if((uintptr_t)srcva < UTOP){ struct PageInfo *pageInfo; pte_t *pte; // srcva is not page-aligned. if(((uintptr_t)srcva & (PGSIZE - 1)))return -E_INVAL; // Permissions deny. if((int32_t)(leastPerm & perm) != leastPerm || (perm & (~PTE_SYSCALL)))return -E_INVAL; // srcva is not mapped in the caller's address space. if(!(pageInfo = page_lookup(currentEnv->env_pgdir, srcva, &pte)))return -E_INVAL; // if(perm & PTE_W),but srcva is read-only in the current environment's address space. if((perm & PTE_W) && !((*pte) & PTE_W))return -E_INVAL; if((uintptr_t)receiverEnv->env_ipc_dstva < UTOP){ if((error = page_insert(receiverEnv->env_pgdir, pageInfo, receiverEnv->env_ipc_dstva, perm)) < 0)return error; } } // restore status. receiverEnv->env_ipc_recving = 0; receiverEnv->env_ipc_value = value; receiverEnv->env_ipc_from = currentEnv->env_id; receiverEnv->env_ipc_perm = perm; // Then we should mark the receiver environment as ENV_RUNNABLE. receiverEnv->env_status = ENV_RUNNABLE; // Return 0 from the paused sys_env_recv system call. // Howerver,the corresponding sys_ipc_recv function will never return,so we need to modify receiver's environment's trapframe. receiverEnv->env_tf.tf_regs.reg_eax = 0; // sys_ipc_try_send could return 0. return 0;}static intsys_ipc_recv(void *dstva){ if((uintptr_t)dstva < UTOP && (uintptr_t)dstva & (PGSIZE - 1))return -E_INVAL; // Willing wo receive a page of data. struct Env *currentEnv; envid2env(0, &currentEnv, 0); assert(currentEnv); currentEnv->env_status = ENV_NOT_RUNNABLE; currentEnv->env_ipc_recving = 1; currentEnv->env_ipc_dstva = dstva; sys_yield(); return 0; // eliminate compile error.} 并且需要实现lib中封装的ipc_send和ipc_recv: 12345678910111213141516171819202122232425262728293031int32_tipc_recv(envid_t *from_env_store, void *pg, int *perm_store){ int error; if(!pg)pg = (void *)UTOP; // see more details in kern/syscall.c:sys_ipc_try_send and sys_ipc_recv. if((error = sys_ipc_recv(pg)) < 0){ if(from_env_store)*from_env_store = 0; if(perm_store)*perm_store = 0; return error; } thisenv = &envs[ENVX(sys_getenvid())]; // for lab4's challenge sfork(). if(from_env_store)*from_env_store = thisenv->env_ipc_from; if(perm_store)*perm_store = thisenv->env_ipc_perm; return thisenv->env_ipc_value;}voidipc_send(envid_t to_env, uint32_t val, void *pg, int perm){ if(!pg)pg = (void *)UTOP; // see more details in kern/syscall.c:sys_ipc_try_send int error; // Keep trying until it succeeds. while((error = sys_ipc_try_send(to_env, val, pg, perm)) < 0){ if(error != -E_IPC_NOT_RECV){ panic(\"sys_ipc_try_send:%e\", error); } sys_yield(); // To be CPU-friendly. }} TEST# 1234567891011121314151617181920212223dumbfork: OK (1.8s) Part A score: 5/5faultread: OK (1.6s) faultwrite: OK (2.1s) faultdie: OK (3.8s) faultregs: OK (2.0s) faultalloc: OK (3.1s) faultallocbad: OK (1.9s) faultnostack: OK (2.2s) faultbadhandler: OK (2.2s) faultevilhandler: OK (2.0s) forktree: OK (2.1s) Part B score: 50/50spin: OK (1.9s) stresssched: OK (2.5s) sendpage: OK (1.6s) pingpong: OK (2.0s) primes: OK (5.4s) Part C score: 25/25Score: 80/80 REFERENCES#【1】 Intel® 64 and IA-32 Architectures Software Developer’s Manual【2】 Liedtke, Jochen. Improving IPC by kernel design[J]. ACM SIGOPS Operating Systems Review, 1993, 27(5):175-188.PDF","link":"/2020/01/24/MIT-6-828-LAB4-Preemptive-Multitasking/"},{"title":"MIT-6.828-LAB3 User Environments","text":"Contents# Part A:User Environments and Exception Handling Exercise 1 Exercise 2 Exercise 3 Exercise 4 Challenge Question Part B:Page Faults,Breakpoint Exceptions and System Calls Exercise 5 Exercise 6 Challenge Question Exercise 7 Exercise 8 Exercise 9 Exercise 10 TEST REFERENCES Part A:User Environments and Exception Handling# Exercise 1#同pages一样，需要在物理内存中为User Environments分配内存来保存Env信息，在Lab2中，在Boot Loader引导加载了内核数据以及代码之后，我们在其后给Kernel Page Directory和Page Info分配了物理内存。 Exercise1实际上就是完成了上图Environments内存的分配，并且将其映射到了图示位置，按道理来说，envs此时应该指向Environments的起始地址，但是由于boot_alloc()返回的是虚拟地址，即实际的物理地址+KERNBASE，因此envs对应的实际物理内存地址需要用宏PADDR(envs)得到。（在KERNBASE之上映射了从0开始的最多2GB的物理内存空间！）除此之外，还有几个细节部分： Kernel Page Directory的物理地址同样会保存在控制寄存器%cr3中，这样通过向%cr3控制寄存器写入不同的值，就能在User Page Directory和Kernel Page Directory之间切换了，并且能辅助实现用户环境的切换，因为正如许多操作系统课程所说，每个进程都会有一张独立的Page Directory，这也是后续的Exercise需要实现的。 Cur.Page Table是每个User Program独有的Page Table，也就是说，当创建一个environment时，会使用page_alloc()为该environment分配一页作为其独立的Page Table，并且将其映射到UVPT，同时将这种映射关系写入到每个environment独立的Page directory中，你可能注意到，并没有地方映射每个environment的Page directory，因此需要environment自己保留相应的page directory虚拟地址，在具体实现中就是Env结构体的env_pgdir指针了。 代码实现：为environment分配内存： 1envs = (struct Env *)boot_alloc(sizeof(struct Env) * NENV); 完成映射关系，写入kern_pgdir： 1boot_map_region(kern_pgdir, UENVS, PTSIZE, PADDR(envs), (PTE_U | PTE_P)); Exercise 2#首先将exercise 1中分配的environments组成链表，以便后续的env的创建和销毁： 123456789101112131415void env_init(void){ // Set up envs array env_free_list = envs; env_free_list->env_id = 0; struct Env *tail = envs, *start = envs + 1, *end = envs + NENV; for(;start < end; ++start){ tail->env_link = start; tail = tail->env_link; tail->env_id = 0; } // Per-CPU part of the initialization env_init_percpu();} 然后，正如上面所讨论的一样，需要每个environment维护一个独立的page directory，因此首先分配一页用来存储page directory，并且直接将kern page direcotyr复制过来，但是仅允许该environment对自己的page direcory有读取权限（除此之外，就是mem_init对user给与的权限，例如图1的READ-ONLY Pages和READ-ONLY ENVS） 1234567891011121314151617181920static int env_setup_vm(struct Env *e){ int i; struct PageInfo *p = NULL; // Allocate a page for the page directory if (!(p = page_alloc(ALLOC_ZERO))) return -E_NO_MEM; // Now, set e->env_pgdir and initialize the page directory. e->env_pgdir = (pde_t *)page2kva(p); memcpy(e->env_pgdir, kern_pgdir, PGSIZE); // Just copy the kern_pgdir because they are mostly the same. ++p->pp_ref; // UVPT maps the env's own page table read-only. // Permissions: kernel R, user R e->env_pgdir[PDX(UVPT)] = PADDR(e->env_pgdir) | PTE_P | PTE_U; return 0;} 随后实现region_alloc作用和boot_map_region很类似，但是除了按照指定的虚拟地址建立映射关系之外，还要按照指定的大小来分配页面。 123456789static void region_alloc(struct Env *e, void *va, size_t len){ void* end = ROUNDUP(va + len, PGSIZE); for(void *start = ROUNDDOWN(va, PGSIZE); start < end; start += PGSIZE){ struct PageInfo *pg = page_alloc(ALLOC_ZERO); if(!pg)panic(\"All pages were assigned!\"); page_insert(e->env_pgdir, pg, start, (PTE_W | PTE_U | PTE_P)); }} 有了region_alloc之后就能够完成load_code来完成可执行文件的加载了，但是现在还没实现文件系统，因此这里加载的是MIT提供的静态二进制文件而不是通常意义上的.o文件。这部分参考boot loader的实现即可： 1234567891011121314151617181920212223242526272829static void load_icode(struct Env *e, uint8_t *binary){ struct Proghdr *ph, *eph; struct Elf *elfHeader = (struct Elf*)binary; // is this a valid ELF? assert(elfHeader->e_magic == ELF_MAGIC); ph = (struct Proghdr *)(binary + elfHeader->e_phoff); eph = ph + elfHeader->e_phnum; lcr3(PADDR(e->env_pgdir)); // switch to this environment's address space.cr3 register must be physical address. for(; ph < eph; ++ph){ if(ph->p_type == ELF_PROG_LOAD){ // assert(ph->p_filesz p_memsz); region_alloc(e, (void *)ph->p_va, ph->p_memsz); memset((void *)ph->p_va, 0, ph->p_memsz); // cleard to zero memcpy((void *)ph->p_va, (void *)(binary + ph->p_offset), ph->p_filesz); // copy contents according to comments above. } } // set current trap frame's eip(PC) of this environment with elfHeader->e_entry to // make sure that the environment starts executing there. e->env_tf.tf_eip = elfHeader->e_entry; // Now map one page for the program's initial stack // at virtual address USTACKTOP - PGSIZE. region_alloc(e, (void *)(USTACKTOP - PGSIZE), PGSIZE); // map user stack. lcr3(PADDR(kern_pgdir)); // switch to kernel's address space.} 当具备了向用户环境中加载代码和数据的能力之后，就能完成environment的创建功能了，分配环境并加载代码和数据： 12345678910void env_create(uint8_t *binary, enum EnvType type){ struct Env *env; int32_t flag; if((flag = env_alloc(&env, (envid_t)0)) < 0){ panic(\"env_create:%e\", flag); } env->env_type = type; load_icode(env, binary); // restore this binary image to corresponding memory.} 最后实现env_run: 123456789101112void env_run(struct Env *e){ if(curenv && curenv->env_status == ENV_RUNNING){ // is a context switch. curenv->env_status = ENV_RUNNABLE; } curenv = e; curenv->env_status = ENV_RUNNING; ++curenv->env_runs; // update the times of the environment has run. lcr3(PADDR(curenv->env_pgdir)); // switch to this new environment's address space. env_pop_tf(&(curenv->env_tf)); // restore the environment's registers and drop into the user mode in the environment.} Exercise 3# Read Chapter 9, Exceptions and Interrupts in the 80386 Programmer’s Manual (or Chapter 5 of the IA-32 Developer’s Manual) 对Lab3最重要的 Exercise 4#正如exercise 3所讨论的，为了处理Interruption，我们需要设置IDT以及相应的Handler，并且为Handler传入它所需要的参数，并且保存现场，以便返回到被中断的Procedure或者Task，这部分给Handler传入的参数等实际上可通过Trapframe来访问。 1234567891011121314151617181920212223+------------------------------------------+ +---------------------------+| Interrupt Signal detected by processor's | Invoke corresponding handler | The Handler will push the | Each Handler will jump to _alltraps| hardware such as APIC(processor with on- | by Iterrupt vector and IDT | the interrupt vector | defined by kern/trapentry.S| chip local APIC),NMI pins or INTR pins. | ============================> | number onto kernel stack | ===================================>+------------------------------------------+ +---------------------------++-------------------------------------------+ +---------------------------+| _alltraps should push the rest necessary | _alltrps call trap function | trap will save some states| trap pass control to| arguments in struct Trapframe such as %ds | defined in kern/trap.c | such as trapframe. | trap_dispatch| %es and some registers. | ===========================> | | ====================>+-------------------------------------------+ +---------------------------++------------------------------------------------------------------------------------+| trap_dispatch invoke handler function(differs from the handler in trapentry.S) || we defined such as page_fault_handler in kern/trap.c and monitor in kern/monitor.c |+------------------------------------------------------------------------------------+*****************************************ABOVE ALL,below is a simple call flow:*****************************************+-----------------+ +------------------+ +-------------------------+ +---------------------------+ +-----------------+ +--------------------------+ +----------------+|procedure or task|=>|processor hardware|=>|handler(kern/trapentry.S)|=>|_alltraps(kern/trapentry.S)|=>|trap(kern/trap.c)|=>|trap_dispatch(kern/trap.c)|=>|handler function|+-----------------+ +------------------+ +-------------------------+ +---------------------------+ +-----------------+ +--------------------------+ +----------------+ 首先，为每个Interrupt vector编写相应的Handler，这里可以直接使用在trapentry.S中定义的宏，其中有两个宏，一个是不要error code的Interrupt，但是为了保持trapframe的格式一致性，需要存放一个值占位，这两个宏的作用都是直接定义Handler函数，.global的作用就是定义全局符号，这样才能在后续trap_init中绑定Interrupt vector和相应的Handler函数。至于哪些需要error code，哪些不需要，在IA-32 Developer’s mannual中写的很清楚。 12345678910111213141516171819202122232425.text// Exceptions without error code.TRAPHANDLER_NOEC(divideErrorHandler, T_DIVIDE);TRAPHANDLER_NOEC(debugHandler, T_DEBUG);TRAPHANDLER_NOEC(NMIHandler, T_NMI);TRAPHANDLER_NOEC(breakpointHandler, T_BRKPT);TRAPHANDLER_NOEC(overflowHandler, T_OFLOW);TRAPHANDLER_NOEC(BOUNDRangeExceededHandler, T_BOUND);TRAPHANDLER_NOEC(invalidOpcodeHandler, T_ILLOP);TRAPHANDLER_NOEC(deviceNotAvailableHandler, T_DEVICE);// Exceptions with error code.You can find this information in chapter 9.10 of 80386 programmer's references mannual.TRAPHANDLER(doubleFaultHandler, T_DBLFLT);// TRAPHANDLER_NOEC(coprocessorSegmentOverrunHandler, T_COPROC); reserved,just ignore.TRAPHANDLER(invalidTSSHandler, T_TSS);TRAPHANDLER(segmentNotPresentHandler, T_SEGNP);TRAPHANDLER(stackFaultHandler, T_STACK);TRAPHANDLER(generalProtectionHandler, T_GPFLT);TRAPHANDLER(pageFaultHandler, T_PGFLT);// Exceptions without error code.TRAPHANDLER_NOEC(floatingPointErrorHandler, T_FPERR);TRAPHANDLER_NOEC(alignmentCheckHandler, T_ALIGN);TRAPHANDLER_NOEC(machineCheckHandler, T_MCHK);TRAPHANDLER_NOEC(SIMDFloatingPointExceptionHandler, T_SIMDERR); 实现_alltraps汇编代码（因为这段代码对所有trap都一样，所以才将其剥离出来）： 1234567891011121314151617181920/* * Key point from lab reference: * 1. push values to make the stack look like a struct Trapframe; * 2. load GD_KD into %ds and %es; * 3. pushl %esp to pass a pointer to the Trapframe as an argument to trap(); * 4. call trap (can trap ever return?Yes); * According to inc/trap.h and the macro TRAPHANDLER,we can know that we should push %ds and %es register after * the tf_trapno because the tf_trapno was pushed onto stack by x86 hardware. * TIPS:pushal instruction will save all registers that trapframe need. */.global _alltraps_alltraps: pushl %ds pushl %es pushal movw $GD_KD, %ax movw %ax, %ds movw %ax, %es pushl %esp call trap 最后在kern/trap.c的trap_init中设置idt，绑定Interrupt vector和Handler(虽然我们在trapentry.S中定义了trap handler function，为了在trap.c中引用到这些handler，我们还需要在trap.c中声明这些函数签名，这样才能够在编译阶段做符号解析时才能不报错，或者声明在头文件中也可以)，这里暂时先将所有Gate的Descriptor privileged level设置为0（内核级）： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647voidtrap_init(void){ extern struct Segdesc gdt[]; // Generate corresponding exception handler function's signature. void divideErrorHandler(); void debugHandler(); void NMIHandler(); void breakpointHandler(); void overflowHandler(); void BOUNDRangeExceededHandler(); void invalidOpcodeHandler(); void deviceNotAvailableHandler(); void doubleFaultHandler(); void invalidTSSHandler(); void segmentNotPresentHandler(); void stackFaultHandler(); void generalProtectionHandler(); void pageFaultHandler(); void floatingPointErrorHandler(); void alignmentCheckHandler(); void machineCheckHandler(); void SIMDFloatingPointExceptionHandler(); // set IDT with macro SETGATE in inc/mmu.h SETGATE(idt[T_DIVIDE], 0, GD_KT, divideErrorHandler, 0); SETGATE(idt[T_DEBUG], 0, GD_KT, debugHandler, 0); SETGATE(idt[T_NMI], 0, GD_KT, NMIHandler, 0); SETGATE(idt[T_BRKPT], 0, GD_KT, breakpointHandler, 0); SETGATE(idt[T_OFLOW], 0, GD_KT, overflowHandler, 0); SETGATE(idt[T_BOUND], 0, GD_KT, BOUNDRangeExceededHandler, 0); SETGATE(idt[T_ILLOP], 0, GD_KT, invalidOpcodeHandler, 0); SETGATE(idt[T_DEVICE], 0, GD_KT, deviceNotAvailableHandler, 0); SETGATE(idt[T_DBLFLT], 0, GD_KT, doubleFaultHandler, 0); SETGATE(idt[T_TSS], 0, GD_KT, invalidTSSHandler, 0); SETGATE(idt[T_SEGNP], 0, GD_KT, segmentNotPresentHandler, 0); SETGATE(idt[T_STACK], 0, GD_KT, stackFaultHandler, 0); SETGATE(idt[T_GPFLT], 0, GD_KT, generalProtectionHandler, 0); SETGATE(idt[T_PGFLT], 0, GD_KT, pageFaultHandler, 0); SETGATE(idt[T_FPERR], 0, GD_KT, floatingPointErrorHandler, 0); SETGATE(idt[T_ALIGN], 0, GD_KT, alignmentCheckHandler, 0); SETGATE(idt[T_MCHK], 0, GD_KT, machineCheckHandler, 0); SETGATE(idt[T_SIMDERR], 0, GD_KT, SIMDFloatingPointExceptionHandler, 0); // Per-CPU setup trap_init_percpu();} Challenge# trap_init太多重复代码了，可以通过在trapentry.S中的.data节中定义一段内存来存储Gate相关参数，从而在trap_init函数中直接通过数组来获取这些参数，然后直接通过一个循环完成Interrupt vector和Handler的绑定。这里我一开始实现的时候，没有考虑太多，仅仅只存储了Handler的函数指针，因此导致后面exercise 7需要为系统调用添加Handler的时候，还是得额外写SETGATE，因此，建议可以多存储一些信息，例如Handler name以及Interrupt vector还有DPL。首先实现自己宏，实际就是添加了.data节用来存储数据。然后定义全局符号entryPointOfTraps以便后续在trap.c中引用数据。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/* * My own macro for exercise 4's chanllenge of lab3. */#define TRAPHANDLER_MINE(name, num) \\.data; \\ .long name; /* entry point's symbol */ \\.text; \\ .global name; /* define global symbol for 'name' */ \\ .type name, @function; /* symbol type is function */ \\ .align 2; /* align function definition */ \\name: /* function starts here */ \\ pushl $(num); \\ jmp _alltraps#define TRAPHANDLER_NOEC_MINE(name, num) \\.data; \\ .long name; \\.text; \\ .global name; /* define global symbol for 'name' */ \\ .type name, @function; /* symbol type is function */ \\ .align 2; /* align function definition */ \\name: /* function starts here */ \\ pushl $0; \\ pushl $(num); \\ jmp _alltraps.data .global entryPointOfTraps entryPointOfTraps:.text// Exceptions without error code.TRAPHANDLER_NOEC_MINE(divideErrorHandler, T_DIVIDE);TRAPHANDLER_NOEC_MINE(debugHandler, T_DEBUG);TRAPHANDLER_NOEC_MINE(NMIHandler, T_NMI);TRAPHANDLER_NOEC_MINE(breakpointHandler, T_BRKPT);TRAPHANDLER_NOEC_MINE(overflowHandler, T_OFLOW);TRAPHANDLER_NOEC_MINE(BOUNDRangeExceededHandler, T_BOUND);TRAPHANDLER_NOEC_MINE(invalidOpcodeHandler, T_ILLOP);TRAPHANDLER_NOEC_MINE(deviceNotAvailableHandler, T_DEVICE);TRAPHANDLER_MINE(doubleFaultHandler, T_DBLFLT);TRAPHANDLER_NOEC_MINE(coprocessorSegmentOverrunHandler, T_COPROC);// Just padding.TRAPHANDLER_MINE(invalidTSSHandler, T_TSS);TRAPHANDLER_MINE(segmentNotPresentHandler, T_SEGNP);TRAPHANDLER_MINE(stackFaultHandler, T_STACK);TRAPHANDLER_MINE(generalProtectionHandler, T_GPFLT);TRAPHANDLER_MINE(pageFaultHandler, T_PGFLT);TRAPHANDLER_MINE(reserved, T_RES); // Just padding.TRAPHANDLER_NOEC_MINE(floatingPointErrorHandler, T_FPERR);TRAPHANDLER_NOEC_MINE(alignmentCheckHandler, T_ALIGN);TRAPHANDLER_NOEC_MINE(machineCheckHandler, T_MCHK);TRAPHANDLER_NOEC_MINE(SIMDFloatingPointExceptionHandler, T_SIMDERR);TRAPHANDLER_NOEC_MINE(syscallHandler, T_SYSCALL); 随后trap.c中就可以直接用循环来设置idt了： 1234567891011121314151617voidtrap_init(void){ extern struct Segdesc gdt[]; extern void(*entryPointOfTraps[])(); int32_t i; for(i = 0; i < 20; ++i){ if(i == T_BRKPT){ SETGATE(idt[i], 0, GD_KT, entryPointOfTraps[i], 3); }else SETGATE(idt[i], 0, GD_KT, entryPointOfTraps[i], 0); } // set syscall gate SETGATE(idt[T_SYSCALL], 0, GD_KT, entryPointOfTraps[i], 3); // syscall entry was in index 20. // Per-CPU setup trap_init_percpu();} 【更新-2020/1/25】：由于之前的不合理考虑，后面的LAB4我增加了这里Challenge中保存的信息，方便后续的设置： 12345678910111213141516171819202122232425/* * My own macro for exercise 4's chanllenge of lab3. */#define TRAPHANDLER_MINE(name, num) \\.data; \\ .long name, num; /* entry point's symbol */ \\.text; \\ .global name; /* define global symbol for 'name' */ \\ .type name, @function; /* symbol type is function */ \\ .align 2; /* align function definition */ \\name: /* function starts here */ \\ pushl $(num); \\ jmp _alltraps#define TRAPHANDLER_NOEC_MINE(name, num) \\.data; \\ .long name, num; \\.text; \\ .global name; /* define global symbol for 'name' */ \\ .type name, @function; /* symbol type is function */ \\ .align 2; /* align function definition */ \\name: /* function starts here */ \\ pushl $0; \\ pushl $(num); \\ jmp _alltraps 可以看到实际上就是增加了Exception Vector的存储。后续在kern/trap.c中初始化trap handler: 123456789101112131415voidtrap_init(void){ extern struct Segdesc gdt[]; extern long *entryPointOfTraps[2]; int32_t i; for(i = 0; i tf_trapno){ case T_PGFLT:page_fault_handler(tf);return; case T_BRKPT:monitor(tf);return; case T_DEBUG:monitor_debug(tf);return; case T_SYSCALL:{ tf->tf_regs.reg_eax = syscall(tf->tf_regs.reg_eax, tf->tf_regs.reg_edx, tf->tf_regs.reg_ecx, tf->tf_regs.reg_ebx, tf->tf_regs.reg_edi, tf->tf_regs.reg_esi); return; } default:break; } // Unexpected trap: The user process or the kernel has a bug. print_trapframe(tf); if (tf->tf_cs == GD_KT) panic(\"unhandled trap in kernel\"); else { env_destroy(curenv); return; }} 上面的代码直接将后续的Exercise都放上去了，对于Exercise 5，只需要添加case T_PGFLT即可。然后修改page_fault_handler即可： 123456789101112131415161718192021void page_fault_handler(struct Trapframe *tf){ uint32_t fault_va; // Read processor's CR2 register to find the faulting address fault_va = rcr2(); // Handle kernel-mode page faults.Beacuse it should never triger page fault in kernel-mode,just panic! if((tf->tf_cs & 3) == 0){ panic(\"Your kernel triger a page fault!Bad kernel:(\"); } // We've already handled kernel-mode exceptions, so if we get here, // the page fault happened in user mode. // Destroy the environment that caused the fault. cprintf(\"[%08x] user fault va %08x ip %08x\\n\", curenv->env_id, fault_va, tf->tf_eip); print_trapframe(tf); env_destroy(curenv);} 内核态之下是绝对不可能触发page fault的! Exercise 6#实现已经在Exercise 5中了。如果make grade在breakpoint test case上失败了，那么可以通过make run-breakpoint或者make run-breakpoint-nox来执行user/breakpoint.c来进行调试。 Challenge#这个Challenge让我们修改monitor从而实现单步调试的功能，根据提示，查阅Intel IA-32 developer’s manual： 【Intel IA-32 developer’s manual:2.3】TF Trap(bit 8)-Set to enablesingle-step mode for debugging;clear to disable single-step mode.In single-step mode,the processor generates a debug exception after each instruction.This allows the execution state of a program to be inspected after each instruction. 这样，就有思路了。触发Breakpoint exception进入monitor之后，需要设置EFLAGS寄存器值的TF位（在实际实现中就是修改trapframe的tf_eflags），随后退出monitor，将控制权交还给被该Breakpoint exception中断的procedure或task，因为将控制权交还给用户程序时，也会把进入中断处理程序时保存的eflags寄存器的值恢复到EFLAGS寄存器之中，而我们在monitor中修改了所保存的eflags寄存器值的TF位，这样后续用户程序再执行一条指令，就会触发Debug Exception，因此，我们还需要修改trap_dispatch，使其能够对Debug Exception进行处理，此时只需要让处理程序继续设置一次TF位然后又返回，这样不断往复，就能够实现逐步调试的功能了。以下是我的实现的简易Call flow: 123456789101112131415161718 +-----------------------------+ +-----------------+ +-----------+ set TF bit |monitor_debug(kern/monitor.c)|==>|run_cmd(buf,tf,1)|==>|debug_stepi|===========> +-----------------------------+ +-----------------+ +-----------+ | ^ | | T_DEBUG | | |+-----------------+ *** +-------------+ T_BRKPT +-----------------------+ +-----------------+ ||procedure or task|====>|trap_dispatch|=========>|monitor(kern/monitor.c)|==>|run_cmd(buf,tf,0)|========|=====+-----------------+ +-------------+ +-----------------------+ +-----------------+ | | ^ | | | Return Control to procefure. | | |mon_intoDebugMode(kern/monitor.c)|==>|run_cmd(buf,tf,1)|==>|debug_stepi|============>tf_trapno == T_BRKPT || tf->tf_trapno == T_DEBUG){ tf->tf_eflags |= FL_TF; // Set EFLAGS register with Trap flag which is a control flag. }else{ cprintf(\"You can only use stepi when the processor encounter Debug or Breakpoint exceptions.\\n\"); } return -1; // must return -1 because we should leave monitor and let user program proceed.}int debug_continue(int argc, char **argv, struct Trapframe *tf){ if(tf->tf_trapno == T_BRKPT || tf->tf_trapno == T_DEBUG){ tf->tf_eflags &= ~FL_TF; } return -1;} Question# 3.The break point test case will either generate a break point exception or a general protection fault depending on how you initialized the break point entry in the IDT (i.e., your call to SETGATE from trap_init). Why? How do you need to set it up in order to get the breakpoint exception to work as specified above and what incorrect setup would cause it to trigger a general protection fault? 事实上，答案已经在上面的Question中的2讨论过了，若想要使其正常工作，就需要CPL tf_cs & 3) == 0){ panic(\":( Your kernel triger a page fault at va@0x%08x !Bad kernel\", fault_va); } // We've already handled kernel-mode exceptions, so if we get here, // the page fault happened in user mode. // Destroy the environment that caused the fault. cprintf(\"[%08x] user fault va %08x ip %08x\\n\", curenv->env_id, fault_va, tf->tf_eip); print_trapframe(tf); env_destroy(curenv);} 最后就是内存访问权限的校验函数的实现，这部分有点坑，后面花了我很多时间找这个bug，如果不是我在写这部分的时候，就注释了我对这里理解可能有问题的话，可能会花更多时间： 12345678910111213141516171819202122int user_mem_check(struct Env *env, const void *va, size_t len, int perm){ // LAB 3: Your code here. uintptr_t startVa = ROUNDDOWN((uintptr_t)va, PGSIZE), endVa = ROUNDUP((uintptr_t)(va + len), PGSIZE); pte_t *pte; struct PageInfo *pageInfo; uint32_t permissions = perm | PTE_P; for(; startVa < endVa; startVa += PGSIZE){ pageInfo = page_lookup(env->env_pgdir, (void *)startVa, &pte); if(!pageInfo || startVa > (uintptr_t)ULIM || ((*pte) & permissions) != permissions){ // cprintf(\"startVa=>0x%08x vaFromPte=>0x%08x *pte=>0x%08x\\n\", startVa, KADDR(PTE_ADDR(*pte)), *pte); // if there is an error,set the 'user_mem_check_addr' variable to the first erroneous virtual address. // :( well,sorry I can't really understand the meaning of \"first erroneous virtual address.\" // Holy shit,this takes me really a lot of time to fix this bug to pass the whole test cases. user_mem_check_addr = (startVa < (uintptr_t)va?(uintptr_t)va:startVa); return -E_FAULT; } } return 0;} 此时运行make run-breakpoint并且调用backtrace后会触发page fault: 1234567891011121314151617K> backtrace'ebp efffff00 eip f01008fd args 00000001 efffff28 f01b4000 0a100188 f0105d53 kern/monitor.c:268: runcmd+-267384840ebp efffff80 eip f0100c03 args 00000002 00000000 efffffb0 f0103821 f01b4000 kern/monitor.c:289: monitor+-267383888ebp efffff90 eip f0103821 args f01b4000 efffffbc 00000000 00000082 00000000 kern/trap.c:203: trap+-267372692ebp efffffb0 eip f0103943 args efffffbc 00000000 00000000 eebfdfd0 efffffdc kern/syscall.c:69: syscall+-267372221ebp eebfdfd0 eip 800073 args 00000000 00000000 eebfdff0 00800049 00000000 lib/libmain.c:26: libmain+8388665Incoming TRAP frame at 0xeffffe8ckernel panic at kern/trap.c:271: :( Your kernel triger a page fault at va@0xeebfe008 !Bad kernelK> showMappings 0xeebfe008 0xeebfe008va@start: eebfe000 va@end: eebff000va@page: eebfe000 pa@page: 00000000 @perm:PTE_P 0 PTE_U 0 PTE_W 0; showMappings的其它值都不重要，可以看到0xeebfe008对应的页的起始地址为0xeebfe000，而在memlayout.h中标明了0xeebfe000为USTACKTOP，也就是说backtrace最后触发page fault就是因为其尝试访问高于USTACKTOP的地址了。 Exercise 10#make run-evilhello，如果这个test case无法通过，可能就是上面的user_mem_check那里那个比较坑的地方不对。 TEST# 123456789101112131415161718divzero: OK (2.0s) softint: OK (0.8s) badsegment: OK (1.0s) Part A score: 30/30faultread: OK (2.0s) faultreadkernel: OK (1.0s) faultwrite: OK (1.9s) faultwritekernel: OK (1.2s) breakpoint: OK (1.8s) testbss: OK (2.3s) hello: OK (1.0s) buggyhello: OK (1.7s) buggyhello2: OK (2.5s) evilhello: OK (2.0s) Part B score: 50/50Score: 80/80 REFERENCES#【1】 Intel 80386 Reference Programmer’s Manual【2】 Intel® 64 and IA-32 Architectures Software Developer’s Manual【3】 XV6 - a simple, Unix-like teaching operating system - Reference Book【4】 《Computer Systems: A Programmer’s Perspective (3rd Edition)》.Randal E.Bryant / David O’Hallaron.【5】 《Modern Opeation Systems (Fourth Edition)》.Andrew S.Tanenbaum / Herbert Bos.","link":"/2020/01/16/MIT-6-828-LAB3-User-Environments/"},{"title":"MIT-6.828-LAB5 File system,Spawn and Shell","text":"Contents# File system preliminaries Block Layout and struct File Design Philosophy of File System The File System Exercise 1 - Disk Access Question Exercise 2 - The Block Cache Challenge - Block Eviction Policy Exercise 3 - The Block Bitmap Exercise 4 - File Operations Exercise 5, 6 - The File System Interface Spawning Process Exercise 7 - Implement spawn Challenge - Implement Unix-style exec Exercise 8 - Sharing library state across fork and spawn The keyboard interface Exercise 9 - Responsing to externel interrupt Shell Exercise 10 - Implement I/O redirection REFERENCES File system preliminaries# Block Layout and struct File#JOS kernel实现的是简化版文件系统，相较于常规文件系统FILE-INODE(META DATA)-BLOCKS的模式，JOS kernel直接使用file的meta data来记录该文件所占用的Blocks信息，即FILE(META DATA)-BLOCKS的模式： struct File也存储在磁盘上，需要找到一个特定的File，就得有一个根File，它能够直接被文件系统获取而不用查找，这个根目录记录在Super Block，在具体实现中，编号为1的Block作为Super Block（Block 0存储boot loader，文件系统不使用block 0），除此之外，还需要记录每个Block的使用情况，将Block 2作为bitmap用来记录Block的占用空闲情况： JOS kernel直接将磁盘至多3GB空间直接加载到内存当中，并且将其映射到线性地址空间DISKMAP ~ DISKMAP + 3GB，换而言之，在文件系统的地址空间中，DISKMAP ~ DISKMAP + 3GB就是磁盘内容，这部分只有文件系统能够访问，不会与其它User Environment共享，并且由于文件系统地址空间中的Block与磁盘内容直接映射，因此能够直接直接通过线性地址计算出Block Number，从而找到需要加载的Sector，例如线性地址va，其对应的BLock Number为(va - DISKMAP) / PGSIZE，相应地，如果文件系统在va产生了page fault，就需要加载磁盘sector编号为BLKSECTORS * (va - DISKMAP) / PGSIZE为起始sector的共BLKSECTORS个sector即可。在JOS的文件系统中，Block size是4096 bytes，因此BLKSECTORS是4096 / 512 = 8。 Design Philosophy of File System#实际操作系统将文件系统作为内核代码实现，因此进程调用文件系统接口最终都会陷入内核态来处理，然而，在JOS中，整个文件系统本质上是一个特殊的User Environment，Normal User Environment调用的文件系统接口是通过IPC实现。换而言之，可以将JOS的文件系统看作一个Server，而Normal User Environment都是Client，Client通过IPC向Server发送请求，而Server则始终准备着接受来自Client的请求。 文件系统是JOS运行的第一个Environment，在kern/init.c:i386_init中直接创建文件系统。文件系统的main入口函数在fs/serv.c中，它完成的主要工作是： fs/serv.c:serve_init - openfile table的初始化，以及file descriptor的地址划分。 fs/fs.c:fs_init - 调用fs/bc.c:bc_init，校验Super Block和bitmap Block的合法性并记录它们的虚拟地址到全局变量super和bitmap。 fs/bc.c:bc_init - 正如Block Layout and struct File中所讨论的一样，当我们知晓了需要加载的Block的虚拟地址va之后，就能够得到它对应的Block Number为(va - DISKMAP) / PGSIZE，相应地，该虚拟地址对应地page就需要从disk中加载serctor编号为BLKSECTORS * (va - DISKMAP) / PGSIZE到BLKSECTORS * (va - DISKMAP) / PGSIZE + BLKSECTORS的sector到内存。因此我们需要设置page fault handler，就像我们在实现fork中做的一样。除此之外，bc.c还需要完成Super Block和bitmap Block的初始化。 fs/serv.c:serve - 接受Regular User Environment发送的请求，并且调用相应的handler来处理请求，再返回响应。但是文件系统同一时间只能够处理一个请求，效率不高。可以考虑多几个File system environment，但是这样需要对一些资源加锁，例如File descriptor，openfile table等，从而避免并发错误。 在提供给用户使用的接口方面，统一接口在lib/fd.c中，同时JOS将一些子系统抽象成Device，例如File Device，Pipe Device以及后面需要实现的Network Driver，Dev结构体包括了Dev id以及相应的处理函数指针: 123456789struct Dev { int dev_id; const char *dev_name; ssize_t (*dev_read)(struct Fd *fd, void *buf, size_t len); ssize_t (*dev_write)(struct Fd *fd, const void *buf, size_t len); int (*dev_close)(struct Fd *fd); int (*dev_stat)(struct Fd *fd, struct Stat *stat); int (*dev_trunc)(struct Fd *fd, off_t length);}; 通过Devices的抽象以及File Descriptor，统一了用户接口（在lib/fd.c中），并且提供了高度的可定制性和可插拔性。我绘制了一个示意图，Client与Server端都划分了三层： 注解： USER API - lib/fd.c DEVICE - For instance - devfile:lib/file.c; devpipe:lib/pipe.c; devcons:lib/console.c IPC - lib/ipc.c SERVER - fs/serv.c FILE SYSTEM - fs/fs.c 以devfile的read操作为例，其Control flow如下所示： 12345678910111213141516171819 Regular env FS env +---------------+ +---------------+ | read | | file_read | | (lib/fd.c) | | (fs/fs.c) |...|.......|.......|...|.......^.......|............... | v | | | | RPC mechanism | devfile_read | | serve_read | | (lib/file.c) | | (fs/serv.c) | | | | | ^ | | v | | | | | fsipc | | serve | | (lib/file.c) | | (fs/serv.c) | | | | | ^ | | v | | | | | ipc_send | | ipc_recv | | | | | ^ | +-------|-------+ +-------|-------+ | | +-------------------+ 任何操作都是通过File Descriptor作为媒介来实现的，并且File Descriptor是File System Environment与Regular User Environment共享的： 123456789struct Fd { int fd_dev_id; off_t fd_offset; int fd_omode; union { // File server files struct FdFile fd_file; };}; 通过Fd的dev_id能够找到相应的Devices，并且调用其处理函数，而fd_file则是OpenFile的索引，控制最终转移到File system时，能够通过fd_file拿到OpenFile，而OpenFile结构体中保留了File指针，在File System Environment的地址空间中，能通过该File指针获取到相应的struct File的引用： 123456struct OpenFile { uint32_t o_fileid; // file id struct File *o_file; // mapped descriptor for open file int o_mode; // open mode struct Fd *o_fd; // Fd page}; 文件系统环境和Regular User Environment之间的结构如下所示： The File System# Exercise 1 - Disk Access#正如上面所讨论的，文件系统是JOS创建的第一个environment，为了将其与Regular user environment区别，需要将其类型设置为ENV_TYPE_FS： 1ENV_CREATE(fs_fs, ENV_TYPE_FS); 并且需要为其赋予I/O权限: 123456789101112131415voidenv_create(uint8_t *binary, enum EnvType type){ struct Env *env; int32_t flag; if((flag = env_alloc(&env, (envid_t)0)) < 0){ panic(\"env_create:%e\", flag); } env->env_type = type; // If this is the file server (type == ENV_TYPE_FS) give it I/O privileges. if(type == ENV_TYPE_FS){ env->env_tf.tf_eflags |= FL_IOPL_3; } load_icode(env, binary); // restore this binary image to corresponding memory.} Question# 1.Do you have to do anything else to ensure that this I/O privilege setting is saved and restored properly when you subsequently switch from one environment to another? Why? 当然不用，eflags寄存器也会在发生switch的时候自动保存到env->env_tf中。即trap时会自动保存这些寄存器的值。 Exercise 2 - The Block Cache#设置page fault handler以便能够从disk加载fault va对应的Block到内存： 1234567891011121314151617181920212223242526272829303132333435static voidbc_pgfault(struct UTrapframe *utf){ void *addr = (void *) utf->utf_fault_va; uint32_t blockno = ((uint32_t)addr - DISKMAP) / BLKSIZE; int r; // Check that the fault was within the block cache region if (addr < (void*)DISKMAP || addr >= (void*)(DISKMAP + DISKSIZE)) panic(\"page fault in FS: eip %08x, va %08x, err %04x\", utf->utf_eip, addr, utf->utf_err); // Sanity check the block number. if (super && blockno >= super->s_nblocks) panic(\"reading non-existent block %08x\\n\", blockno); // Allocate a page in the disk map region, read the contents // of the block from the disk into that page. addr = (void *)ROUNDDOWN((uintptr_t)addr, PGSIZE); if((r = sys_page_alloc(0, addr, (PTE_U | PTE_P | PTE_W))) < 0){ panic(\"sys_page_alloc:%e\", r); } if((r = ide_read(blockno * BLKSECTS, addr, BLKSECTS)) < 0){ panic(\"ide_read:%e\", r); } // Clear the dirty bit for the disk block page since we just read the // block from disk if ((r = sys_page_map(0, addr, 0, addr, uvpt[PGNUM(addr)] & PTE_SYSCALL)) < 0) panic(\"in bc_pgfault, sys_page_map: %e\", r); // Check that the block we read was allocated. if (bitmap && block_is_free(blockno)) panic(\"reading free block %08x\\n\", blockno);} 实现flush_block以便能够将内存中的Block同步回DISK，达到数据持久化的效果： 123456789101112131415161718192021222324voidflush_block(void *addr){ uint32_t blockno = ((uint32_t)addr - DISKMAP) / BLKSIZE; int r; if (addr < (void*)DISKMAP || addr >= (void*)(DISKMAP + DISKSIZE)) panic(\"flush_block of bad va %08x\", addr); // LAB 5: Your code here. addr = (void *)ROUNDDOWN((uintptr_t)addr, PGSIZE); // If the block isn't in the block cache,just not do anything. if(!va_is_mapped(addr) || !va_is_dirty(addr))return; // bit dirty was set,we should write it back to dist. if((r = ide_write(blockno * BLKSECTS, addr, BLKSECTS)) < 0){ panic(\"ide_write:%e\", r); } // After we write back this dirty block to disk,we should clear the PTE_D bit. if((r = sys_page_map(0, addr, 0, addr, uvpt[PGNUM(addr)] & PTE_SYSCALL)) < 0){ panic(\"int flush_block, sys_page_map:%e\", r); }} Challenge - Block Eviction Policy#实现起来倒不难，但是我着实没明白PTE_A和dirty Block不是相互矛盾的吗，如果是dirty block，它的PTE_A也必然被设置了呀。其实JOS压根就不需要Eviction Policy，因为JOS的文件系统与DISK是一对一的，不存在Block满了之后，还能加载新的Block的情况，但是也可以说是为了不让文件系统占用过多的物理内存。我实现的仅仅是释放掉没有被访问过的Block的超简单策略： 12345678910111213141516171819202122232425262728293031323334353637383940// lab 5's challenge : implement eviction policy for block cache.voidevict_block_force(void *addr){ uint32_t blockno = ((uint32_t)addr - DISKMAP) / BLKSIZE; int r; if(addr < (void *)DISKMAP || addr >= (void *)(DISKMAP + DISKSIZE)){ panic(\"evict_block_force of bad va %08x\", addr); } // ignore boot sector,super block and bitmap block. // if the block isn't in the block cache,just not do anything. if(blockno s_nblocks blocks in the disk altogether. uint32_t i; for(i = 0; i < super->s_nblocks; ++i){ if(block_is_free(i)){ bitmap[i / 32] &= ~(1 = NDIRECT + NINDIRECT)return -E_INVAL; if(filebno < NDIRECT){ *ppdiskbno = f->f_direct + filebno; return 0; } if(!(f->f_indirect)){ // get here means that we need to allocate an indirect block, // but alloc was 0. if(!alloc)return -E_NOT_FOUND; // Now we could allocate an indirect block by using alloc_block. if((blockno = alloc_block()) < 0)return -E_NO_DISK; f->f_indirect = blockno; // claer the block we allocated above. memset(diskaddr(f->f_indirect), 0, BLKSIZE); flush_block(diskaddr(f->f_indirect)); } // There is a trick:f->f_indirect is an block number while f->direct is an virtual address. // That's why we need to convert f->f_indirect to virtual address firstly. *ppdiskbno = ((uint32_t *)diskaddr(f->f_indirect)) + (filebno - NDIRECT); return 0;} 以及通过索引返回该索引对应的block虚拟地址，注意这个索引是相对于这个特定的File而言的： 12345678910111213141516intfile_get_block(struct File *f, uint32_t filebno, char **blk){ int r; uint32_t *ppdiskno; // value of r might be 0, -E_INVAL, -E_NO_DISK. if((r = file_block_walk(f, filebno, &ppdiskno, 1)) < 0)return r; // *ppdiskno is zero means that we should allocate a blobk. if(!(*ppdiskno)){ if((r = alloc_block()) < 0)return -E_NO_DISK; *ppdiskno = r; } *blk = (char *)diskaddr(*ppdiskno); return 0;} Exercise 5, 6 - The File System Interface#Exercise 5,6实际上就是实现图1-3所示的SERVER层的handler function，它需要调用File System提供的接口才能完成功能： 12345678910111213141516171819202122232425262728293031intserve_read(envid_t envid, union Fsipc *ipc){ struct Fsreq_read *req = &ipc->read; struct Fsret_read *ret = &ipc->readRet; if (debug) cprintf(\"serve_read %08x %08x %08x\\n\", envid, req->req_fileid, req->req_n); struct OpenFile *openFile; int r; if((r = openfile_lookup(envid, req->req_fileid, &openFile)) < 0)return r; if((r = file_read(openFile->o_file, ret->ret_buf, req->req_n, openFile->o_fd->fd_offset)) < 0)return r; openFile->o_fd->fd_offset += r; return r;}intserve_write(envid_t envid, struct Fsreq_write *req){ if (debug) cprintf(\"serve_write %08x %08x %08x\\n\", envid, req->req_fileid, req->req_n); struct OpenFile *openFile; int r, t = 0; if((r = openfile_lookup(envid, req->req_fileid, &openFile)) < 0)return r; t = req->req_n > PGSIZE?PGSIZE:req->req_n; if((r = file_write(openFile->o_file, req->req_buf, t, openFile->o_fd->fd_offset)) < 0)return r; openFile->o_fd->fd_offset += r; return r;} Spawning Process# Exercise 7 - Implement spawn#spawn由parent environment为child environment进行初始化，因此不会有任何问题，但是要在用户态下实现Unix-style exec是很有难度的。 12345678910111213141516171819static intsys_env_set_trapframe(envid_t envid, struct Trapframe *tf){ // Remember to check whether the user has supplied us with a good // address! struct Env *theEnv; if(envid2env(envid, &theEnv, 1) < 0)return -E_BAD_ENV; // cprintf(\"this tf va@0x%p\\n\", tf); user_mem_assert(theEnv, tf, sizeof(struct Trapframe), PTE_U); // Clear IOPL bits. tf->tf_eflags &= ~FL_IOPL_MASK; // Interrupts enabled. tf->tf_eflags |= FL_IF; // code protection level 3(CPL 3). tf->tf_cs |= GD_UT | 3; // set envid's trap frame to tf. theEnv->env_tf = *tf; return 0;} 其实这里我卡了很久，就是faultio测试用例无法通过，我确实花了非常多的时间来定位bug，解决bug，最后发现是问题在于CPU的Task State Segment设置有一点问题，我没有设置TSS的IO permission bit map的偏移量，从而产生问题。 I/O map base address field-contains a 16-bit offset from the base of the TSS to the I/O permission bit map and interrupt redirection bitmap.When present,these maps are stored in the TSS at the higher addresses.The I/O map base address points to the beginning of the I/O permission bit map and the end of the interrupt redirection bit map.See Chapter 13,”Input/Output,”in the Intel 64 and IA-32 Architectures Software Developer’s Manual,Volume 1,for more information about the I/O permission bit map.See Section 15.3,”Interrupt and Exception Handling in Virtual-8086 Mode,”for a detailed description of the interrupt redirection bit map. 换而言之，这个bug就是I/O Map Base设置为0所导致的，因此，解决这个bug只需要将I/O Base设置为sizof(struct Taskstate)即可： 修复I/O permission的bug，在trap_init_percpu(kern/trap.c)中设置: 1thiscpu->cpu_ts.ts_iomb = sizeof(struct Taskstate); Challenge - Implement Unix-style exec#在用户环境中实现exec的难点在哪里？我们需要做些什么？ 难点就是我们不能够直接将需要加载的代码和数据映射到当前Environment正在使用的虚拟页面上，如果这么做了，后续exec的代码就无法执行了，因为映射关系改变了，处理器执行指令进行地址转换的时候，会定位到未知的地方。因此我们需要找到一个暂存空间，将exec需要加载的代码和数据加载到这个暂存空间，然后通过系统调用陷入内核态，让内核代码为该执行exec的Environment完成最终代码和数据的装载（或者说新的内存映射）。总而言之，两个关键点，一是预留一个暂存空间用来临时存储exec需要装载的数据和代码，二是最终需要实现一个系统调用完成最终代码和数据的装载或者说新的内存映射（可以考虑在系统调用中用memmove直接将暂存空间的内容复制到调用exec的Environment的相应的地方） 上面是我的初始想法，实现了一版之后，出现了许多很难解决的问题，于是我参考了xv6的内核态下实现exec的流程，最终成功完成了这个challenge。原理简单来说就是创建临时的page directory，随后将exec指定的内容加载到内存并且映射到这个临时的page directory，完成装载之后再替换page directory并且释放旧的page directory，page table以及相应的page。 实现主要通过三个核心的系统调用： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127// allocate a new page as this environmnt's page directory and map// it to va temporarily.static intsys_exec_alloc_pgdir(void *va){ struct Env *currentEnv; struct PageInfo *pageInfo = NULL; pde_t *new_pgdir; envid2env(0, &currentEnv, 1); assert(currentEnv); // step 1) we should check that whether the page correspondingly to pgdir_temp // is present or not.At the same time,we have to ensure that the virtual // address va is page-aligned. if(((uintptr_t)va & (PGSIZE - 1)) || page_lookup(currentEnv->env_pgdir, va, NULL)){ cprintf(\"[DEBUG]sys_exec_alloc_pgdir:va is now mapped or va was not page aligned.\\n\"); return -E_INVAL; } // step 2) allocate a new page as this environment's page directory. if(!(pageInfo = page_alloc(ALLOC_ZERO))){ return -E_NO_MEM; } // step 3) map the new page to va temporarily. if(page_insert(currentEnv->env_pgdir, pageInfo, va, (PTE_W | PTE_P | PTE_U)) < 0){ return -E_NO_MEM; } // step 4) copy this environment's old pgdir here just like what we have done before. // Don't forget to increment its ref counter. // Most importantly,it's necessary switch page directory for that we are now // in kernel mode. //cprintf(\"[INFO]Before cr3 is %p.\\n\", rcr3()); lcr3(PADDR(currentEnv->env_pgdir)); //cprintf(\"[INFO]After cr3 is %p.\\n\", rcr3()); memcpy(va, kern_pgdir, PGSIZE); ++pageInfo->pp_ref; //lcr3(PADDR(kern_pgdir)); //cprintf(\"[INFO]Finally cr3 is %p.\\n\", rcr3()); return 0;}// lab 5's challenge - implement Unix-Like exec.static intsys_exec_map(pde_t *pg_dir, void *srcva, void *dstva, int perm){ struct PageInfo *pageInfo = NULL; struct Env *currentEnv; int32_t leastPerm = (PTE_U | PTE_P); envid2env(0, &currentEnv, 1); assert(currentEnv); // step 0) if((uintptr_t)srcva >= UTOP || (uintptr_t)dstva >= UTOP || ((uintptr_t)srcva & (PGSIZE - 1)) || ((uintptr_t)dstva & (PGSIZE - 1))){ cprintf(\"[DEBUG]sys_exec_map:step 0 failed.\\n\"); return -E_INVAL; } // step 1) check pg_dir present. if(!page_lookup(currentEnv->env_pgdir, pg_dir, NULL)){ cprintf(\"[DEBUG]sys_exec_map:pg_dir not present.\\n\"); return -E_INVAL; } // step 2) check source page present. if(!( pageInfo = page_lookup(currentEnv->env_pgdir, srcva, NULL))){ cprintf(\"[DEBUG]sys_exec_map:step 2 failed.\\n\"); return -E_INVAL; } // step 3) if((perm & leastPerm) != leastPerm || (perm & (~PTE_SYSCALL))){ cprintf(\"[DEBUG]sys_exec_map:step 3 failed,permisson denied.\\n\"); return -E_INVAL; } // step 4) map pageInfo to dstva. // cprintf(\"[DEBUG]pg_dir is %p and dstva is %p\\n\", pg_dir, dstva); return page_insert(pg_dir, pageInfo, dstva, perm);}// lab 5's challenge - implement Unix-Like exec.static intsys_exec_replace_pgdir(pde_t *pg_dir, uintptr_t esp, uintptr_t e_entry){ struct PageInfo *pageInfo = NULL; struct Env *currentEnv = NULL; pde_t *old_pgdir; pte_t *pt; uint32_t pdeno, pteno; physaddr_t pa; envid2env(0, &currentEnv, 1); assert(currentEnv); if(!(pageInfo = page_lookup(currentEnv->env_pgdir, (void *)pg_dir, NULL))){ cprintf(\"[DEBUG]sys_exec_replace_pgdir:page_lookup:pageInfo is null.\\n\"); return -E_INVAL; } // save the old page directory. old_pgdir = currentEnv->env_pgdir; currentEnv->env_pgdir = (pde_t *)page2kva(pageInfo); // UVPT maps the env's own page table read-only. currentEnv->env_pgdir[PDX(UVPT)] = PADDR(currentEnv->env_pgdir) | PTE_P | PTE_U; // we have replaced page directory.However,we didn't free old page directory and page table, // that's what we are going to do next. for(pdeno = 0; pdeno < PDX(UTOP); ++pdeno){ if(!(old_pgdir[pdeno] & PTE_P)) continue; // find the pa and va of the page table. pa = PTE_ADDR(old_pgdir[pdeno]); pt = (pte_t *)KADDR(pa); // unmap all PTEs in this page table. for(pteno = 0; pteno env_tf.tf_esp = esp; currentEnv->env_tf.tf_eip = e_entry; env_run(currentEnv); return 0; // never get here,just eliminate compiling error.} 除此之外，还需要修改一些地方，篇幅原因，完整实现可参考Github:YanTang Qin的lab5dev分支： git checkout lab5dev切换到lab5dev分支 git diff lab5 这样就能够快速找到我为实现exec所做的修改了。 下图是实现的效果。可以看到我的测试程序使用了fork+execl的模式，子进程会加载testshell这个程序执行，可以看到完全符合预期！ 以下是测试程序： 123456789101112131415161718192021222324voidumain(int argc, char **argv){ int r; cprintf(\"hello, world!\\n\"); cprintf(\"[BEFORE]parent environment %08x\\n\", thisenv->env_id); if((r = fork()) < 0){ cprintf(\"[DEBUG]fork failed for %e.\\n\", r); return; } // printe by parent and child environment. cprintf(\"[COMMON]environment %08x\\n\", thisenv->env_id); if(r > 0){ // parent environment. cprintf(\"[PARENT]hello\\n\"); }else if(r == 0){ // child environment. cprintf(\"[CHILD]world!\\n\"); if((r = execl(\"testshell\", \"testshell\", 0)) < 0){ panic(\"[DEBUG]panic for %e\", r); } } cprintf(\"[PARENT]Oh!\\n\");} 有效输出结果（剔除了调试信息）： 123456789hello, world![BEFORE]parent environment 00001001[COMMON]environment 00001001[COMMON]environment 00001002[PARENT]hello[PARENT]Oh![CHILD]world!running sh -x < testshell.sh | catshell ran correctly 可以看到，抛开并发运行带来的不确定性，输出结果完全符合预期。 Exercise 8 - Sharing library state across fork and spawn#123456789101112131415161718192021222324static intduppage(envid_t envid, unsigned pn){ int r; uintptr_t pn_va = pn * PGSIZE; if(uvpt[pn] & PTE_SHARE){ if((r = sys_page_map(0, (void *)pn_va, envid, (void *)pn_va, uvpt[pn] & PTE_SYSCALL)) < 0){ panic(\"sys_page_map:%e\", r); } }else if((uvpt[pn] & PTE_W) || (uvpt[pn] & PTE_COW)){ if((r = sys_page_map(0, (void *)pn_va, envid, (void *)pn_va, (PTE_COW | PTE_P | PTE_U))) < 0){ panic(\"sys_page_map:%e\", r); } if((r = sys_page_map(0, (void *)pn_va, 0, (void *)pn_va, (PTE_COW | PTE_P | PTE_U))) < 0){ panic(\"sys_page_map:%e\", r); } }else{ if((r = sys_page_map(0, (void *)pn_va, envid, (void *)pn_va, PTE_P | PTE_U)) < 0){ panic(\"sys_page_map:%e\", r); } } return 0;} 以及： 12345678910111213141516static intcopy_shared_pages(envid_t child){ uintptr_t pageVa; unsigned pn; int r; for(pageVa = UTEXT; pageVa < UTOP; pageVa += PGSIZE){ pn = PGNUM(pageVa); if((uvpd[PDX(pageVa)] & PTE_P) && (uvpt[pn] & PTE_P) && (uvpt[pn] & PTE_SHARE)){ if((r = sys_page_map(0, (void *)pageVa, child, (void *)pageVa, uvpt[pn] & PTE_SYSCALL)) < 0){ panic(\"copy_shared_pages:sys_page_map:%e\", r); } } } return 0;} The keyboard interface# Exercise 9 - Responsing to externel interrupt#在trap_dispatch中添加上trap number对应的相应即可： 123456789if(tf->tf_trapno == (IRQ_OFFSET + IRQ_KBD)){ kbd_intr(); return;}if(tf->tf_trapno == (IRQ_OFFSET + IRQ_SERIAL)){ serial_intr(); return;} Shell# Exercise 10 - Implement I/O redirection#理解了文件系统的结构和接口之后不难： 12345678910111213141516171819202122case '","link":"/2020/01/31/MIT-6-828-LAB5-File-system-Spawn-and-Shell/"},{"title":"MySQL学习笔记（一）：存储引擎和事务","text":"一、如何阅读官方文档#官方中文文档传送门：MySQL5.1中文文档重点关注： 第七章 优化 第十一章 列类型 第十三章 SQL语句语法 第十五章 存储引擎和表类型 更好地阅读文档：注意方括号 [] 意味着该字段可以省略，也就是可选字段；当要用到圆括号字段修饰的字段的时候，圆括号()不可以省略；大括号{}意味着在该字段的给定值中进行选择，| 这个符号就意味着选择呗；啥符号都没带的就是必填字段呗。例如下面由MySQL官方文档给出的select语法：像[all | distinct | distinctrow] 这个字段本身是可选字段，写select语句的时候可加可不加，但是如果加上该字段的时候，就要在all，distinct，distinctrow中选择一个字段加上。select_expr就是必选字段，必须要在select语句中写这个字段。像[LIMIT {[offset,] row_count | row_count OFFSET offset}]这个，也就是说，这一整个字段是可选字段，但是如果加上该字段，就要在{}中给出选项中选择一个，offser加上了[]，说明它可有可无。 1234567891011121314151617181920# 以MySQL官方文档的SELECT语法说明为例SELECT [ALL | DISTINCT | DISTINCTROW ] [HIGH_PRIORITY] [STRAIGHT_JOIN] [SQL_SMALL_RESULT] [SQL_BIG_RESULT] [SQL_BUFFER_RESULT] [SQL_CACHE | SQL_NO_CACHE] [SQL_CALC_FOUND_ROWS] select_expr, ... [INTO OUTFILE 'file_name' export_options | INTO DUMPFILE 'file_name'] [FROM table_references [WHERE where_definition] [GROUP BY {col_name | expr | position} [ASC | DESC], ... [WITH ROLLUP]] [HAVING where_definition] [ORDER BY {col_name | expr | position} [ASC | DESC] , ...] [LIMIT {[offset,] row_count | row_count OFFSET offset}] [PROCEDURE procedure_name(argument_list)] [FOR UPDATE | LOCK IN SHARE MODE]] 二、存储引擎#存储引擎简单总结#以下内容基本来源于官方文档以及书籍《深入浅出MySQL》 常用存储引擎的对比 特点 MyISAM InnoDB MEMORY MERGE NDB 存储限制 有 64TB 有 没有 有 事务安全 支持 锁机制 表锁 行锁 表锁 表锁 行锁 B树索引 支持 支持 支持 支持 支持 哈希索引 支持 支持 全文索引 支持 集群索引 支持 数据缓存 支持 支持 支持 索引缓存 支持 支持 支持 支持 支持 数据可压缩 支持 空间使用 低 高 N/A 低 低 内存使用 低 高 中等 低 高 批量插入的速度 高 低 高 高 高 支持外键 支持 其中常用的几种就是MyISAM（默认存储引擎）、InnoDB、MEMORY和MERGE； MyISAM不支持事务，也不支持外键，优势是访问的速度快，对事务性没有要求或者以SELECT和INSERT为主的应用可以使用这个引擎来创建表； InnoDB提供了具有提交、回滚和崩溃恢复能力的事务安全，相较于MyISAM的存储引擎，InnoDB写的处理效率差一些并且会占用更多的磁盘空间以保留数据和索引，并且在MySQL中支持外键的存储引擎只有InnoDB，因此需要使用外键约束的时候就只能够选择InnoDB存储引擎； MEMORY使用存在内存中的内容来创建表，因此它的表访问起来非常快，并且默认使用HASH索引（创建索引的时候也可以指定使用HASH索引还是BTREE索引，例如create index mem_hash USING HASH on tab_memory (city_id)），但是这只是临时表，服务关闭之后，数据就会丢失； MERGE是一组MyISAM表的组合，这些MyISAM表必须结构完全相同，而MERGE表本身没有数据，对MERGE类型的表可以进行查询、更新、删除的操作，但是其实际上就是对内部的MyISAM表进行的； 1234567891011121314# 创建MERGE表示例，代码来源于《深入浅出MySQL》# 三个关键点：# 1. payment_2006与payment_2007都是使用MyISAM存储引擎的表，并且该MERGE表的# 定义和payment_2006，payment_2007都一样；# 2. INSERT_METHOD=LAST指定了当对该MERGE表进行插入时应当作用在最后一个表上# 也可以指定为FIRST，如果创建MERGE表时不对该子句指定或者指定为NO，就不允许对# 该MERGE表进行插入操作；# 3. 对MERGE表进行DROP删除只会删除MERGE表的定义，对实际MyISAM表没有影响；mysql> CREATE TABLE payment_all( -> country_id smallint, -> payment_date datetime, -> amount DECIMAL(15,2), -> INDEX(country_id) -> )engine=merge union=(payment_2006,payment_2007) INSERT_METHOD=LAST; 关于InnoDB# InnoDB默认地被包含在MySQL二进制分发中。Windows Essentials installer使InnoDB成为Windows上MySQL的默认表。如果你想要所有（非系统）表都被创建成InnoDB表，你可以简单地把default-table-type=innodb行添加到my.cnf或my.ini文件的[mysqld]节里。 每个连接到MySQL服务器的客户端开始之时是允许自动提交模式的，这个模式自动提交你运行的每个SQL语句。要使用多语句事务，你可以用SQL语句SET AUTOCOMMIT = 0禁止自动提交，并且用COMMIT和ROLLBACK来提交或回滚你的事务。 改变一个表为InnoDB型最快的办法就是直接插入进一个InnoDB表。即，使用ALTER TABLE ... ENGINE=INNODB，或用相同的定义创建一个空InnoDB表，并且用INSERT INTO ... SELECT * FROM ...插入行。如果你对第二个键有UNIQUE约束，你可以在导入阶段设置：SET UNIQUE_CHECKS=0，以临时关掉唯一性检查好加速表的导入。对于大表，这节省了大量的磁盘I/O，因为InnoDB随后可以使用它的插入缓冲区来第二个索引记录作为一批来写入。三、事务控制与锁定# MySQL 通过SET AUTOCOMMIT、START TRANSACTION、COMMIT和ROLLBACK等语句支持本地事务。默认情况下，MySQL 是自动提交（Autocommit）的，如果需要通过明确的Commit和Rollback来提交和回滚事务，那么需要通过明确的事务控制命令来开始事务，这是和Oracle的事务管理明显不同的地方。 如果只是对某些语句需要进行事务控制，则使用START TRANSACTION语句开始一个事务比较方便，这样事务结束之后可以自动回到自动提交的方式，如果希望所有的事务都不是自动提交的，那么通过修改AUTOCOMMIT为0来控制事务比较方便，这样不用在每个事务开始的时候再执行START TRANSACTION语句。 在同一个事务中，最好不使用不同存储引擎的表，否则ROLLBACK时需要对非事务类型的表进行特别的处理，因为COMMIT、ROLLBACK只能对事务类型的表进行提交和回滚。","link":"/2019/10/25/MySQL学习笔记学习笔记-一-存储引擎和事务/"},{"title":"Shell demo on Unix Platform","text":"@[TOC] 一、题目说明#同Cache lab一样，完整的题目说明可以在其官网上找到，在student site当中的for self-study中可以找到所有lab的参考文档，以及一些其它的有用文件，例如GDB调试指南等等。这里附上Shell lab的传送门（注：该链接会直接下载shell lab的self-study handout):Shell Lab self-study handout 二、代码#这个lab的难度在于多进程并发带来的坑以及信号量的处理，为了确保一些操作的原子性，需要使用sigpromask函数来屏蔽掉操作系统内核向进程发送的信号，实际上在csapp书的异常控制流这一章中已经实现了一个非常简易的shell demo,以及一些常见的问题也在书中说明了，例如可以善用volatile关键字来实现全局状态的检测与设置等等。 关于eval函数，思路大致如下： 初始化必要变量并且设置阻塞必要的信号； 解析shell中由用户输入的命令行，设置state标志位（标志着是前台进程还是后台进程）; 若输入的指令是内置指令则立即执行，不需要fork子进程，否则fork子进程并调用execve加载相应的可执行文件并且在shell进程中输出必要的信息，然后退出父进程执行第四步； 将子进程job加入到job list中; 判断是否是bg,若是前台进程调用waifg函数阻塞前台进程运行完成，并且打印消息； 直接上代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715/* * tsh - A tiny shell program with job control * * */#include #include #include #include #include #include #include #include #include /* Misc manifest constants */#define MAXLINE 1024 /* max line size */#define MAXARGS 128 /* max args on a command line */#define MAXJOBS 16 /* max jobs at any point in time */#define MAXJID 1 FG : fg command * ST -> BG : bg command * BG -> FG : fg command * At most 1 job can be in the FG state. *//* Global variables */extern char **environ; /* defined in libc */char prompt[] = \"tsh> \"; /* command line prompt (DO NOT CHANGE) */int verbose = 0; /* if true, print additional output */int nextjid = 1; /* next job ID to allocate */char sbuf[MAXLINE]; /* for composing sprintf messages */static volatile sig_atomic_t flag;static pid_t shell_pid;struct job_t { /* The job struct */ pid_t pid; /* job PID */ int jid; /* job ID [1, 2, ...] */ int state; /* UNDEF, BG, FG, or ST */ char cmdline[MAXLINE]; /* command line */};struct job_t jobs[MAXJOBS]; /* The job list *//* End global variables *//* Function prototypes *//* Here are the functions that you will implement */void eval(char *cmdline);int builtin_cmd(char **argv);void do_bgfg(char **argv);void waitfg(pid_t pid);void sigchld_handler(int sig);void sigtstp_handler(int sig);void sigint_handler(int sig);/* Here are helper routines that we've provided for you */int parseline(const char *cmdline, char **argv);void sigquit_handler(int sig);void clearjob(struct job_t *job);void initjobs(struct job_t *jobs);int maxjid(struct job_t *jobs);int addjob(struct job_t *jobs, pid_t pid, int state, char *cmdline);int deletejob(struct job_t *jobs, pid_t pid);pid_t fgpid(struct job_t *jobs);struct job_t *getjobpid(struct job_t *jobs, pid_t pid);struct job_t *getjobjid(struct job_t *jobs, int jid);int pid2jid(pid_t pid);void listjobs(struct job_t *jobs);void usage(void);void unix_error(char *msg);void app_error(char *msg);typedef void handler_t(int);handler_t *Signal(int signum, handler_t *handler);/* * main - The shell's main routine */int main(int argc, char **argv){ char c; char cmdline[MAXLINE]; int emit_prompt = 1; /* emit prompt (default) */ /* Redirect stderr to stdout (so that driver will get all output * on the pipe connected to stdout) */ dup2(1, 2); /* Parse the command line */ while ((c = getopt(argc, argv, \"hvp\")) != EOF) { switch (c) { case 'h': /* print help message */ usage(); break; case 'v': /* emit additional diagnostic info */ verbose = 1; break; case 'p': /* don't print a prompt */ emit_prompt = 0; /* handy for automatic testing */ break; default: usage(); } } /* Install the signal handlers */ /* These are the ones you will need to implement */ Signal(SIGINT, sigint_handler); /* ctrl-c */ Signal(SIGTSTP, sigtstp_handler); /* ctrl-z */ Signal(SIGCHLD, sigchld_handler); /* Terminated or stopped child */ /* This one provides a clean way to kill the shell */ Signal(SIGQUIT, sigquit_handler); /* Initialize the job list */ initjobs(jobs); /* Get shell pid */ shell_pid=getpid(); /* Execute the shell's read/eval loop */ while (1) { /* Read command line */ if (emit_prompt) { printf(\"%s\", prompt); fflush(stdout); } if ((fgets(cmdline, MAXLINE, stdin) == NULL) && ferror(stdin)) app_error(\"fgets error\"); if (feof(stdin)) { /* End of file (ctrl-d) */ fflush(stdout); exit(0); } /* Evaluate the command line */ eval(cmdline); fflush(stdout); fflush(stdout); } exit(0); /* control never reaches here */}/* * eval - Evaluate the command line that the user has just typed in * * If the user has requested a built-in command (quit, jobs, bg or fg) * then execute it immediately. Otherwise, fork a child process and * run the job in the context of the child. If the job is running in * the foreground, wait for it to terminate and then return. Note: * each child process must have a unique process group ID so that our * background children don't receive SIGINT (SIGTSTP) from the kernel * when we type ctrl-c (ctrl-z) at the keyboard.*/void eval(char *cmdline){ int bg,state; sigset_t mask_all,prev_mask,mask_one; pid_t pid; char buf[MAXLINE]; char *argv[MAXARGS]; struct job_t *job_ptr=NULL; strcpy(buf,cmdline); bg=parseline(buf,argv); if(argv[0]==NULL)return; if(!builtin_cmd(argv)){ // 不是内置指令 sigemptyset(&mask_one); sigaddset(&mask_one,SIGCHLD); // 阻塞SIGCHLD信号 sigprocmask(SIG_BLOCK,&mask_one,&prev_mask); if((pid=fork())==0){ // in subprocess // restore SIGNAL SIGCHLD sigprocmask(SIG_SETMASK,&prev_mask,NULL); setpgid(0,0); if(execve(argv[0],argv,environ)jid,job_ptr->pid,job_ptr->cmdline); fflush(stdout); }else{ // 如果是前台进程，就调用waitfg()等待前台进程终止 waitfg(pid); } } } return;}/* * parseline - Parse the command line and build the argv array. * * Characters enclosed in single quotes are treated as a single * argument. Return true if the user has requested a BG job, false if * the user has requested a FG job. */int parseline(const char *cmdline, char **argv){ static char array[MAXLINE]; /* holds local copy of command line */ char *buf = array; /* ptr that traverses command line */ char *delim; /* points to first space delimiter */ int argc; /* number of args */ int bg; /* background job? */ strcpy(buf, cmdline); buf[strlen(buf)-1] = ' '; /* replace trailing '\\n' with space */ while (*buf && (*buf == ' ')) /* ignore leading spaces */ buf++; /* Build the argv list */ argc = 0; if (*buf == '\\'') { buf++; delim = strchr(buf, '\\''); } else { delim = strchr(buf, ' '); } while (delim) { argv[argc++] = buf; *delim = '\\0'; buf = delim + 1; while (*buf && (*buf == ' ')) /* ignore spaces */ buf++; if (*buf == '\\'') { buf++; delim = strchr(buf, '\\''); } else { delim = strchr(buf, ' '); } } argv[argc] = NULL; if (argc == 0) /* ignore blank line */ return 1; /* should the job run in the background? */ if ((bg = (*argv[argc-1] == '&')) != 0) { argv[--argc] = NULL; } return bg;}/* * builtin_cmd - If the user has typed a built-in command then execute * it immediately. */int builtin_cmd(char **argv){ sigset_t mask_all,prev_mask; if(!strcmp(argv[0],\"quit\")){ // 指令为quit，终止shell进程 kill(shell_pid,SIGQUIT); return 1; }else if(strcmp(argv[0],\"fg\")==0||strcmp(argv[0],\"bg\")==0){ do_bgfg(argv); return 1; }else if(!strcmp(argv[0],\"jobs\")){ sigfillset(&mask_all); sigprocmask(SIG_SETMASK,&mask_all,&prev_mask); listjobs(jobs); sigprocmask(SIG_SETMASK,&prev_mask,NULL); return 1; } return 0; /* not a builtin command */}/* * do_bgfg - Execute the builtin bg and fg commands */void do_bgfg(char **argv){ // 让一个已停止的后台作业运行 // 或者让一个已停止或正在运行的后台作业变为前台作业 sigset_t mask_all,prev_mask; int argc=0,id,is_pid; char *temp_ptr=argv[0]; struct job_t *job_ptr=NULL; while(temp_ptr)argc++; // 参数个数 if(argcstate){ case ST: job_ptr->state=BG; kill(-(job_ptr->pid),SIGCONT); printf(\"[%d] (%d) %s\", job_ptr->jid, job_ptr->pid, job_ptr->cmdline); break; case UNDEF: case FG: // debug unix_error(\"error in function do_bgfg()\\n\"); break; default: break; } }else if(strcmp(argv[0],\"fg\")){ // 命令为fg switch(job_ptr->state){ case ST: // 如果前台进程为停止状态，则调用重启该前台进程并且调用waitfg() job_ptr->state=FG; kill(-(job_ptr->pid),SIGCONT); waitfg(job_ptr->pid); break; case BG: // 如果是后台进程，就将其转为前台进程并且调用waitfg() job_ptr->state=FG; waitfg(job_ptr->pid); break; default: // debug unix_error(\"error in function do_bgfg()\\n\"); break; } } }else{ printf(\"(%s): No such process\\n\", argv[1]); fflush(stdout); } sigprocmask(SIG_SETMASK,&prev_mask,NULL); // restore return;}/* * waitfg - Block until process pid is no longer the foreground process */void waitfg(pid_t pid){ sigset_t mask_one,prev_mask; // 阻塞SIGCHLD，以避免在调用sigsuspend之前对SIGCHLD做出反应进入相应的 // 信号处理程序，从而导致主进程永远被挂起 sigemptyset(&mask_one); sigaddset(&mask_one,SIGCHLD); sigprocmask(SIG_BLOCK,&mask_one,&prev_mask); flag=pid; while(flag) // sigsuspend函数实际上等价于不可中断的： // sigprocmask(SIG_SET_MASK,&mask,&prev); // pause(); // sigprocmask(SIG_SETMASK,&prev,NULL sigsuspend(&prev_mask); // 此时已经回收了终止的子进程 // optionally unblock SIGCHLD sigprocmask(SIG_SETMASK,&prev_mask,NULL); return;}/***************** * Signal handlers *****************//* * sigchld_handler - The kernel sends a SIGCHLD to the shell whenever * a child job terminates (becomes a zombie), or stops because it * received a SIGSTOP or SIGTSTP signal. The handler reaps all * available zombie children, but doesn't wait for any other * currently running children to terminate. */void sigchld_handler(int sig){ // 值得注意的是,sigchld_handler不仅要回收显式等待的前台进程，而且也要 // 回收后台中停止或终止的进程 int olderrno=errno,status; sigset_t mask_all,prev_mask; struct job_t *job_ptr=NULL; pid_t pid; while((pid=waitpid(-1,&status,WUNTRACED|WNOHANG))>0){ sigfillset(&mask_all); sigprocmask(SIG_BLOCK,&mask_all,&prev_mask); job_ptr=getjobpid(jobs,pid); if(job_ptr->pid==flag){ // 回收的前台作业 flag=0; } if(WIFSTOPPED(status)){ // 停止 job_ptr->state=ST; }else{ // 终止 deletejob(jobs,pid); } printf(\"Job [%d] (%d) terminated by signal %d\\n\", job_ptr->jid, job_ptr->pid, WSTOPSIG(status)); fflush(stdout); sigprocmask(SIG_SETMASK,&prev_mask,NULL); } errno=olderrno; return;}/* * sigint_handler - The kernel sends a SIGINT to the shell whenver the * user types ctrl-c at the keyboard. Catch it and send it along * to the foreground job. */void sigint_handler(int sig){ int olderrno=errno,fg_pid; sigset_t mask_all,prev_mask; sigfillset(&mask_all); sigprocmask(SIG_SETMASK,&mask_all,&prev_mask); fg_pid=fgpid(jobs); sigprocmask(SIG_SETMASK,&prev_mask,NULL); if(fg_pid){ // 存在前台进程,将该信号发送给前台进程组 kill(-fg_pid,SIGINT); } errno=olderrno; return;}/* * sigtstp_handler - The kernel sends a SIGTSTP to the shell whenever * the user types ctrl-z at the keyboard. Catch it and suspend the * foreground job by sending it a SIGTSTP. */void sigtstp_handler(int sig){ int olderrno=errno,fg_pid; sigset_t mask_all,prev_mask; sigfillset(&mask_all); sigprocmask(SIG_SETMASK,&mask_all,&prev_mask); fg_pid=fgpid(jobs); sigprocmask(SIG_SETMASK,&prev_mask,NULL); if(fg_pid){ // 存在前台进程，挂起该前台进程组 kill(-fg_pid,SIGTSTP); } errno=olderrno; return;}/********************* * End signal handlers *********************//*********************************************** * Helper routines that manipulate the job list **********************************************//* clearjob - Clear the entries in a job struct */void clearjob(struct job_t *job) { job->pid = 0; job->jid = 0; job->state = UNDEF; job->cmdline[0] = '\\0';}/* initjobs - Initialize the job list */void initjobs(struct job_t *jobs) { int i; for (i = 0; i < MAXJOBS; i++) clearjob(&jobs[i]);}/* maxjid - Returns largest allocated job ID */int maxjid(struct job_t *jobs){ int i, max=0; for (i = 0; i < MAXJOBS; i++) if (jobs[i].jid > max) max = jobs[i].jid; return max;}/* addjob - Add a job to the job list */int addjob(struct job_t *jobs, pid_t pid, int state, char *cmdline){ int i; if (pid < 1) return 0; for (i = 0; i < MAXJOBS; i++) { if (jobs[i].pid == 0) { jobs[i].pid = pid; jobs[i].state = state; jobs[i].jid = nextjid++; if (nextjid > MAXJOBS) nextjid = 1; strcpy(jobs[i].cmdline, cmdline); if(verbose){ printf(\"Added job [%d] %d %s\\n\", jobs[i].jid, jobs[i].pid, jobs[i].cmdline); } return 1; } } printf(\"Tried to create too many jobs\\n\"); return 0;}/* deletejob - Delete a job whose PID=pid from the job list */int deletejob(struct job_t *jobs, pid_t pid){ int i; if (pid < 1) return 0; for (i = 0; i < MAXJOBS; i++) { if (jobs[i].pid == pid) { clearjob(&jobs[i]); nextjid = maxjid(jobs)+1; return 1; } } return 0;}/* fgpid - Return PID of current foreground job, 0 if no such job */pid_t fgpid(struct job_t *jobs) { int i; for (i = 0; i < MAXJOBS; i++) if (jobs[i].state == FG) return jobs[i].pid; return 0;}/* getjobpid - Find a job (by PID) on the job list */struct job_t *getjobpid(struct job_t *jobs, pid_t pid) { int i; if (pid < 1) return NULL; for (i = 0; i < MAXJOBS; i++) if (jobs[i].pid == pid) return &jobs[i]; return NULL;}/* getjobjid - Find a job (by JID) on the job list */struct job_t *getjobjid(struct job_t *jobs, int jid){ int i; if (jid < 1) return NULL; for (i = 0; i < MAXJOBS; i++) if (jobs[i].jid == jid) return &jobs[i]; return NULL;}/* pid2jid - Map process ID to job ID */int pid2jid(pid_t pid){ int i; if (pid < 1) return 0; for (i = 0; i < MAXJOBS; i++) if (jobs[i].pid == pid) { return jobs[i].jid; } return 0;}/* listjobs - Print the job list */void listjobs(struct job_t *jobs){ int i; for (i = 0; i < MAXJOBS; i++) { if (jobs[i].pid != 0) { printf(\"[%d] (%d) \", jobs[i].jid, jobs[i].pid); switch (jobs[i].state) { case BG: printf(\"Running \"); break; case FG: printf(\"Foreground \"); break; case ST: printf(\"Stopped \"); break; default: printf(\"listjobs: Internal error: job[%d].state=%d \", i, jobs[i].state); } printf(\"%s\", jobs[i].cmdline); } }}/****************************** * end job list helper routines ******************************//*********************** * Other helper routines ***********************//* * usage - print a help message */void usage(void){ printf(\"Usage: shell [-hvp]\\n\"); printf(\" -h print this message\\n\"); printf(\" -v print additional diagnostic information\\n\"); printf(\" -p do not emit a command prompt\\n\"); exit(1);}/* * unix_error - unix-style error routine */void unix_error(char *msg){ fprintf(stdout, \"%s: %s\\n\", msg, strerror(errno)); exit(1);}/* * app_error - application-style error routine */void app_error(char *msg){ fprintf(stdout, \"%s\\n\", msg); exit(1);}/* * Signal - wrapper for the sigaction function */handler_t *Signal(int signum, handler_t *handler){ struct sigaction action, old_action; action.sa_handler = handler; sigemptyset(&action.sa_mask); /* block sigs of type being handled */ action.sa_flags = SA_RESTART; /* restart syscalls if possible */ if (sigaction(signum, &action, &old_action) < 0) unix_error(\"Signal error\"); return (old_action.sa_handler);}/* * sigquit_handler - The driver program can gracefully terminate the * child shell by sending it a SIGQUIT signal. */void sigquit_handler(int sig){ printf(\"Terminating after receipt of SIGQUIT signal\\n\"); exit(1);}","link":"/2019/11/17/Shell-demo-on-Unix-Platform/"},{"title":"《现代操作系统》学习笔记(一):进程与线程","text":"@[TOC] 一、进程与线程的简单回顾#进程与线程的简单回顾# 《Modern Operating System》：进程就是一个正在执行的程序的实例，包括程序计数器、寄存器和变量的当前值。 每一个进程都拥有自己独立的地址空间（这源于虚拟内存技术），其中有程序和数据以及独立的用户栈和独立的堆空间等。例如在UNIX系统中，可以调用系统级函数fork()来创建一个子进程，在还未加载新的代码之前，此时子进程与父进程拥有几乎完全相同的内存映像、同样的环境字符串和同样的打开文件，可以通过execve()来重新加载新的程序（可执行文件），但是execve仅仅只是分配了虚拟页，此时并没有实际将程序从磁盘中调入内存，只有当某一条指令触发了缺页故障的时候，此时将陷入内核态，将该条指令虚拟页所指定的内容调入物理内存，并且修改相应的PTE条目（Page Table Entry)，然后系统调用返回到这条指令，再一次执行该指令时就不再会触发缺页故障了（详情可参考机械工业出版社的《深入理解计算机系统》第三版）。线程不准确地理解的话，可以将其看作一种轻量级的进程，同一个进程中的线程都有完全一样的地址空间，共享同样的全局变量，由于各个线程都可以放你问进程地址空间中的每一个内存地址，所以一个线程可以读、写甚至清除另一个线程的堆栈，也就是说，线程之间是没有保护的。除了共享地址空间外，还共享同一个打开文件集、子进程、定时器以及相关信号（因为这些基本上都是操作系统维护在进程的上下文中的） 为什么需要线程？# 线程拥有共享同一个地址空间和所有可用数据的能力，但是多进程模型无法做到； 线程比进程更轻量级，创建线程的开销比创建进程的开销要小得多（无论是时间上还是空间上），也更容易撤销； 性能。若多个线程都是CPU密集型的，那么不能获得性能上的增强（线程的调度也是需要开销的），但是如果存在着大量的计算和I/O处理，拥有多个线程允许这些活动彼此重叠进行，从而会加快应用程序执行的速度 线程包的实现方式# 线程包有两种实现方式：在用户空间中和在内核中。除此之外还有混合实现方式。 第一种实现方式就是把整个线程包放在用户空间中，而内核对线程包一无所知。在这种方式下，进程中有一个运行时系统，管理着该进程特有的线程表（thread table），用来跟踪该进程中的线程。 第二种实现方式就不需要运行时系统了，每个进程也不要存储和管理各自的线程表了，相反，在内核当中有用来记录系统中所有线程的线程表（进程通常运行在用户模式下，对内存的访问通常是受限的）。当某个线程希望创建一个新线程或者撤销一个已有线程时，它进行一个系统调用（系统调用实际上是一种异常控制流，注意和Java的异常区别开来，中断、陷阱、故障等实际上都是一种异常控制流），该系统调用将切换到内核模式（内核模式拥有最高访问权限），并且通过对线程表的更新完成线程创建或撤销工作。 两种线程包的实现方式各自的优缺点总结#在用户空间中实现线程包： 优点：1. 用户级线程包可以在不支持线程的操作系统上实现； 2. 允许每个进程有自己定制的调度算法； 3. 当某个线程做了一些会引起在**本地阻塞**的事情之后，运行时系统将会调度该进程中的其它线程来运行，并且如果机器有一条保存所有寄存器的指令和另一条装入全部寄存器的指令，那么整个线程的切换就可以在几条指令内完成，这比内核级线程的切换的代价要小得多（因为内核级线程的切换首先陷入内核，切换上下文，这个开销是巨大的）； 缺点：1. 阻塞系统调用。如果进程P中的某一个线程产生了一个阻塞系统调用，那么由于会进行上下文的切换，整个进程都将被阻塞，从而导致该进程中的其它线程也被迫进入阻塞状态，这显然违背了线程本身出现的原因； 2. 缺页中断问题。在《深入理解计算机系统》这本书中，对程序的加载进行了详细的解释与说明，以UNIX系统为例，调用execve()之后，只是分配了虚拟页，程序实际上还并没有加载进内存，详细可自行查阅。如果某个程序调用或者跳转到了一条不在内存上的指令时，将会引发缺页故障，从而导致整个**进程**陷入内核态，然后内核异常处理程序将对应的虚拟页调入物理内存当中，并且修改相应的PTE，然后返回到引发该缺页故障的指令，该指令将会重新执行，这一次就不会再触发缺页故障了。显然，缺页中断将会导致整个进程中的线程都被阻塞直到缺页故障被处理完毕； 3. 在用户级线程包中，如果一个线程开始运行，那么在该进程中的其它线程就不能运行，除非第一个线程自动放弃CPU。 在内核中实现线程: 优点：1. 不再需要运行时系统了，每个进程中也没有线程表，相反，线程统一由内核维护在内核区域中； 2. 解决了阻塞系统调用的问题。所有能够阻塞线程的调用都以系统调用的形式实现，当一个线程阻塞时，内核根据相应的调度算法而调度其它就绪状态的线程的运行； 3. 解决了缺页中断问题。同样的，当一个线程引发了缺页故障需要将所需要的页面调入物理内存时，内核可选择调度其它线程来运行； 缺点：1. 信号（Signal）是发送给进程的（在进程的上下文中由内核维护着一个bind向量，详情请查看《深入理解计算机系统》），当一个信号到达的时候，那么这个信号应该由哪一个线程来处理？ 2. 当一个进程创建了一个子进程的时候，新的进程是应该拥有与父进程一样的线程吗？等等这些问题都是值得考虑的。 二、进程间通信#竞争条件、互斥与临界区# 《Modern Operating Systems》： 竞争条件（Race Condition）即两个或者多个进程读写某些共享数据，而最后的结果取决于进程运行的精确时序。 互斥（Mutual Exclusion）即以某种手段确保当一个进程在使用一个共享变量或文件时，其它进程不能做同样的操作。 临界区（Critical Region）即对共享内存进行访问的程序片段。 解决共享数据的并发进程需要满足的条件# 任何两个进程不能同时处于其临界区中； 不应对CPU的速度和数量做任何假设； 临界区外运行的进程不得阻塞其它进程； 不能够使进程无限期等待进入临界区； 互斥的实现方式概述#在软件层面上和硬件层面上都可以实现互斥： 软件层面： 锁变量 严格轮换法（Busy Waiting） Peterson解法（Busy Waiting） … 硬件层面： 屏蔽中断（仅适用于单处理器操作系统） 专用机器指令（例如TSL指令，XCHG指令，保证了操作的原子性） Semaphore信号量（很重要，既能够实现互斥也能够实现同步） 管程（一个编程语言概念，不是所有语言都支持管程，Java支持） 消息传递（Message Passing）互斥的实现方式详解：软件层面# 锁变量：设定有一个进程间共享锁，初始值为0，当一个进程想要进入临界区时，首先测试这把锁，如果值为0，则该进程将其设置为1并且进入临界区；若为1，则该进程将等待直到其值变为0。 实际上并没有解决互斥问题，仍然存在竞争条件，仍有可能导致多个进程同时进入临界区之中。 严格轮换法：共享一个整型变量turn，初始值为0，用于记录轮到哪个进程进入临界区，并且检查或共享内存。开始时，进程0检查其值为0，于是进入临界区，进程1也发现其值为0，所以在一个等待循环中不停地测试turn，看其值何时变为1。（本质上就是busy waiting) 显然，假设进程0在非临界区中运行的速度很慢而导致其慢于进程1的运行速度，当进程0离开临界区之后并且将turn置为1，然后进程1进入临界区并且很快执行完毕，那么进程1将会由于进程0的非临界区代码的运行速度太慢而迟迟不将turn置为1，从而被阻塞，换而言之，进程1是被一个临界区外之外的进程所阻塞。这显然违反了之前所说的四个条件中的第三个。 12345678910111213141516171819/* ** 严格轮换法示意** from Modern Operating Systems*//* 进程0 */while(true){t while(turn!=0); critical_region(); // 临界区 turn=1; noncritical_region();}/* 进程1 */while(true){ while(turn!=1); critical_region(); // 临界区 turn=0; noncritical_region();} 互斥的实现方式详解：硬件层面# 屏蔽中断：即使每个进程在刚刚进入临界区后立即屏蔽所有中断，并且在离开临界区时打开中断。屏蔽中断后，时钟中断也被屏蔽，因此不会发生进程的切换，从而也就实现了进程的互斥。 缺点是仅仅适用于单处理系统，但是屏蔽中断对于操作系统本身而言是一项很有用的技术。 专用机器指令 优点是：1、不管是在单处理器还是多处理器上，对任意数量的进程都使用；2、原理很简单并且很容易实现；3、能够支持多个临界资源访问的控制； 缺点是：1、忙等待；2、可能会有饥饿现象（Starvation）；3、可能导致死锁； Semaphore信号量：信号量是一种信号变量，其中它有一个整型值，并且还有一个队列表明阻塞在该信号量上的进程。（注：后续的内容在术语上与《现代操作系统》有出入，但是原理一致）提供了wait和signal两个通信原语（即具有原子性，无法被中断），即以前所说的PV操作。Wait操作对信号量的值做减W法，即：Wait(s): s-1 等价于 P(s) 申请资源可能会阻塞自己（s","link":"/2019/10/20/《现代操作系统》学习笔记-一-进程与线程/"},{"title":"代理模式以及它与装饰模式的异同","text":"文章目录# 一、代理设计模式 组成 分类 静态代理UML结构图 静态代理模式示例 静态代理的局限性 动态代理 动态代理UML结构图 Additional Thinking 二、装饰设计模式 三、二者异同 参考资料 一、代理设计模式#组成#代理模式包含如下角色： Subject：抽象角色。通过接口或抽象类声明真实角色实现的业务方法。 Proxy：代理角色。实现抽象角色，是真实角色的代理，通过真实角色的业务逻辑方法来实现抽象方法，并可以附加自己的操作。 RealSubject：真实角色。实现抽象角色，定义真实角色所要实现的业务逻辑，供代理角色调用。 分类#代理可分为静态代理和动态代理，静态代理需要自己按照上面的UML类图来实现，并且在是在编译时就已经确定了代理，而Java提供了动态代理的方式，在反射包下面的DynamicProxy中，可以通过Proxy来运行时完成动态代理。 静态代理UML结构图# 静态代理模式示例#首先创建抽象角色： 1234567/** 抽象主题角色* 为真实主题角色以及代理主题角色统一接口* */public interface Subject { void doSomething();} 然后创建真实角色并实现抽象角色接口 12345678910/** 真实角色* 实现了抽线角色接口* */public class RealSubject implements Subject,SubjectAnother { @Override public void doSomething() { System.out.println(\"RealSubject doSomething.\"); }} 其次再创建代理角色，同样也实现抽象角色接口，并且代理角色持有真实角色 123456789101112131415161718192021/** 代理角色* */public class Proxy implements Subject { /* * 持有一个真实角色的引用 * */ private Subject realSubject; public Proxy(Subject realSubject){ this.realSubject = realSubject; } @Override public void doSomething() { // 在真实角色接口前附加职责 System.out.println(\"Before realSubject.doSomething().\"); realSubject.doSomething(); // 调用真实角色的相应接口 System.out.println(\"After realSubject.doSomething().\"); }} 最后让我们测试静态代理的效果： 123456789101112131415public class Main { public static void main(String[] args) { // 创建真实角色对象 Subject realSubject = new RealSubject(); // 用代理对象代理真实角色对象 Subject proxySubject = new Proxy(realSubject); // 调用抽象角色定义的接口 proxySubject.doSomething(); }}// 输出结果为：Before realSubject.doSomething().RealSubject doSomething.After realSubject.doSomething(). 静态代理的局限性# 重复性。需要代理的接口越多就要去重复生成一些模板化的代码，不仅麻烦而且不易维护。 脆弱性。一旦接口的定义修改，实现了该接口的真实角色以及代理角色的定义也要修改。 动态代理#JVM可以在运行器件动态生成类字节码（名字为$Proxy0），这种动态生成的类通常用来作为代理类，即动态代理类。JVM生成的动态代理类必须实现一个或多个接口，所以JVM生成的动态类只能用作具有相同接口的目标类的代理，如果要为一个没有实现接口的类生成动态代理类，可以使用CGLIB（实际上这也是SPRING框架除了JDK Proxy之外采用的另外一种生成代理类的方法），这里不对CGLIB作具体介绍。 动态代理UML结构图#Java动态代理运用示例（就用刚才静态代理定义的接口以及真实角色）：首先自定义调用处理器（对代理对象的方法的调用最终都会被委派到自定义调用处理器上）： 12345678910111213141516171819/** 自定义调用处理器，必须实现InvocationHandler接口* */public class InvocationHandlerImp implements InvocationHandler { // 被代理对象 private Object object; public InvocationHandlerImp(Object object){ this.object = object; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(\"Invoke class \"+proxy.getClass()+\" and method \"+method); // Method是在代理对象上调用的方法对应的Method对象 // args是参数列表 return method.invoke(object,args); }} 然后有两种方式创建代理对象:方法一： 12345678910111213141516171819202122public class ProxyTest1 { public static void main(String[] args) { // 实际对象(即要被代理的对象) Subject subject = new RealSubject(); // 调用处理器，传入被代理对象 InvocationHandler invocationHandler = new InvocationHandlerImp(subject); // 为SubjectAnother接口以及Subject接口创建代理Class对象 // 【TIPS】注意接口的传入顺序，并且也要注意到SubjectAnother与Subject有着一个相同的方法签名doSomething() Class proxyClass = Proxy.getProxyClass(ProxyTest1.class.getClassLoader(), SubjectAnother.class, Subject.class); try { // 获取代理对象的构造器 Constructor constructor = proxyClass.getConstructor(InvocationHandler.class); // 通过构造器获取动态代理对象 // 这里不通过Class对象的newInstance()方法创建代理对象的原因是其只能够调用无参构造方法，而Constructor对象则可调用任意构造方法（有参无参多参） Subject proxySubject = (Subject) constructor.newInstance(invocationHandler); // 调用代理对象的接口，最终都会被委派到InvocationHandlerImp中的invoke方法当中 proxySubject.doSomething(); } catch (NoSuchMethodException | InvocationTargetException | InstantiationException | IllegalAccessException e) { e.printStackTrace(); } }} 方法二（实际上就是将方法一的步骤封装起来，可查看源码验证）： 12345678910public class ProxyTest { public static void main(String[] args) { InvocationHandler invocationHandler = new InvocationHandlerImp(new RealSubject()); // Proxy.newProxyInstance方法为我们封装了那一系列步骤 Subject proxySubject = (Subject) Proxy.newProxyInstance(ProxyTest.class.getClassLoader(), new Class[]{SubjectAnother.class, Subject.class}, invocationHandler); proxySubject.doSomething(); }} 为了验证一些在JDK DOC中提到的一些动态代理中的坑，可以看到RealSubject实现了两个接口Subject与SubjectAnother，其中SubjectAnother接口定义如下所示： 123public interface SubjectAnother { void doSomething();} 可以看到SubjectAnother接口定义了一个与Subject接口中方法签名一样的方法。结果输出如下所示（两种方法创建的代理对象调用doSomething结果一致）： 12Invoke class class com.sun.proxy.$Proxy0 and method public abstract void com.qin.proxyTest.SubjectAnother.doSomething()RealSubject doSomething. 可以发现一个问题，无论是在方法一还是在方法二中，我向Handler中传递的都是Subject类型的真实对象的引用，并且代理对象都被我强制转换为Subject接口类型了，那么按道理被代理的接口类型应当是Subject才对，但是从输出结果来看，调用的doSomething()实际上是SubjectAnother中的定义，这是为什么？其实在JDK DOC中已经对这个trick作了说明如下： 【引用来自JDK8 DOC】When two or more interfaces of a proxy class contain a method with the same name and parameter signature, the order of the proxy class’s interfaces becomes significant. When such a duplicate method is invoked on a proxy instance, the Method object passed to the invocation handler will not necessarily be the one whose declaring class is assignable from the reference type of the interface that the proxy’s method was invoked through. This limitation exists because the corresponding method implementation in the generated proxy class cannot determine which interface it was invoked through. Therefore, when a duplicate method is invoked on a proxy instance, the Method object for the method in the foremost interface that contains the method (either directly or inherited through a superinterface) in the proxy class’s list of interfaces is passed to the invocation handler’s invoke method, regardless of the reference type through which the method invocation occurred. 可以注意到我代理接口时是先传入了SubjectAnother.class再传入了Subject.class，由于二者有着一样的方法签名doSomething()，而根据JDK8 DOC的解释，最终传入invoke的Method对象的应用将是传入顺序在前的SubjectAnother接口的doSomething()方法，这与验证结果保持一致。 Additional Thinking#Q：invoke方法中的proxy参数是什么？通过翻阅参考文档以及从参数名就可以推测proxy实际就是生成的动态代理类的引用，还记得我们在动态代理示例中的输出吗，在InvocationHandler的invoke方法中调用proxy.getClass()输出的信息是class com.sun.proxy.$Proxy0，这就是动态代理类，下面可以去验证一下： 首先修改之前的InvocationHandlerImp中的invoke方法，将生成的动态代理类proxy的字节码保存到.class文件当中： 12345678910111213141516171819202122/** 自定义调用处理器，必须实现InvocationHandler接口* */public class InvocationHandlerImp implements InvocationHandler { // 被代理对象 private Object object; public InvocationHandlerImp(Object object){ this.object = object; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { String simpleName = proxy.getClass().getSimpleName(); byte[] bytes = ProxyGenerator.generateProxyClass(simpleName, proxy.getClass().getInterfaces()); // 将代理类proxy的字节码文件保存到$Proxy0.class文件中 BufferedOutputStream ops = new BufferedOutputStream(new FileOutputStream(\"./\"+ simpleName+\".class\")); ops.write(bytes); ops.close(); return method.invoke(object,args); }} 然后就能够得到一个$Proxy0.class文件：然后反编译该字节码文件：javap -p $Proxy0.class 得到结果如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public final class $Proxy0 extends Proxy implements SubjectAnother, Subject { private static Method m1; private static Method m3; private static Method m2; private static Method m0; public $Proxy0(InvocationHandler var1) throws { super(var1); } public final boolean equals(Object var1) throws { try { return (Boolean)super.h.invoke(this, m1, new Object[]{var1}); } catch (RuntimeException | Error var3) { throw var3; } catch (Throwable var4) { throw new UndeclaredThrowableException(var4); } } public final void doSomething() throws { try { super.h.invoke(this, m3, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final String toString() throws { try { return (String)super.h.invoke(this, m2, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final int hashCode() throws { try { return (Integer)super.h.invoke(this, m0, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } static { try { m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", Class.forName(\"java.lang.Object\")); m3 = Class.forName(\"com.qin.proxyTest.SubjectAnother\").getMethod(\"doSomething\"); m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\"); m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\"); } catch (NoSuchMethodException var2) { throw new NoSuchMethodError(var2.getMessage()); } catch (ClassNotFoundException var3) { throw new NoClassDefFoundError(var3.getMessage()); } }} 在静态代码块里对m0,m1,m2,m3进行了初始化，可以看到，不仅被代理接口自己声明的doSomething接口会被委派到invoke函数，被代理对象从Object继承的equals(),toString()以及hashCode()方法也会被自动委派（实际上这个在API文档中有提到！） 然后我们查看该代理类的doSomething()方法，实际上就执行了这一行： 1super.h.invoke(this, m3, (Object[])null); 而super.h实际上就是父类Proxy中的一个保护成员： 1234/*** 此声明来源于JDK8 Proxy类的源码*/protected InvocationHandler h; 因此上面那行代码实际上就是调用了我们自定义的InvocationHandlerImp中定义的invoke方法，而给proxy参数传递的引用是this，也就是生成的动态代理类$Proxy0的对象的this引用，可见proxy参数就是代理类的引用！ 二、装饰设计模式#在我的另外一篇博文中已经讨论过：浅谈装饰器设计模式Java I/O结合装饰器模式的一点理解 三、二者异同#关于二者异同，由于个人水平所限，我查阅了很多资料，但是似乎没有一个特别标准的回答，在这里，我会将自己所看到的大多数人都认同的点进行简单的归纳（或许会持续更新），以及附上原文链接。相同点： 如你所见，二者的结构是类似的 不同点： 应用场景不同。Proxy常用来延迟实例化(Lazy-instantiate)被代理对象，隐藏远程服务( Hide Remote Service)，控制对被代理对象的访问权限等，典型例如Hibernate框架的延迟加载就是通过动态代理实现的；而Decorator又称为“智能代理”(Smart Proxy)，它使得你可以在运行时向对象添加功能，典型例如new BufferedInputStream(new FileInputStream(...))等。 Decorator通常允许“链式叠加”（非准确描述），而Proxy则不允许。例如在C++中的Stream* aStream = new CompressingStream(new ASCII7Stream(new FileStream(\"fileName.dat\")))，而代理往往不能够这样; Decorator强调的是职责附加(Additional Responsibility)，提供增强的接口(enhanced interface)而Proxy往往强调对被代理对象的访问控制等并提供相同的接口(Same interface) 参考资料 【StackOverflow】Differences between Proxy and Decorator Pattern【StackOverflow】How do the Proxy, Decorator, Adapter, and Bridge Patterns differ?","link":"/2019/11/19/代理模式以及它与装饰模式的异同/"},{"title":"关于动态规划的一点简单思考","text":"文章目录# 零、鸣谢 一、写这篇博客的背景 二、要不，先上个萝卜丁开开胃？ 例子概览 Maximal Square Brust balloons version-0 回溯法未优化版 version-1 记忆优化版本回溯 version-2 动态规划版本 Shortest Common Supersequence Wildcard Matching 三、别问，问就是使劲刷题 四、没什么用的技巧总结 五、动态规划入门模型回顾 参考资料 零、鸣谢#感谢室友祁挣斌友情制作动态图 一、写这篇博客的背景#为了面试，这段时间，在leetcode上刷刷算法题，做了很多道题之后，在Best Time to Buy and Sell Stock IV这道题始终超内存不知该如何解决的时候，在讨论区看到了Most consistent ways of dealing with the series of stock problems用同一个套路解决leetcode中六道关于股票买卖的题目，让我大开眼界，也让我只能感叹自己之前解决的几个股票买卖的解法就是shit。总而言之，这篇非常优秀的文章给予了我打算写这篇博客的源动力，其次，就是想把这几天集中训练动态规划题目的一点小小收获与感想记录下来，便于日后复习。 二、要不，先上个小菜？#俗话说，”talk is cheap,show me the code”，因此通过几个例子来完整记录一下自己对几个典型题目的解决方式。(不会附上题目，可通过点击链接进入leetcode主页自行查看题目描述)用到了4个题目作为例子，难度为中等、困难、困难以及困难，如下所示： 例子概览# #221 Maximal Square #312 Brust balloons #1092 Shortest Common Supersequence #44 Wildcard Matching Maximal Square#题目描述：Maximal Square 这道题很简单，定义： dp[i][j]为以matrix[i][j]为左上角的最大正方形的边长 边界条件： $dp[rowThresh - 1][k] = matrix[rowThresh - 1][k] - ‘0', 0≤ k","link":"/2019/12/17/关于动态规划的一点简单思考/"},{"title":"浅谈Java线程池","text":"文章目录# 浅谈Java线程池（jdk1.8) 线程池状态部分 构造函数中的参数部分 线程池提供的hook function 初探execute(Runnable command)方法 线程池的核心:Worker 理清脉络 浅谈Java线程池（jdk1.8)# 本博客来源于自己在看JDK线程池源码时，边看边同步写下的笔记，因此排版基本没有，希望见谅； 仅仅只是分析了比较核心的实现，限于个人目前的水平，尚有不理解之处，写的内容也可能有差错，非常乐意接受您的指正与建议； 对于线程终止，shutdown()与shutdownNow()我觉得没必要说，因为源代码很清晰，阅读者这部分代码也没什么难度，因此没有说这一部分 线程池状态部分# 使用一个AtomicInteger类型的ctl来存储wokerCount和线程池运行状态runSate，其中高3位用来存储runState，而低29位存储wokerCount，因此在jdk1.8的设计当中，有效线程数量最多是2^29-1,而不是2^31-1; 线程池有五种运行状态： RUNNING:能够接受新的任务并且能够处理队列中的任务。数值为0xE0 00 00 00(也就是高三位为1，后29位为0); SHUTDOWN:不能接受新的任务，但是还能处理队列中的任务。数值为0x00 00 00 00; STOP:不能接受新的任务，也不能处理队列中的任务，等待终止正在进行中的任务。数值为0x20 00 00 00; TIDYING:所有的任务都已经终止，wokerCount等于0。数值为0x40 00 00 00; TERMINATED:terminated()方法已经完成，则进入该状态。数值为0x50 00 00 00; 之所以这样安排线程池的运行状态的数值，是为了方便通过数值大小的比较，可以发现从数值上来说RUNNING TERMINATED（当terminated()钩子方法调用结束，terminated()方法是一个protected的空方法，可以通过继承来重写该方法，当线程池状态转变为TIDYING时将会调用该方法，该方法调用完成之后线程池就会进入TERMINATED状态，当线程池进入TERMINATED状态时awaitTermination()方法才会返回； （TEMP）检测线程池是否能从SHUTDOWN进入TIDYING状态有trick,（在队列非空之后可能变为空，在关闭状态下，队列也可能变为空，但是我们只能在wokerCount为0(有时需要重新检查)的情况下才能终止）； 1234567891011121314151617181920private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3;private static final int CAPACITY = (1","link":"/2019/10/28/浅谈Java线程池/"},{"title":"浅谈装饰器设计模式","text":"文章目录：# 一、概念 二、结构 如何理解装饰器设计模式的运行原理？ 下面给出一个简单的示例 一、概念# 《Thinking in Java》: 装饰器模式使用分层对象来动态透明地向单个对象中添加责任。装饰器指定包装在最初地对象周围地所有对象都具有相同的基本接口。某些事物是可装饰的，可以通过将其它类包装在这个可装饰对象的四周，从而将功能分层，这使得对装饰器的使用是透明的——无论对象是否被装饰，你都拥有一个可以向对象发送的公共消息集。 二、结构#结构如下图所示（图片来源于互联网）：在装饰器模式中有如下一系列角色： 抽象构件角色（component）：给出抽象接口，规范准备接收附加责任的对象； 具体构件角色（Concrete Component）：定义一个将要接收附加责任的对象： 装饰角色（Decorator）：持有一个构件对象的实例，并且实现了抽线构件规定的接口； 具体装饰角色（Concrete Decorator）：负责给构件对象增加附加的责任； 如何理解装饰器设计模式的运行原理？#在上图中，ConcreteDecoratorA与ConcreteDecoratorB都是具体装饰器，它们的构造函数接收一个具体构件（Concrete Component）角色对象，由于具体装饰器器继承自装饰角色，其内部都声明了一个能够指向具体构件的变量，因此该变量最后会指向我们向装饰器传递的具体构件的对象，而具体装饰器角色对象也有具体构件角色的接口（这就是抽象构件角色所起到的作用之一，规范接口），因此，装饰器就可以调用具体构件的接口了，并且，还可以增加功能。 下面给出一个简单的示例#抽象构件 123public interface Component{ public void operation();} 装饰角色 123456789101112public class Decorator implements Component{ protected Component component; public Decorator(Component component){ this.component = component; } @override public void operation(){ // 可以增加功能，调用具体构件的接口 component.operation(); }} 具体装饰器角色 123456789101112pubic class SpecialDecorator extends Decorator{ public SpecialDecorator(Component component){ super(component); } @override public void operation(){ // 可以增加功能，也可以调用具体构件接口 super.operation(); System.out.print(\"我是具体装饰器角色增加的功能\"); }} 具体构件角色 123456public class ConcreteComponent implements Component{ @override public void operation(){ // 业务代码 }}","link":"/2019/10/11/浅谈装饰器设计模式/"},{"title":"【译文】The end of the Redis adventure.antirez.","text":"版权©️归属# 原文引用 - The end of the Redis adventure - antirez Redis这场冒险的终点# When I started the Redis project more than ten years ago I was in one of the most exciting moments of my career. My co-founder and I had successfully launched two of the major web 2.0 services of the Italian web. In order to make them scalable we had to invent many new concepts, that were already known in the field most of the times, but we didn’t know, nor we cared to check. Problem? Let’s figure out a solution. We wanted to solve problems but we wanted, even more, to have fun. This was the playful environment where was born. 10年多之前我启动Redis项目的时候，正处于我事业最令人激动的时刻之一，我同我的合伙人成功地启动了意大利网络的两个主要的Web 2.0服务，为了使得它们具有足够的伸缩性，我们不得不发明许多新的概念，尽管这些概念在该领域已经被多数人熟知，但是我们不知道，也不想去检查。存在问题？那就让我们找出解决方案吧。我们想解决问题，但我们更想获取乐趣，这也就是Redis项目创始时的背景了，很有意思。 But now Redis is, incredibly, one of the main parts of so many things. And year after year my work changed from building this thing to making sure that it was also as useful as possible, as reliable as possible. And in recent years, what I do every day changed so much that most of my attention is spent in checking what other developers tell me about the Redis code, how to improve it, the changes it requires to be more correct or faster or more secure. However I never wanted to be a software maintainer. 难以置信，Redis如今已经是许多项目的主要部分之一了。一年又一年，我的工作从构建Redis变成了确保它尽可能的有用，尽可能的可靠。在最近这几年，我每天要做的事情改变了非常多，每天我都要花大量精力去检查其它开发人员对我说的关于Redis代码的问题，如何改进代码以及那些需要更正确、更快速或者更安全的更改上。然而，我并不想成为一个软件维护者。 I write code in order to express myself, and I consider what I code an artifact, rather than just something useful to get things done. I would say that what I write is useful just as a side effect, but my first goal is to make something that is, in some way, beautiful. In essence, I would rather be remembered as a bad artist than a good programmer. Now I’m asked more and more, by the circumstances created by a project that became so important, to express myself less and to maintain the project more. And this is indeed exactly what Redis needs right now. But this is not what I want to do, and I stretched myself enough during the past years. 我写代码是为了表达我自己，我将我写的代码视作手工艺品而不仅仅是一个能够解决问题的有用的东西，我想说的是，我写的代码有用仅仅只是因为它的副作用就是它有用，但是我的首要目标是写出在某种程度上很漂亮的东西。本质上，我宁愿作为一个坏艺术家而不是一个好的程序员而被世人铭记。如今，在一个非常重要的项目所创造的环境下，我被问得越来越多，越来越少去表达我自己，而更多的是在维护这个项目。的确，这是Redis目前需要的，但是这样的状态不是我想要的，在过去的几年里，我也一直在提升自己。 So, dear Redis community, today I’m stepping back as the Redis maintainer. My new position will be, on one side, an “ideas” person at Redis Labs, in order to provide inputs for new Redis possibilities: I’ll continue to be part of the Redis Labs advisory board. On the other hand however my hands will be free, and I’ll do something else, that could be writing code or not, who knows, I don’t want to make plans for now. However I’m very skeptical about me not writing more code in the future. It’s just too much fun :D 所以，亲爱的Redis社区，今天我就不再作为Redis的维护者了。我的新的定位，一方面将会是作为Redis实验室的“军师”，以便能为Redis新的可能性提出建议：即我将成为Redis实验室顾问委员会的一员。但是从另外一方面来说，我也就空闲下来了，我会做些别的什么，或许是写代码也可能不是，谁知道呢，我现在不想制定计划。然而，我对将来我是否会写更多的代码特别怀疑，因为写代码实在是太有趣了:D I leave Redis in the hands of the Redis community. I asked my colleagues Yossi Gottlied and Oran Agra to continue to maintain the project starting from today: these are the people that helped me the most in recent years, and that tried hard, even when it was not “linear” to follow me in my very subjective point of views, to understand what my vision on Redis was. Since I don’t want to be part of how the new Redis development setup will be shaped (that is the most meta of the maintenance tasks, exactly what I want to avoid), I’ll just leave Yossi and Oran the task of understanding how to interface with the rest of the Redis developers to find a sustainable development model, you can hear directly from Yossi and Oran in this blog post:https://redislabs.com/blog/new-governance-for-redis/ 我将Redis交给Redis社区，并且请我的同事Yossi Gottlied和Oran Agra从今天开始继续维护这个项目，他们是这些年帮助我最多的人，即使他们并不总是完全认同我的十分主观的观点，不完全了解我对Redis的看法，但是他们也十分努力了。由于我不想成为了解未来Redis的开发计划将如何制定的一员（这是维护任务中最重要的部分，也正是我想避免的事情），我把负责理解如何与其余的Redis开发人员找到一个可持续发展模型的任务交给了Yossi和Oran，你可以通过以下链接的博客文章中直接了解到具体发展：https://redislabs.com/blog/new-governance-for-redis/ I believe I’m not just leaving Redis in the hands of community of expert programmers, but also in the hands of people who care about the legacy of the community spirit of Redis. In eleven years I hope I was able to provide a point of view that certain persons understood, about an alternative way to write software. I hope that such point of view will be taken into consideration in the evolution of Redis. 我相信我把Redis不仅仅交给了专家程序员，也交给了那些在乎Redis社区精神遗产的人。希望在11年后，我能就可替代的写软件的方法，提供某些人能理解的点子，我希望Redis未来的发展也能够考虑这些点子。 Redis was the most stressful thing I did in my career, and probably also the most important. I don’t like much what the underground programming world became in recent years, but even if it was not an easy journey, I had the privilege to work and interact with mant great individuals. Thank you for your humanity and your help, and for what you taught me. You know who you are! I want to also say thank you to the companies and individuals inside such companies that allowed me to write open source every day for so many years, with the freedom to do what I believed to be correct for the user base. Redis Labs, VMware and Pivotal, thank you for your great help and generosity. Redis是我职业生涯中做的最有压力的，也可能是最重要的一个项目。虽然我并不喜欢近几年背后编程界的发展，但是即使这不是一段轻松的旅程，我仍然有幸与许多优秀的人一起工作、交流，感谢你们的宽容与帮助，感谢你们所教给我的，你们知道你们是谁！我还要对那些公司以及那些公司里的人表示感谢，正是他们，在这么多年的时间里，允许我每天写开源代码，并且可以自由地做我所认为的对于用户来说正确的事情。Redis实验室，VMware和Pivotal，感谢你们的大力支持和宽宏大量。 As I said, I don’t really know what there is for me in my future, other than the involvement with the Redis advisory board. I guess that for some time, just look around is a good idea, without doing too many things. I would like to explore more a few hobbies of mine. Writing blog posts is also a major thing that I wanted to do but did less and less because of time concerns. Recently I published videos in Italian language explaining technological concepts to the general public, I had fun doing that and received good feedbacks, maybe I’ll do more of that as well. Anyway I guess some of you know that I’m active on Twitter as @antirez. If you are interested in what an old, strange programmer will do next, see you there. 正如我所说，除了参加Redis顾问委员会之外，我真的不知道在未来等待我的是什么。我想，在未来的一段时间里，只是四处看看会是个好主意，不要做太多事情。我想探索更多业余爱好，写博客也是一件主要的我想做的事情，但是由于时间上的考量，我做的越来越少。最近我发布了意大利语的视频来向大众介绍技术概念，我乐在其中并且也收到了很不错的反馈，可能我也会做更多这样的视频。无论如何，我想你们当中有些人知道我在Twitter上以@antirez的身份活跃着，如果你对一个老而陌生的程序员接下来将会做些什么感兴趣，那就相见于Twitter吧。 Statement# 业余翻译，业余爱好，如有建议请发邮件至staunchqyt@163.com 原文内容版权归属原文作者所有@antirez，翻译内容仅供学习、交流之用。","link":"/2020/07/01/【译文】The-end-of-the-Redis-adventure-antirez/"},{"title":"高速缓存模拟器:Cache Simulator","text":"文章目录# 一、题目说明 相关说明 测试用例以及得分点 二、代码 三、结果测试一、题目说明#相关说明#self-study student可以在CMU相关官网上下载到相应的lab resource以及对lab的英文文档说明，下载传送门：Lab resource[PDF] 测试用例以及得分点#根据说明文档，我做的时候抽取出来的几个关键点，包括格式，注意事项，得分点，以及测试用例：说明文档中，没有给出测试用例的结果，我这里全部测出来了，如下表所示： s E b hit_counts miss_counts eviction_counts test trace files 分值 1 1 1 9 8 6 yi2.trace 3 4 2 4 4 5 2 yi.trace 3 2 1 4 2 3 1 dave.trace 3 2 1 3 167 71 67 trans.trace 3 2 2 3 201 37 29 trans.trace 3 2 4 3 212 26 10 trans.trace 3 5 1 5 231 7 0 trans.trace 3 5 1 5 265189 21775 21743 long.trace 6 二、代码#话不多说，直接上代码，关于函数接口的设计以及算法和一些细节上的问题已经注释了： 编译时的指令为:gcc -Og -o my_csim_ref csim.c cachelab.c 得到一个可执行文件my_csim_ref 如果代码有问题，可以用gdb调试 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179#include \"cachelab.h\"#include#include#include #define BUFSIZE 30 void get_opt(); // 获取参数void init_cache(); // 初始化cache，分配内存void del_cache(); // 程序结束时释放申请的内存void load_block(int address,int size); // load指令void modify_block(long address,int size); // modify指令void store_block(long address,int size); // store指令int tag(long address); // 根据地址返回标记值int set_index(long address); // 根据地址返回组索引 // 行typedef struct{ int flag; long tag; long latest_access_time;}cache_line; // 组，为了更加地形象所以这么写，组中有一个指向组内缓冲行的指针typedef struct{ cache_line *data_lines;}set; set *cache=NULL; // cache指针int S=0,E=0,B=0;int hit_counts=0,miss_counts=0,eviction_counts=0;long my_clock=0; // 简单使用一个长整型来抽象表达时间，不科学，但是有效char *file=NULL; // 保存要用的traces测试文件的文件名，文件名在get_opt()中获取 int main(int argc,char **argv){ get_opt(argc,argv); init_cache(); FILE *test_file_ptr=fopen(file,\"r\"); // 打开测试文件 char instruction[BUFSIZE]; long addr; int size; char buffer[BUFSIZE]; while(fgets(buffer,BUFSIZE,test_file_ptr)!=NULL) { // 这里有两个细节问题，首先不能用%c来读取instruction(即说明文档中提到的L,M,S) // 因为一开始我是用的%c,但是我打印出来后发现和期望值不同 // 其次就是，CMU给的说明文档中说了测试用例中的地址实际上是16进制，我一开始就是 // 当十进制了，结果调试很久很久 sscanf(buffer,\"%s %lx,%d\",instruction,&addr,&size); long address=(long)addr; if(*instruction=='L')load_block(address,size); else if(*instruction=='M')modify_block(address,size); else if(*instruction=='S')store_block(address,size); } printSummary(hit_counts,miss_counts,eviction_counts); // 打印结果 del_cache(); // 释放内存 return 0;} void get_opt(int argc,char **argv){ int c; while((c=getopt(argc,argv,\"s:E:b:t:\"))!= -1) { switch(c) { // atoi将字符串转换为数字 case 's':S=atoi(optarg);break; case 'E':E=atoi(optarg);break; case 'b':B=atoi(optarg);break; case 't':file=optarg;break; // 测试文件traces的文件名 } }} void init_cache(){ int i,j,set_num=1","link":"/2019/11/17/高速缓存模拟器-Cache-Simulator/"},{"title":"踩过的Mybatis坑及一些注意事项总结","text":"文章目录# 一、Mybatis注意事项以及踩过的坑 Mybatis主配置文件注意事项 package SqlSession select insert,update,delete sql resultMap结果映射（最关键也非常重要） 不使用resultMap标签配置结果映射 一对一 一对多 多对多 二、Mybatis缓存机制 一级缓存 二级缓存 三、Mybatis延迟加载 一、Mybatis注意事项以及踩过的坑#Mybatis主配置文件注意事项# 配置项标签的顺序很重要，不按照文档中介绍的顺序来配置就会报错（但是可以缺少配置项）。 如果想要使用第三方DataSource，那么就可以通过实现DataSourceFactory接口来使用第三方数据源，例如Druid连接池等。然后再在dataSource type属性中配置上该实现类的名称即可，另外，为该第三方数据源配置的配置项根据使用数据源的不同而有所不同，Mybatis只是解析你所配置的属性。以Druid连接池为例，通过自己实现DataSourceFactory接口，里面有两个方法，一个是setProperties，这个方法的参数properties是mybatis自动解析了主配置文件中你所配置的属性得到的（可以自己输出验证一下，确实是这样），而Druid连接池产生DataSource往往通过DruidDataSourceFactory.createDataSource(properties)，因此你就能理解我前面所说的配置项要根据使用数据源的不同而有所不同的含义啦。 package#在mybatis主配置文件的别名配置中使用package标签可以配置包名，通过这种方式能够简化对该包下的类的访问。例如在主配置文件配置了，那么在以后需要引用到该包下的JavaBean的时候，就不要加上这个包名了，直接使用类的名称即可。 SqlSession# 默认情况下，SqlSession是不会开启autocommit的，即默认情况下，一个SqlSession就是一个事务，因此，若更新了数据库就需要调用SqlSession.commit()来提交,若更新发生异常需要调用SqlSession.rollback()进行事务的回滚（在这里发现了一个MySQL自增主键的坑，由于自增主键的值是存放在内存当中的，并且不会因为事务的回滚而使自增主键的值减小，因此倘若插入失败，那么就会导致自增主键的值在数据库中不再连续） 通常我们在使用mybatis时，都是定义dao层接口，以及相应的sql语句，让mybatis来帮我们完成数据的查询与封装，而实际上，当你调用getmapper方法时，实际上在mybatis的内部会把调用getmapper的sqlsession对象的this引用传递到底层的函数，到最后，实际上就是调用了sqlsession的那些方法完成数据的查询的：例如selectList等（可以自己查看源码验证）。因此，除了使用mybatis提供的代理对象的方式，还可以自己实现Dao层接口，在内部直接使用sqlsession的那些方法然后再自己完成封装同样也能完成Dao层的功能。 select# id名不能够相同（update等同理），因此通过Mybatis来实现Dao层接口没法实现方法的重载，通过看一些博客，发现可以通过在Service层实现方法的重载，但是在Dao层不使用重载，这时候又会产生一个新的问题，如果希望能够在Service层实现重载，那么Dao层提供的接口必然就需要查询很多参数，那应该如何实现接口的高可用性呢？目前我觉得可以使用Mybatis的动态SQL的特性来解决，让Dao层的接口可以接受很多的必要的参数，但是可以传入无效值，例如Null，然后通过动态SQL的IF等达到动态构建SQL语句的功能。 parameterType是可选参数，即便不写，Mybatis也可以通过类型处理器（TypeHandler）来推断出具体传入语句的参数 如果希望能够有多个参数，那么有几种实现方式，（1）直接使用arg0-argn(n的取值取决于Dao层接口方法的参数个数）；（2）在Dao层接口的参数配置上@Param注解，这样就可以在Mapper的配置文件中使用你在@Param中为该参数设置的名称了；（【注】我个人觉得根据不同的情况前面两种方式实际上都可行）；（3）在Dao层接口中传入Map，通过设置Map的K-V来实现多参数，这样就可以在Mapper的配置文件中使用Map的K值了（不推荐这种方式，绝对代码维护火葬场） 如果参数允许null值，那么根据JDBC的规范，必须在参数中指定JDBC Type，例如#{age,jdbcType=NUMERIC} insert,update,delete#在这三种映射标签中，会让人产生疑惑的是useGeneratedKeys和keyProperty两个属性，实际上就是当数据库表的主键是自动增长的时候（例如MySQL中的autoincrement），调用insert或者update的时候是肯定没办法拿到该主键的，那么这时候就可以通过设置userGeneratedKeys为true，并且为keyProperty设置一个名字（例如可以设置为keyProperty=“id_autoIncrement”）那么执行该SQL语句之后会返回主键值，在Java代码中就能够获取该主键对应的对象的属性值（即通过我所配置的keyProperty的值“id_autoIncrement”）。例如，UserDao接口定义了int addUser(User user)方法，一开始user对象的id值尚未初始化，因为该user还没有被添加进数据库，因此它还没有id，但是执行了insert方法之后，由于设置上面那个属性，这时调用user.getId()就会返回该user对象插入到数据库之后由数据库自动增长生成的Id值，相反，如果没有设置上面那两个属性，调用user.getId()就不会返回Id值。还有我猜测addUser方法返回的结果是不是也是Id值？经验证不是，只是插入成功的行数而已。 sql#搭配include标签可重复利用SQL代码段。没有什么特别的注意事项吧，看看官方文档还有博客就行。 resultMap结果映射（最关键也非常重要）#不使用resultMap标签配置结果映射#数据库中的列名与相应的JavaBean中的属性名不匹配怎么办？（1）用select as别名的方式；（2）使用resultMap标签来创建数据库列名到JavaBean的属性名的映射关系，然后在相应的SQL语句映射里面的resultMap属性配置上你使用resultMap标签创建的映射关系即可。 一对一#associate标签用来描述“一对一”的关系。例如，一个人有一个博客，在项目domain中可能有User和Blog，这时想要查询User对象以及对应的Blog，SQL语句有可能是这样的：select u.*,b.id as bid,b.title,b.brief from user u,blog b where u.id=b.id;相应的，若要建立相应的结果映射ResultMap就应当是这样的： 1234567891011 一对多#collection标签用来描述“一对多”的关系。例如，一个人可以有多个账单，假设在项目的domain中User有一个私有成员private List bills;那么此时对应的查询SQL语句可能是这样的： 123select u.*,b.id as bid,b.date as date,b.money as money from user u left outer join blog b on u.id = b.uid``` 并且最终的结果映射可能是这样的： 123456789101112131415161718### 多对多“多对多”的关系同样可以用collection标签来描述。例如考虑这样一个应用场景，一个人可以有多种角色（例如职员，董事等），而一个角色也能够被赋予给多个人，假设在项目中的domain中对“人”以及“角色”有相应的JavaBean如下所示(省略getter和setter等方法，懒得写）： ```javapackage cn.uestc.domainpublic class User{ private int id; private String password; private String telephone; private List roles;}package cn.uestc.domainpublic class Role{ private in id; private String roleName; private List users;} 而在数据库当中，除了对应的User表和Role表之外，由于是M:N的关系，需要有第三张表描述这个关系： 123456create table if not exist user_role(uid int not null,rid int not null,constraint user_role_uid_fk_ref_user foreign key (uid) references user(id) on delete cascade on update cascade,constraint user_role_rid_fk_ref_role foreign key (rid) references role(id) on delete cascade on update cascade)engine=InnoDB; 那么想实现，查询user以及该user被赋予的角色最终的Sql语句可能是这样的: 123select u.*,r.id as rid,r.rolename as rolename from user u left join user_role ur on u.id=ur.uid left join role r on ur.rid=r.id; 那么结果映射可能就是这样的： 123456789 同理，想要查询role以及被赋予了role角色的user最终的sql语句可能是这样的： 123select u.*,r.id as rid,r.rolename as rolename from role r left join user_role ur on r.id=ur.ridleft join user u on u.id=ur.uid; 相应的结果映射为： 123456789 二、Mybatis缓存机制#Mybatis有两级缓存，默认仅开启一级会话缓存，而二级缓存需要自己配置。 一级缓存#一级缓存的作用域是SqlSession对象，在每个SqlSession对象中都有一个Map作为缓存，当在同一个SqlSession对象上执行同样的查询操作时，第二次不会执行SQL语句，而是直接从SqlSession内部的Map当中取出对象返回，可以这样来验证： 1234567891011121314151617181920212223public class Test{ @Test public void test0(){ SqlSession sqlSession0 = MybatisUtil.getSqlSession(); UserDao userDao0 = sqlSession0.getMapper(UserDao.class); User user0 = userDao0.findUserById(1); User user1 = userDao0.findUserById(1); sqlSession0.close(); SqlSession sqlSession1 = MybatisUtil.getSqlSession(); UserDao userDao1 = sqlSession1.getMapper(UserDao.class); User user2 = userDao1.findUserById(1); if(user0==user1){ System.out.println(\"Yes\"); } if(user0!=user2){ System.out.println(\"No\"); } }}输出结果应该是：YesNo 因此关闭了SqlSession，相应的一级缓存也会被清空。 二级缓存#二级缓存的作用域是mapper，默认是不会开启二级缓存的，需要在mapper配置中加上标签，并且对Sql语句使用useCache属性，这样就能开启二级缓存了，关于二级缓存的特性与更多配置，在Mybatis的官方文档解释得非常清楚，就不再多说，仅仅记录几个关键的点： 二级缓存作用域是mapper，跨sqlsession； 开启了二级缓存之后，一级缓存就失效了，查询语句都直接从二级缓存中拿数据； 二级缓存能够将对象序列化，因此Domain的JavaBean需要实现Serializable接口，否则会报错； 二级缓存能够自定义，只需要实现Cache接口就行，例如可以用Redis来实现一个分布式的二级缓存； 当调用了插入，更新等语句之后会清空二级缓存，注意上面说到二级缓存是作用域是mapper，也就是该mapper的二级缓存都会清空，因此，为了提高性能，有时候需要将那些不常更新的数据单独放在一个mapper当中。 三、Mybatis延迟加载#在Django框架的ORM系统中，同样有着这样的机制，即查询是“惰性”的，只有需要用到的时候才会执行查询，没有用到的时候不会执行查询，从而优化内存的使用。Mybatis的延迟加载也是类似的，但是Mybatis并不是默认这样的机制，需要在主配置文件的settings中进行配置才行，在Mybatis官方文档中对于延迟加载这个配置项这样描述： lazyLoadingEnabled：延迟加载的全局开关。当开启时，所有关联对象都会延迟加载,特定关联关系中可通过设置 fetchType 属性来覆盖该项的开关状态。aggressiveLazyLoading：当开启时，任何方法的调用都会加载该对象的所有属性。 否则，每个属性会按需加载（参考 lazyLoadTriggerMethods)。 因此想要使用延迟加载，首先需要在主配置文件当中将lazyLoadingEnabled与aggressiveLazyLoading设为true。其次，在配置resultMap时不能够完全按照上面来，以上面所说的“一对一”的关系为例： 1234567891011 若想实现延迟加载需要这样来配置： 1234567 并且除此之外还需要实现一个selectBlog（额外思考，这是如何实现的?我觉得是使用了代理，代理了JavaBean对象，并且拦截了getBlog()方法，并且假如的确是使用了代理，考虑到Java动态代理仅能对接口生效，因此，这里必然是使用CGLIB来完成代理功能的，实际上也确实是这样的，可去查看源码！）： 123 select * from blog where id=#{id}; 相应的还需要一个SQL语句： 1select * from user 这时，当业务调用查询user的Dao层接口时，不会立即将blog查询，而是当用到的时候才会执行（例如执行完查询user之后返回的user对象，调用user.getBlog()方法，将导致上面的selectBlog执行）。此外，这里有一个点，就是associate标签中的column应该怎么取数据库中的哪一列？官方文档是这么解释的： select：用于加载复杂类型属性的映射语句的 ID，它会从 column 属性中指定的列检索数据，作为参数传递给此 select 语句。具体请参考关联元素。 答案就很明显了，可以看到selectBlog中使用到id作为参数，那么associate中也要对应，并且更重要的是，查询列表得有叫id的列，从resultMap的配置来看，显然是满足了这些要求的。 不过这样的方式对于大数据集存在N+1的问题，并且会产生严重的性能问题。Mybatis推荐了另外一种方式，resultMap的嵌套映射，详情可参考Mybatis官方文档。同样继续改进上面的那个例子： 12345678910111213 此时就不能像上面用select属性一样，单独有一个SQL语句，而应该这样使用整体的SQL语句，但是，这种方式没有延迟加载的效果，其实也能发现和之前直接放入associate，不使用associate的resultMap属性是完全一样的，不同的是，这样可以复用resultMap，所以也很不错： 1select u.*,b.id as bid,b.title as title,b.brief as brief from user u,blog b where u.id=b.uid;","link":"/2019/11/25/踩过的Mybatis坑及一些注意事项总结/"}],"tags":[{"name":"6.S081","slug":"6-S081","link":"/tags/6-S081/"},{"name":"No-tags","slug":"No-tags","link":"/tags/No-tags/"},{"name":"并发控制","slug":"并发控制","link":"/tags/并发控制/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"设计模式","slug":"设计模式","link":"/tags/设计模式/"},{"name":"MIT6.828","slug":"MIT6-828","link":"/tags/MIT6-828/"},{"name":"csapp","slug":"csapp","link":"/tags/csapp/"},{"name":"数据库","slug":"数据库","link":"/tags/数据库/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"操作系统","slug":"操作系统","link":"/tags/操作系统/"},{"name":"进程","slug":"进程","link":"/tags/进程/"},{"name":"线程","slug":"线程","link":"/tags/线程/"},{"name":"互斥","slug":"互斥","link":"/tags/互斥/"},{"name":"临界区","slug":"临界区","link":"/tags/临界区/"},{"name":"Algorithms","slug":"Algorithms","link":"/tags/Algorithms/"},{"name":"线程池","slug":"线程池","link":"/tags/线程池/"},{"name":"杂记译文","slug":"杂记译文","link":"/tags/杂记译文/"},{"name":"Mybatis","slug":"Mybatis","link":"/tags/Mybatis/"}],"categories":[{"name":"操作系统","slug":"操作系统","link":"/categories/操作系统/"},{"name":"Unclassified","slug":"Unclassified","link":"/categories/Unclassified/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"6.S081","slug":"操作系统/6-S081","link":"/categories/操作系统/6-S081/"},{"name":"MIT-6.828-OSE","slug":"操作系统/MIT-6-828-OSE","link":"/categories/操作系统/MIT-6-828-OSE/"},{"name":"csapp","slug":"操作系统/csapp","link":"/categories/操作系统/csapp/"},{"name":"并发控制","slug":"Java/并发控制","link":"/categories/Java/并发控制/"},{"name":"Java编程语言","slug":"Java/Java编程语言","link":"/categories/Java/Java编程语言/"},{"name":"数据库","slug":"数据库","link":"/categories/数据库/"},{"name":"设计模式","slug":"设计模式","link":"/categories/设计模式/"},{"name":"algorithms","slug":"Java/algorithms","link":"/categories/Java/algorithms/"},{"name":"译文","slug":"译文","link":"/categories/译文/"},{"name":"Framework","slug":"Framework","link":"/categories/Framework/"},{"name":"MySQL","slug":"数据库/MySQL","link":"/categories/数据库/MySQL/"},{"name":"杂记","slug":"译文/杂记","link":"/categories/译文/杂记/"},{"name":"Mybatis","slug":"Framework/Mybatis","link":"/categories/Framework/Mybatis/"}]}