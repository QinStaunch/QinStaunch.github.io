{"pages":[{"title":"文章分类","text":"1 1.1 1.2234","link":"/categories/index.html"}],"posts":[{"title":"About me and the blog","text":"Welcome~(｡•ᴗ-)_#关于我# 电子科技大学学生 主要从事Java后端、Python数据挖掘与分析 热爱编程、骑行、刷剧、看电影、喝奶茶，业余时间也喜欢学习与深度学习相关的知识 关于该博客# 基于hexo与icarus构建 Hexo：A fast,simple and powerful frameworkIcarus：A simple, delicate, and modern theme for the static site generator Hexo 记录学习笔记与总结，骑行经历 Tips# 如果你在浏览博文中有任何疑问，欢迎与我交流，或者留言给我 如果你也想构建自己的技术博客，但是在对照官方文档给出的构建方式进行构建时产生任何bug或者疑问，也可以留言给我 如果你也曾和我一样，是一个计算机小白，想入行cs，却苦于不知该如何入手，也欢迎向我提问~","link":"/2019/09/30/About-me-and-the-blog/"},{"title":"MySQL学习笔记（一）：存储引擎和事务","text":"一、如何阅读官方文档#官方中文文档传送门：MySQL5.1中文文档重点关注： 第七章 优化 第十一章 列类型 第十三章 SQL语句语法 第十五章 存储引擎和表类型 更好地阅读文档：注意方括号 [] 意味着该字段可以省略，也就是可选字段；当要用到圆括号字段修饰的字段的时候，圆括号()不可以省略；大括号{}意味着在该字段的给定值中进行选择，| 这个符号就意味着选择呗；啥符号都没带的就是必填字段呗。例如下面由MySQL官方文档给出的select语法：像[all | distinct | distinctrow] 这个字段本身是可选字段，写select语句的时候可加可不加，但是如果加上该字段的时候，就要在all，distinct，distinctrow中选择一个字段加上。select_expr就是必选字段，必须要在select语句中写这个字段。像[LIMIT {[offset,] row_count | row_count OFFSET offset}]这个，也就是说，这一整个字段是可选字段，但是如果加上该字段，就要在{}中给出选项中选择一个，offser加上了[]，说明它可有可无。 1234567891011121314151617181920# 以MySQL官方文档的SELECT语法说明为例SELECT [ALL | DISTINCT | DISTINCTROW ] [HIGH_PRIORITY] [STRAIGHT_JOIN] [SQL_SMALL_RESULT] [SQL_BIG_RESULT] [SQL_BUFFER_RESULT] [SQL_CACHE | SQL_NO_CACHE] [SQL_CALC_FOUND_ROWS] select_expr, ... [INTO OUTFILE 'file_name' export_options | INTO DUMPFILE 'file_name'] [FROM table_references [WHERE where_definition] [GROUP BY {col_name | expr | position} [ASC | DESC], ... [WITH ROLLUP]] [HAVING where_definition] [ORDER BY {col_name | expr | position} [ASC | DESC] , ...] [LIMIT {[offset,] row_count | row_count OFFSET offset}] [PROCEDURE procedure_name(argument_list)] [FOR UPDATE | LOCK IN SHARE MODE]] 二、存储引擎#存储引擎简单总结#以下内容基本来源于官方文档以及书籍《深入浅出MySQL》 常用存储引擎的对比 特点 MyISAM InnoDB MEMORY MERGE NDB 存储限制 有 64TB 有 没有 有 事务安全 支持 锁机制 表锁 行锁 表锁 表锁 行锁 B树索引 支持 支持 支持 支持 支持 哈希索引 支持 支持 全文索引 支持 集群索引 支持 数据缓存 支持 支持 支持 索引缓存 支持 支持 支持 支持 支持 数据可压缩 支持 空间使用 低 高 N/A 低 低 内存使用 低 高 中等 低 高 批量插入的速度 高 低 高 高 高 支持外键 支持 其中常用的几种就是MyISAM（默认存储引擎）、InnoDB、MEMORY和MERGE； MyISAM不支持事务，也不支持外键，优势是访问的速度快，对事务性没有要求或者以SELECT和INSERT为主的应用可以使用这个引擎来创建表； InnoDB提供了具有提交、回滚和崩溃恢复能力的事务安全，相较于MyISAM的存储引擎，InnoDB写的处理效率差一些并且会占用更多的磁盘空间以保留数据和索引，并且在MySQL中支持外键的存储引擎只有InnoDB，因此需要使用外键约束的时候就只能够选择InnoDB存储引擎； MEMORY使用存在内存中的内容来创建表，因此它的表访问起来非常快，并且默认使用HASH索引（创建索引的时候也可以指定使用HASH索引还是BTREE索引，例如create index mem_hash USING HASH on tab_memory (city_id)），但是这只是临时表，服务关闭之后，数据就会丢失； MERGE是一组MyISAM表的组合，这些MyISAM表必须结构完全相同，而MERGE表本身没有数据，对MERGE类型的表可以进行查询、更新、删除的操作，但是其实际上就是对内部的MyISAM表进行的； 1234567891011121314# 创建MERGE表示例，代码来源于《深入浅出MySQL》# 三个关键点：# 1. payment_2006与payment_2007都是使用MyISAM存储引擎的表，并且该MERGE表的# 定义和payment_2006，payment_2007都一样；# 2. INSERT_METHOD=LAST指定了当对该MERGE表进行插入时应当作用在最后一个表上# 也可以指定为FIRST，如果创建MERGE表时不对该子句指定或者指定为NO，就不允许对# 该MERGE表进行插入操作；# 3. 对MERGE表进行DROP删除只会删除MERGE表的定义，对实际MyISAM表没有影响；mysql&gt; CREATE TABLE payment_all( -&gt; country_id smallint, -&gt; payment_date datetime, -&gt; amount DECIMAL(15,2), -&gt; INDEX(country_id) -&gt; )engine=merge union=(payment_2006,payment_2007) INSERT_METHOD=LAST; 关于InnoDB# InnoDB默认地被包含在MySQL二进制分发中。Windows Essentials installer使InnoDB成为Windows上MySQL的默认表。如果你想要所有（非系统）表都被创建成InnoDB表，你可以简单地把default-table-type=innodb行添加到my.cnf或my.ini文件的[mysqld]节里。 每个连接到MySQL服务器的客户端开始之时是允许自动提交模式的，这个模式自动提交你运行的每个SQL语句。要使用多语句事务，你可以用SQL语句SET AUTOCOMMIT = 0禁止自动提交，并且用COMMIT和ROLLBACK来提交或回滚你的事务。 改变一个表为InnoDB型最快的办法就是直接插入进一个InnoDB表。即，使用ALTER TABLE ... ENGINE=INNODB，或用相同的定义创建一个空InnoDB表，并且用INSERT INTO ... SELECT * FROM ...插入行。如果你对第二个键有UNIQUE约束，你可以在导入阶段设置：SET UNIQUE_CHECKS=0，以临时关掉唯一性检查好加速表的导入。对于大表，这节省了大量的磁盘I/O，因为InnoDB随后可以使用它的插入缓冲区来第二个索引记录作为一批来写入。三、事务控制与锁定# MySQL 通过SET AUTOCOMMIT、START TRANSACTION、COMMIT和ROLLBACK等语句支持本地事务。默认情况下，MySQL 是自动提交（Autocommit）的，如果需要通过明确的Commit和Rollback来提交和回滚事务，那么需要通过明确的事务控制命令来开始事务，这是和Oracle的事务管理明显不同的地方。 如果只是对某些语句需要进行事务控制，则使用START TRANSACTION语句开始一个事务比较方便，这样事务结束之后可以自动回到自动提交的方式，如果希望所有的事务都不是自动提交的，那么通过修改AUTOCOMMIT为0来控制事务比较方便，这样不用在每个事务开始的时候再执行START TRANSACTION语句。 在同一个事务中，最好不使用不同存储引擎的表，否则ROLLBACK时需要对非事务类型的表进行特别的处理，因为COMMIT、ROLLBACK只能对事务类型的表进行提交和回滚。","link":"/2019/10/25/MySQL学习笔记学习笔记-一-存储引擎和事务/"},{"title":"Java I/O结合装饰器设计模式的一点理解","text":"@[TOC](Java I/O库结合装饰器设计模式的一点理解) 一、概述#关于I/O库使用的设计模式-装饰器模式# 《Thinking in Java》: 装饰器模式使用分层对象来动态透明地向单个对象中添加责任。装饰器指定包装在最初地对象周围地所有对象都具有相同的基本接口。某些事物是可装饰的，可以通过将其它类包装在这个可装饰对象的四周，从而将功能分层，这使得对装饰器的使用是透明的——无论对象是否被装饰，你都拥有一个可以向对象发送的公共消息集。 Java I/O库实际是很多功能的组合，所以使用装饰器设计模式。至于装饰器设计模式，在我的另外一篇笔记中也进行了学习，这里就不再赘述。 装饰器模式在I/O库中的实际应用#就以字节输入流系列为例:InputStream是一个抽象类，在装饰器设计模式当中，充当了抽象构件的角色，它为所有被修饰的对象提供通用接口，通过查看源码也能知道这点。 FilterInputStream继承自InputStream，充当装饰角色(Decorator)，该类应当持有一个构件角色对象的实例，在FilterInputStream中含有一个输入流对象的保护成员： 1protected volatile InputStream in; 通过给构造方法传递InputStream子类对象的引用就可以初始化该保护成员，该保护成员其实就是JDK文档中I/O部分提到的underlying stream，详细可自己查看JDK文档。 FilterInputStream只有一个子类BufferedInputStream，其充当了具体装饰角色(Concrete Decorator)，给具体构件提供额外的功能（如我们所知，BufferedInputStream给输入流提供了缓冲功能，减少了I/O次数)。 FileInputStream等则充当的是具体构件角色，可以把具体构件角色的对象传递给具体装饰器角色，如之前所示，其内部的保护成员in会被初始化，指向该具体构件角色的对象。典型的： 1BufferedInputStream bis = new BufferedInputStream(new FileInputStream(file)); BufferedInputStream实现原理简述#通过上面的分析我们知道BufferedInputStream实际就是一个装饰器，它为输入流提供了缓冲功能，实际上就是内置了一个字节数组buf，默认大小是8192，大小也可以自己指定，除此之外，在BufferedInputStream中还提供了其它一些比较关键的保护成员（指的是对于缓冲功能实现相对比较重要）： 1234567891011121314151617181920protected volatile byte buf[]; /** * The index one greater than the index of the last valid byte in * the buffer.This value is always in the range 0 through buf.length; * elements buf[0] through buf[count-1] contain buffered input data obtained from the underlying * input stream. */protected int count;/** * The current position in the buffer. This is the index of the next * character to be read from the buf array. * This value is always in the range 0 through count. If it is less * than count, then buf[pos] is the next byte to be supplied as input; * if it is equal to count, then the next read or skip operation will require * more bytes to be read from the contained input stream. */protected int pos;protected int markpos = -1;protected int marklimit; 其中两个比较关键的字段count和pos已经给出了注释，注释来源于JDK源代码的注释，count和pos其实就是两个指针，count指向buf中最后一个有效字节之后的那个位置，而pos指向buf中下一个要读取的位置（即pos处还未被读取)。 buf缓冲数组中的数据则来源于underlying stream即之前被初始化的in，在BufferedInputStream中还增加了一个私有函数fill()，该函数实际上就是完成了从输入流到缓冲数组的数据的读取，其功能依赖于count,pos,mark等指针，每当pos&gt;=count(这说明buf中的有效数据已经读取完毕)就会调用fill()方法，往buf数组中填充数据，若buf中除了有效数据还有位置，则会紧接着有效位置填充来自于in的数据。 那么为什么BufferedInputStream能够有效减少I/O次数，从而提高性能呢？因为buf数组的存在，每一次其内部的输入流in调用read()方法，实际上都会读写很多个字节的数据，并且将其缓冲在buf数组当中，因此当调用BufferedInputStream的read方法时实际上就是从buf数组中读数据，但是如果我们直接使用输入流的read方法，那么每一次读取都要付出昂贵的磁盘IO的代价。因此，显然，从内存中读数据要比从磁盘上读数据快得多（通常每次读取可能会少上数十或者上百个时钟周期）。 I/O库流的分类#可以划分为字符流和字节流。字符流包括Reader，Writer及其子类，字节流包括InputStream，OutputStream及其子类，一般读取文本文件可以用字符流，图像等其它文件则可以使用字节流。 二、简单使用方式#字符流#控制台输入#1BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); 因为System.in是InputStream类型，而BufferedReader需要接受Reader类型，因此需要InputStreamReader来进行字节流与字符流之间的转换，实际上InputStreamReader内置了一个解码器(Decoder)，因此可以指定字符集来对字节流进行解码。 读取文本文件#12345678910public class Main { public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new FileReader(\"test.txt\")); int c; while ((c = br.read()) != -1) { System.out.print((char) c); } br.close(); }} 因为close()方法声明抛出了IOException异常，必须对其处理，这里选择继续向上层调用栈抛出。 向文件写入文本#1234567public class Main { public static void main(String[] args) throws IOException { BufferedWriter bw = new BufferedWriter(new FileWriter(\"write_in.txt\")); bw.write(\"感谢您看我的博客文章！\"); bw.close(); }} 字节流#复制文件#12345678910111213public class Main { public static void main(String[] args) throws IOException { BufferedInputStream bis = new BufferedInputStream(new FileInputStream(\"test.jpg\")); BufferedOutputStream bos= new BufferedOutputStream(new FileOutputStream(\"test_copy4.jpg\")); byte[] bytes=new byte[1024]; int len; // 读取的有效字节数 while((len=bis.read(bytes))!=-1){ bos.write(bytes,0,len); // 将有效字节续写在文件后 } bos.close(); bis.close(); }}","link":"/2019/10/11/Java-I-O结合装饰器设计模式的一点理解/"},{"title":"Memory mountain for Principle of program locality","text":"一、存储器山的数据测量#存储器山的数据测量（包含我所测试的数据）#这一部分很简单，因为代码已经由CMU提供给大家了，大家只需要简单地修改代码，将结果输出到txt文件即可，然后再用MATLAB或者Python写一个脚本读取该txt文件，然后将结果绘制出来即可。 首先，将结果输出到文件，很简单，这个大家都会。不过这里还是有一个要注意的点，将修改的代码编译时，（由于我是在Linux系统上完成这个实验的），mountain.c这个文件中包含对另外两个自定义的头文件（“clock.h”以及“fcyc2.h）的引用，因此编译时需要执行： 1gcc -Og -o my_memory_mountain moutain.c clock.c fcyc2.c 然后会得到一个可执行文件 my_memory_mountain，然后直接执行./my_memory_moutain等待一段时间之后就会得到存储器山的测量结果了。以我自己所测量的结果为例： 首先是原始输出的数据：其中s1-s15为步长，128m是数据大小，表格结果为读吞吐量。为了便于后期脚本的数据读取与处理，将原始结果人工进行处理，结果如下： 二、存储器山的绘制#因为我Matlab用得不熟，所以这里是用python的第三方库pyecharts的Surface3D来绘制的存储器山，但是绘制出来的结果不是很理想，因为我看了很久文档都没有弄太明白如何设置颜色的渐变，或者是说将存储器上的不同区域着上不同的色。 其实从pyecharts的官方文档中，我只找到了一个设置颜色渐变的系列配置项，ItemStyleOpts，但是，我设置的时候老出问题，而且好像没有什么效果 先上python的代码（全局配置项当中的VisualMapOpts其实可以忽略，我当时是想设置颜色渐变的，但是没弄出来，所以把这一部分的代码去掉也是没有问题的）： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# author Morty# 2019-8-25# latest update 2019-11-17# python 3.6from pyecharts.charts import Surface3Dfrom pyecharts import options as opts class CreateMountain: def __init__(self): self.data_set = [] self.gragh = Surface3D() def data_process(self): with open(r\"C:\\Users\\54235\\Desktop\\m_data_set.txt\", \"r\") as f: data_set_origin = f.readlines() for line in data_set_origin: for index, item in enumerate(line.split(\"\\t\")[:-1], start=0): # index即为步长 # 【更新之后这段代码应当修改才对】 if index == 0: read_throughput = int(item[0:-1]) flag = item[-1] if flag == \"m\": read_throughput *= 1000000 elif flag == \"k\": read_throughput *= 1000 else: size = int(item) self.data_set.append([index, read_throughput, size]) def plot(self): self.data_process() self.gragh.add( # series name \"\", # 通过k*k循环展开测出来的数据集 data=self.data_set, # 三维图形的着色效果配置，realistic即为真实感渲染 shading=\"realistic\", # 图元配置项 itemstyle_opts=opts.ItemStyleOpts(), # 3D X坐标轴配置项 xaxis3d_opts=opts.Axis3DOpts( name=\"步长\", name_gap=40), # 3D Y坐标轴配置项 yaxis3d_opts=opts.Axis3DOpts( name=\"大小/B\", name_gap=40), # 3D Z坐标轴配置项 zaxis3d_opts=opts.Axis3DOpts( name=\"存储器读取速度MB/s\", name_gap=40), # 三维笛卡尔坐标系配置项 grid3d_opts=opts.Grid3DOpts( width=100, height=100, depth=100 ), ).set_global_opts( title_opts=opts.TitleOpts( title=\"Memory Mountain K*K Loop unrolling\", pos_left=\"center\", pos_top=90, ))).render() if __name__ == \"__main__\": c = CreateMountain() c.plot() 关于pyecharts，官方文档很友好，很容易阅读，中文文档的传送门：Pyecharts绘制结果如下：Tips:其实我对于这个绘制出来的结果非常的不自信，不知道是我设置的比例问题，还是因为我不会按照不同的区域来着色导致的视觉差的问题，同我理想当中的存储器山差距有点大，所以如果有热心的小伙伴知道我这是什么问题，或者说知道pyecharts怎么按照不同的区域来对曲面着色的话，请一定留言告诉我！我万分感激！ 【更新】2019/11/17 上面的问题解决了！其实这个问题早就解决了，只是一直忘了修改博客了。出现问题的原因在于大小/B的坐标轴，因为按照实际的大小（即测出来的真实值）作为坐标轴就会导致整个高速缓存紧缩在一起了，导致实际绘制渲染出来的图片与书本上的有所差异，其实想一想确实是自己蠢了，整个高速缓存的大小与内存相比无论如何都是没法比的，所以导致了上图那个90度直角的感觉，但是实际上仔细看还是能够看到存储器的分级的。如何解决？很简单，如果用真实的大小会导致缓存分级的部分紧缩在一堆，那么其实可以就用等间距的“假数据”把大小这个坐标轴给换掉，然后就能够突出缓存分级的区域了，最终效果图如下：","link":"/2019/11/17/Memory-mountain-for-Principle-of-program-locality/"},{"title":"MIT-6.828-LAB2 Memory Management","text":"Contents# Part 1:Physical Page Management Exercise 1 Key Point Part 2:Virtual Memory Exercise 2,3 Key Point Exercise 4 Part 3:Kernel Address Space Exercise 5 Key Point Questions Challenge Code implemention for all exercises REFERENCES Part 1:Physical Page Management# Exercise 1#Key point#后续内容建议配合该图食用： 在LAB1做完之后，物理内存当中就已经被加载了内核代码以及数据了（.text Section,.data Section)。kern/init.c当中下一步就是调用mem_init()，通过LAB1的学习以及kern/pmap.c当中的mem_init以及boot_alloc函数的注释，能够了解到boot_alloc是在尚未划分物理页面时在kernel的.bss segment之后分配一个页面大小的内存空间作为kernel page directory,并且分配一定大小的内存空间作为Page Info arrays（该内存空间的大小取决于npages以及sizeof(struct PageInfo),并且还要按PGSIZE对齐）。因此在mem_init中，首先初始化了kernerl page directory，随后给Page Info arrays分配了内存空间，用来存储整个物理内存空间对应的页面信息(Page Information)，在exercise 1当中，最后就是调用page_init来初始化整个物理内存空间对应的页面信息，理解了上图，写出page_init以及整个exercise 1就不难了。 但是仍然有几个注意点： 记录一个页面信息时，将PageInfo中的pp_ref置为1并不是表明其in use或者could not allocate，实际上正确的方式就是忽略这个页面（但是由于C语言需要初始化，因此将pp_ref置为0，pp_link置为NULL即可），虽然将pp_ref置为1好像也不会出错，但是不建议这么做。 npages_basemem实际上低于1MB并且低于其中IO hole(在LAB1当中有解释！）的部分的物理页面的数量，而npages则是整个物理内存空间包含的物理页面的数量。 关于上图如何验证，事实上make qemu启动后在i386_detect_memory函数中会输出base=640K，然后你还会发现在该函数中有npages_basemem = basemem / (PGSIZE / 1024);事实上这就完美验证了！ 代码实现见Code implemention for all exercises. Part 2:Virtual Memory# Exercise 2,3#Key point#这一部分就是让我们认真阅读80386 programmer mannual.这部分基础知识就不再赘述。但是值得一提的是，在80386中，并不是没有segment translation的机制，只是在boot.S当中加载了全局描述符表，该GDT将所有的段寄存器的Base address都设置为0，段寄存器寻址上限设置为0xffff ffff，因此虚拟地址经过Segment translation之后与线性地址等价，对外表现为没有segment translation的机制，但是不能够说80386将segment translation机制禁用了。下面这个简单的示意图还是很重要的： 123456789 Selector +--------------+ +-----------+ ----------&gt;| | | | | Segmentation | | Paging |Software | |--------&gt;| |----------&gt; RAM Offset | Mechanism | | Mechanism | ----------&gt;| | | | +--------------+ +-----------+ Virtual Linear Physical 此外，就是exercise3提到的进入qemu monitor的快捷键在我这不顶用，根据这个老哥的博客fatsheep-mit6.828-lab2,这个是可行的。 1qemu-system-i386 -hda obj/kern/kernel.img -monitor stdio -gdb tcp::26000 -D qemu.log Exercise 4#无特殊注意事项，代码实现见Code implemention for all exercises. Part 3:Kernel Address Space# Exercise 5#Key point#完善mem_init()的虚拟内存映射代码即可。 1boot_map_region(kern_pgdir, UPAGES, PTSIZE, PADDR(pages), (PTE_U | PTE_P)); 将pages那部分内容映射到虚拟地址UPAGES处，这里的PTSIZE实际上与ROUNDUP(sizeof(struct PageInfo)*npages, PGSIZE)是等价的，虽然它们值不相等，但是都能通过校验函数。用PTSIZE可能是源于inc/memlayout.h中的示意图，使用另外一种是因为这是PageInfo实际分配的物理存储空间大小。 1boot_map_region(kern_pgdir, KSTACKTOP-KSTKSIZE, KSTKSIZE, PADDR(bootstack), (PTE_W | PTE_P)); 将内核栈映射到虚拟地址KSTACKTOP-KSTKSIZE处。 1boot_map_region(kern_pgdir, KERNBASE, -KERNBASE, 0, (PTE_W | PTE_P)); 将整个物理存储空间映射到KERNBASE之上，在32位机器上将-KERNBASE按照无符号数解释恰好就是2^32-KERNBASE。 代码实现见Code implemention for all exercises. Questions# 1.Assuming that the following JOS kernel code is correct,what type should variable x have,uintptr_t or physaddr_t? 1234mystery_t x;char* value = return_a_pointer();*value = 10;x = (mystery_t) value; 很显然，返回的是指针，必然是虚拟地址，因此x的类型是uintptr_t. 2.What entries (rows) in the page directory have been filled in at this point? What addresses do they map and where do they point? In other words, fill out this table as much as possible: 3.We have placed the kernel and user environment in the same address space. Why will user programs not be able to read or write the kernel’s memory? What specific mechanisms protect the kernel memory? 无论是Page directory entry还是Page table entry，其低12位的控制bit起到了访问控制（读/写）以及校验优先等级（privileged level）的作用。通过设置相应的bit位就能够控制user对page的访问权限。具体参阅Intel 80386 Reference Programmer’s Manual 4.What is the maximum amount of physical memory that this operating system can support? Why? JOS使用32位系统，并且通过mem_init的设置虚拟内存对物理内存的映射的代码，我们将物理内存从0开始映射到了KERNBASE之上，而KERNBASE是0xF000 0000，32位系统最大虚拟地址为0xFFFF FFFF，因此无论实际物理内存有多大，JOS最大也只能映射2GB的物理内存。从另外一个角度来看，JOS为Page Info分配了4MB的空间，每个struct PageIngo需要8字节空间，因此最多有4MB/8=512K个PageInfo对应于512K个Page，每个Page 4KB，因此最大物理内存空间为2GB。 5.How much space overhead is there for managing memory, if we actually had the maximum amount of physical memory? How is this overhead broken down? 倘若JOS映射了2GB的物理内存，那么就有2GB/4KB=512K个物理页面，每个物理页面对应于4 bytes的page table entry，因此这部分花销是512K*4=2MB。除此之外，还有4KB的Page directory以及4MB的Page Info，因此总的花销是2MB + 4MB + 4KB. 6.Revisit the page table setup in kern/entry.S and kern/entrypgdir.c. Immediately after we turn on paging, EIP is still a low number (a little over 1MB). At what point do we transition to running at an EIP above KERNBASE? What makes it possible for us to continue executing at a low EIP between when we enable paging and when we begin running at an EIP above KERNBASE? Why is this transition necessary? 在LAB1当中已经提到了，在jmp *%eax之后，EIP从高于KERNBASE的地址处开始执行。之所以这样可行是因为entrypgdir.c将虚拟地址[0, 4MB)还有[KERNBASE, KERNBASE+4MB)映射到了物理地址[0, 4MB)。之所以要将[0, 4MB)的虚拟地址空间也映射到物理地址[0, 4MB)是因为在开启Paging之后，entry.S中还有少许指令需要执行，当其执行完之后，就会进入C语言编写的代码来对内核进行初始化，而C实际上只支持虚拟内存，因此这种转移是必要的。 Challenges# Challenge! We consumed many physical pages to hold the page tables for the KERNBASE mapping. Do a more space-efficient job using the PTE_PS (“Page Size”) bit in the page directory entries. This bit was not supported in the original 80386, but is supported on more recent x86 processors. 查阅Intel® 64 and IA-32 Architectures Software Developer’s Manual。例如基于x86架构的IA-32处理器以及 Pentium II处理器都支持了在Page directory entry中PTE_PS位的设置。在同时设置了控制寄存器CR4的PSE flag以及Page direcotry entry中的PTE_PS flag之后，该Page directory entry实际上就存储了指向4MB物理页的指针（即22~31bit位）这时候实际上二级页表不会起作用。但值得注意的是，按照Intel参考文档的说明，若没有设置CR4的PSE flag，即便设置了PTE_PS flag物理页也只能是4KB，不会是4MB。 【Reference from volume 3-27】When the PSE flag in CR4 is set, both 4-MByte pages and page tables for 4-KBytepages can be accessed from the same page directory. If the PSE flag is clear, onlypage tables for 4-KByte pages can be accessed (regardless of the setting of the PSflag in a page-directory entry). 我们熟知的4KB页面大小的Page Directory Entry： 当设置了PSE flag以及PTE_PS flag之后，页面大小为4MB，这时的Page Directory Entry: 相应的linear address translation也与之前两级页表有所不同： 当页面大小是4MB时，二级页表就不起作用了，因此，不仅能够减少存储页面信息的开销，还能减少页表的开销。 Challenge! Extend the JOS kernel monitor with commands to: 实现了一个简单版本，代码比较丑陋，没有做到能对任何的参数都不会产生bug，仅限简单的参数校验。下方是核心showMappings函数，其它util工具函数参见github代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748int show_mappings(int argc, char **argv, struct Trapframe *tf){ // validate arguments amount // argc==3,which means that show pages information between argv[1] and argv[2]. // argc==4,which means that set all the pages with perm. // argc==5,which means that only set page argv[4] with perm. cprintf(\"debug-&gt; argc :%d\\n\",argc); if(argc &lt; 3){ cprintf(\"Invalid arguments.You should pass two virtual address:startVA endVA and optional permissions.\\n\"); return 0; } int32_t start = s2va(argv[1]), end = s2va(argv[2]) + 1, perm = 0, onlyTarget = 0; if(start == -1 || end == -1 || end &lt; start){ cprintf(\"Invalid virual address was given.\\n\"); return 0; } // obtain optional perm. if(argc &gt;= 4){ char *tmp = argv[3]; if(tmp[0] == '-')perm = -1; else{ while(*tmp){ perm = perm * 10 + (*tmp - '0'); ++tmp; } } } // obtain onlyTarget while argc==4 if(argc == 5){ onlyTarget = s2va(argv[4]); } uintptr_t u_start_align = ROUNDDOWN((uintptr_t)start, PGSIZE), u_end_align = ROUNDUP((uintptr_t)end, PGSIZE); pte_t *pte; cprintf(\"va@start: %08x va@end: %08x\\n\", u_start_align, u_end_align); for(;u_start_align &lt; u_end_align; u_start_align += PGSIZE){ pte = pgdir_walk(kern_pgdir, (void *)u_start_align, 1); if(pte){ if(argc == 4)setPermissions(perm, pte); if(argc == 5 &amp;&amp; (uintptr_t)onlyTarget == u_start_align)setPermissions(perm, pte); cprintf(\"va@page: %08x \", u_start_align); cprintf(\"pa@page: %08x @perm:PTE_P %d PTE_U %d PTE_W %d;\\n\", PTE_ADDR(*pte),lovelyValidate(*pte &amp; PTE_P), lovelyValidate(*pte &amp; PTE_U), lovelyValidate(*pte &amp; PTE_W)); } } return 0;} 效果示意图： Code implemention for all exercises#See github:YanTang Qin- MIT6.828 REFERENCES#【1】 Intel 80386 Reference Programmer’s Manual【2】 Intel® 64 and IA-32 Architectures Software Developer’s Manual【3】 XV6 - a simple, Unix-like teaching operating system - Reference Book【4】 《Computer Systems: A Programmer’s Perspective (3rd Edition)》.Randal E.Bryant / David O’Hallaron.【5】 《Modern Opeation Systems (Fourth Edition)》.Andrew S.Tanenbaum / Herbert Bos.","link":"/2020/01/01/MIT-6-828-LAB2-Memory-Management/"},{"title":"《现代操作系统》学习笔记(一):进程与线程","text":"@[TOC] 一、进程与线程的简单回顾#进程与线程的简单回顾# 《Modern Operating System》：进程就是一个正在执行的程序的实例，包括程序计数器、寄存器和变量的当前值。 每一个进程都拥有自己独立的地址空间（这源于虚拟内存技术），其中有程序和数据以及独立的用户栈和独立的堆空间等。例如在UNIX系统中，可以调用系统级函数fork()来创建一个子进程，在还未加载新的代码之前，此时子进程与父进程拥有几乎完全相同的内存映像、同样的环境字符串和同样的打开文件，可以通过execve()来重新加载新的程序（可执行文件），但是execve仅仅只是分配了虚拟页，此时并没有实际将程序从磁盘中调入内存，只有当某一条指令触发了缺页故障的时候，此时将陷入内核态，将该条指令虚拟页所指定的内容调入物理内存，并且修改相应的PTE条目（Page Table Entry)，然后系统调用返回到这条指令，再一次执行该指令时就不再会触发缺页故障了（详情可参考机械工业出版社的《深入理解计算机系统》第三版）。线程不准确地理解的话，可以将其看作一种轻量级的进程，同一个进程中的线程都有完全一样的地址空间，共享同样的全局变量，由于各个线程都可以放你问进程地址空间中的每一个内存地址，所以一个线程可以读、写甚至清除另一个线程的堆栈，也就是说，线程之间是没有保护的。除了共享地址空间外，还共享同一个打开文件集、子进程、定时器以及相关信号（因为这些基本上都是操作系统维护在进程的上下文中的） 为什么需要线程？# 线程拥有共享同一个地址空间和所有可用数据的能力，但是多进程模型无法做到； 线程比进程更轻量级，创建线程的开销比创建进程的开销要小得多（无论是时间上还是空间上），也更容易撤销； 性能。若多个线程都是CPU密集型的，那么不能获得性能上的增强（线程的调度也是需要开销的），但是如果存在着大量的计算和I/O处理，拥有多个线程允许这些活动彼此重叠进行，从而会加快应用程序执行的速度 线程包的实现方式# 线程包有两种实现方式：在用户空间中和在内核中。除此之外还有混合实现方式。 第一种实现方式就是把整个线程包放在用户空间中，而内核对线程包一无所知。在这种方式下，进程中有一个运行时系统，管理着该进程特有的线程表（thread table），用来跟踪该进程中的线程。 第二种实现方式就不需要运行时系统了，每个进程也不要存储和管理各自的线程表了，相反，在内核当中有用来记录系统中所有线程的线程表（进程通常运行在用户模式下，对内存的访问通常是受限的）。当某个线程希望创建一个新线程或者撤销一个已有线程时，它进行一个系统调用（系统调用实际上是一种异常控制流，注意和Java的异常区别开来，中断、陷阱、故障等实际上都是一种异常控制流），该系统调用将切换到内核模式（内核模式拥有最高访问权限），并且通过对线程表的更新完成线程创建或撤销工作。 两种线程包的实现方式各自的优缺点总结#在用户空间中实现线程包： 优点：1. 用户级线程包可以在不支持线程的操作系统上实现； 2. 允许每个进程有自己定制的调度算法； 3. 当某个线程做了一些会引起在**本地阻塞**的事情之后，运行时系统将会调度该进程中的其它线程来运行，并且如果机器有一条保存所有寄存器的指令和另一条装入全部寄存器的指令，那么整个线程的切换就可以在几条指令内完成，这比内核级线程的切换的代价要小得多（因为内核级线程的切换首先陷入内核，切换上下文，这个开销是巨大的）； 缺点：1. 阻塞系统调用。如果进程P中的某一个线程产生了一个阻塞系统调用，那么由于会进行上下文的切换，整个进程都将被阻塞，从而导致该进程中的其它线程也被迫进入阻塞状态，这显然违背了线程本身出现的原因； 2. 缺页中断问题。在《深入理解计算机系统》这本书中，对程序的加载进行了详细的解释与说明，以UNIX系统为例，调用execve()之后，只是分配了虚拟页，程序实际上还并没有加载进内存，详细可自行查阅。如果某个程序调用或者跳转到了一条不在内存上的指令时，将会引发缺页故障，从而导致整个**进程**陷入内核态，然后内核异常处理程序将对应的虚拟页调入物理内存当中，并且修改相应的PTE，然后返回到引发该缺页故障的指令，该指令将会重新执行，这一次就不会再触发缺页故障了。显然，缺页中断将会导致整个进程中的线程都被阻塞直到缺页故障被处理完毕； 3. 在用户级线程包中，如果一个线程开始运行，那么在该进程中的其它线程就不能运行，除非第一个线程自动放弃CPU。 在内核中实现线程: 优点：1. 不再需要运行时系统了，每个进程中也没有线程表，相反，线程统一由内核维护在内核区域中； 2. 解决了阻塞系统调用的问题。所有能够阻塞线程的调用都以系统调用的形式实现，当一个线程阻塞时，内核根据相应的调度算法而调度其它就绪状态的线程的运行； 3. 解决了缺页中断问题。同样的，当一个线程引发了缺页故障需要将所需要的页面调入物理内存时，内核可选择调度其它线程来运行； 缺点：1. 信号（Signal）是发送给进程的（在进程的上下文中由内核维护着一个bind向量，详情请查看《深入理解计算机系统》），当一个信号到达的时候，那么这个信号应该由哪一个线程来处理？ 2. 当一个进程创建了一个子进程的时候，新的进程是应该拥有与父进程一样的线程吗？等等这些问题都是值得考虑的。 二、进程间通信#竞争条件、互斥与临界区# 《Modern Operating Systems》： 竞争条件（Race Condition）即两个或者多个进程读写某些共享数据，而最后的结果取决于进程运行的精确时序。 互斥（Mutual Exclusion）即以某种手段确保当一个进程在使用一个共享变量或文件时，其它进程不能做同样的操作。 临界区（Critical Region）即对共享内存进行访问的程序片段。 解决共享数据的并发进程需要满足的条件# 任何两个进程不能同时处于其临界区中； 不应对CPU的速度和数量做任何假设； 临界区外运行的进程不得阻塞其它进程； 不能够使进程无限期等待进入临界区； 互斥的实现方式概述#在软件层面上和硬件层面上都可以实现互斥： 软件层面： 锁变量 严格轮换法（Busy Waiting） Peterson解法（Busy Waiting） … 硬件层面： 屏蔽中断（仅适用于单处理器操作系统） 专用机器指令（例如TSL指令，XCHG指令，保证了操作的原子性） Semaphore信号量（很重要，既能够实现互斥也能够实现同步） 管程（一个编程语言概念，不是所有语言都支持管程，Java支持） 消息传递（Message Passing）互斥的实现方式详解：软件层面# 锁变量：设定有一个进程间共享锁，初始值为0，当一个进程想要进入临界区时，首先测试这把锁，如果值为0，则该进程将其设置为1并且进入临界区；若为1，则该进程将等待直到其值变为0。 实际上并没有解决互斥问题，仍然存在竞争条件，仍有可能导致多个进程同时进入临界区之中。 严格轮换法：共享一个整型变量turn，初始值为0，用于记录轮到哪个进程进入临界区，并且检查或共享内存。开始时，进程0检查其值为0，于是进入临界区，进程1也发现其值为0，所以在一个等待循环中不停地测试turn，看其值何时变为1。（本质上就是busy waiting) 显然，假设进程0在非临界区中运行的速度很慢而导致其慢于进程1的运行速度，当进程0离开临界区之后并且将turn置为1，然后进程1进入临界区并且很快执行完毕，那么进程1将会由于进程0的非临界区代码的运行速度太慢而迟迟不将turn置为1，从而被阻塞，换而言之，进程1是被一个临界区外之外的进程所阻塞。这显然违反了之前所说的四个条件中的第三个。 12345678910111213141516171819/* ** 严格轮换法示意** from Modern Operating Systems*//* 进程0 */while(true){t while(turn!=0); critical_region(); // 临界区 turn=1; noncritical_region();}/* 进程1 */while(true){ while(turn!=1); critical_region(); // 临界区 turn=0; noncritical_region();} 互斥的实现方式详解：硬件层面# 屏蔽中断：即使每个进程在刚刚进入临界区后立即屏蔽所有中断，并且在离开临界区时打开中断。屏蔽中断后，时钟中断也被屏蔽，因此不会发生进程的切换，从而也就实现了进程的互斥。 缺点是仅仅适用于单处理系统，但是屏蔽中断对于操作系统本身而言是一项很有用的技术。 专用机器指令 优点是：1、不管是在单处理器还是多处理器上，对任意数量的进程都使用；2、原理很简单并且很容易实现；3、能够支持多个临界资源访问的控制； 缺点是：1、忙等待；2、可能会有饥饿现象（Starvation）；3、可能导致死锁； Semaphore信号量：信号量是一种信号变量，其中它有一个整型值，并且还有一个队列表明阻塞在该信号量上的进程。（注：后续的内容在术语上与《现代操作系统》有出入，但是原理一致）提供了wait和signal两个通信原语（即具有原子性，无法被中断），即以前所说的PV操作。Wait操作对信号量的值做减W法，即：Wait(s): s-1 等价于 P(s) 申请资源可能会阻塞自己（s&lt;0）Signal操作对信号量的值做加法，即：Signal(s): s+1 等价于 V(s) 释放资源并且唤醒阻塞在该信号量上的进程（s≤0）信号量不仅能实现互斥，也能够实现同步。信号量也可以划分为：互斥信号量（P74）和资源信号量。互斥信号量用于申请或释放资源的使用权，常初始化为1；资源信号量用于申请或归还资源，可以初始化为大于的1的正整数，表示系统中某类资源的可用个数。信号量中s.count的意义为：若s.count≥0，表示还可以执行wait(s)而不会阻塞的进程数（可用资源数）；若s.count&lt;0，表示s.queue队列中阻塞进程的个数（被阻塞进程数）。当用s来实现n个进程的互斥时，假设初始资源数为1，那么s.count的取值范围为1~ -(n-1)； 管程：一个管程是一个由过程、变量及数据结构等组成的一个集合，它们组成一个特殊的模块或软件包。进程可以在任何需要的时候调用管程中的过程，但是它们能在管程之外声明的过程中直接访问管程内的数据结构。 消息传递（message passing）：这种进程间通信的方法使用两条原语send和receive，它们像信号量而不像管程，是系统调用而不是语言成分。","link":"/2019/10/20/《现代操作系统》学习笔记-一-进程与线程/"},{"title":"高速缓存模拟器:Cache Simulator","text":"文章目录# 一、题目说明 相关说明 测试用例以及得分点 二、代码 三、结果测试一、题目说明#相关说明#self-study student可以在CMU相关官网上下载到相应的lab resource以及对lab的英文文档说明，下载传送门：Lab resource[PDF] 测试用例以及得分点#根据说明文档，我做的时候抽取出来的几个关键点，包括格式，注意事项，得分点，以及测试用例：说明文档中，没有给出测试用例的结果，我这里全部测出来了，如下表所示： s E b hit_counts miss_counts eviction_counts test trace files 分值 1 1 1 9 8 6 yi2.trace 3 4 2 4 4 5 2 yi.trace 3 2 1 4 2 3 1 dave.trace 3 2 1 3 167 71 67 trans.trace 3 2 2 3 201 37 29 trans.trace 3 2 4 3 212 26 10 trans.trace 3 5 1 5 231 7 0 trans.trace 3 5 1 5 265189 21775 21743 long.trace 6 二、代码#话不多说，直接上代码，关于函数接口的设计以及算法和一些细节上的问题已经注释了： 编译时的指令为:gcc -Og -o my_csim_ref csim.c cachelab.c 得到一个可执行文件my_csim_ref 如果代码有问题，可以用gdb调试 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179#include \"cachelab.h\"#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;getopt.h&gt; #define BUFSIZE 30 void get_opt(); // 获取参数void init_cache(); // 初始化cache，分配内存void del_cache(); // 程序结束时释放申请的内存void load_block(int address,int size); // load指令void modify_block(long address,int size); // modify指令void store_block(long address,int size); // store指令int tag(long address); // 根据地址返回标记值int set_index(long address); // 根据地址返回组索引 // 行typedef struct{ int flag; long tag; long latest_access_time;}cache_line; // 组，为了更加地形象所以这么写，组中有一个指向组内缓冲行的指针typedef struct{ cache_line *data_lines;}set; set *cache=NULL; // cache指针int S=0,E=0,B=0;int hit_counts=0,miss_counts=0,eviction_counts=0;long my_clock=0; // 简单使用一个长整型来抽象表达时间，不科学，但是有效char *file=NULL; // 保存要用的traces测试文件的文件名，文件名在get_opt()中获取 int main(int argc,char **argv){ get_opt(argc,argv); init_cache(); FILE *test_file_ptr=fopen(file,\"r\"); // 打开测试文件 char instruction[BUFSIZE]; long addr; int size; char buffer[BUFSIZE]; while(fgets(buffer,BUFSIZE,test_file_ptr)!=NULL) { // 这里有两个细节问题，首先不能用%c来读取instruction(即说明文档中提到的L,M,S) // 因为一开始我是用的%c,但是我打印出来后发现和期望值不同 // 其次就是，CMU给的说明文档中说了测试用例中的地址实际上是16进制，我一开始就是 // 当十进制了，结果调试很久很久 sscanf(buffer,\"%s %lx,%d\",instruction,&amp;addr,&amp;size); long address=(long)addr; if(*instruction=='L')load_block(address,size); else if(*instruction=='M')modify_block(address,size); else if(*instruction=='S')store_block(address,size); } printSummary(hit_counts,miss_counts,eviction_counts); // 打印结果 del_cache(); // 释放内存 return 0;} void get_opt(int argc,char **argv){ int c; while((c=getopt(argc,argv,\"s:E:b:t:\"))!= -1) { switch(c) { // atoi将字符串转换为数字 case 's':S=atoi(optarg);break; case 'E':E=atoi(optarg);break; case 'b':B=atoi(optarg);break; case 't':file=optarg;break; // 测试文件traces的文件名 } }} void init_cache(){ int i,j,set_num=1&lt;&lt;S,temp=sizeof(cache_line)*E; cache=(set*)malloc(sizeof(set)*set_num); // 分配组 for(i=0;i&lt;set_num;i++) { cache[i].data_lines=(cache_line*)malloc(temp); // 分配行 for(j=0;j&lt;E;j++) { cache[i].data_lines[j].flag=0; cache[i].data_lines[j].tag=0; cache[i].data_lines[j].latest_access_time=0; } }} void del_cache(){ int i,j,set_num=1&lt;&lt;S; // set_num为2^S==1&lt;&lt;S for(i=0;i&lt;set_num;i++) { free(cache[i].data_lines); } free(cache);} void load_block(int address,int size){ // 这里block_replace必须赋初值，否则结果不会正确 int i,full=1,block_replace=0,set_index_=set_index(address),tag_=tag(address); int compare_time=cache[set_index_].data_lines[0].latest_access_time; // 按照CSAPP第六章给出三个步骤：1.组选择 2.行匹配 3.字节偏移 cache_line *line=cache[set_index_].data_lines; // 组选择 for(i=0;i&lt;E;i++) // 行匹配 { if(line[i].flag==1) // 行有效 { if(tag_==line[i].tag) // 命中 { hit_counts++; line[i].latest_access_time=++my_clock; break; }else if(full&amp;&amp;compare_time&gt;line[i].latest_access_time){ // 行有效，但标记不匹配 // 说明文档中要求我们采用LRU算法来进行块的替换 // 这里有一个细节问题，只有在full仍然是真时才需要不断按照LRU思想更新 // block_replace的值，若full已经为假了，就存在空闲块了，不需要使用LRU // 算法选择块来替换了 compare_time=line[i].latest_access_time; block_replace=i; } }else{ // 行无效，即存在空闲行 full=0; block_replace=i; } } if(i==E) // 未命中 { miss_counts++; line[block_replace].flag=1; line[block_replace].tag=tag_; line[block_replace].latest_access_time=++my_clock; if(full)eviction_counts++; // 产生替换 }} void store_block(long address,int size){ int i,set_index_=set_index(address),tag_=tag(address); cache_line *line=cache[set_index_].data_lines; for(i=0;i&lt;E;i++) // 写命中 { if(line[i].flag==1&amp;&amp;line[i].tag==tag_) { hit_counts++; line[i].latest_access_time=my_clock; break; } } if(i==E) // 写不命中，使用写分配法 { load_block(address,size); }} void modify_block(long address,int size){ load_block(address,size); store_block(address,size);} int set_index(long address){ return (address&gt;&gt;B)&amp;((1&lt;&lt;S)-1); // 去掉B位，并且只保留S位即为索引位} int tag(long address){ return (long)address&gt;&gt;(B+S); // 去掉块偏移以及组索引位，剩下的即为标记位} 三、结果测试#所有测试用例均通过：","link":"/2019/11/17/高速缓存模拟器-Cache-Simulator/"},{"title":"浅谈装饰器设计模式","text":"文章目录：# 一、概念 二、结构 如何理解装饰器设计模式的运行原理？ 下面给出一个简单的示例 一、概念# 《Thinking in Java》: 装饰器模式使用分层对象来动态透明地向单个对象中添加责任。装饰器指定包装在最初地对象周围地所有对象都具有相同的基本接口。某些事物是可装饰的，可以通过将其它类包装在这个可装饰对象的四周，从而将功能分层，这使得对装饰器的使用是透明的——无论对象是否被装饰，你都拥有一个可以向对象发送的公共消息集。 二、结构#结构如下图所示（图片来源于互联网）：在装饰器模式中有如下一系列角色： 抽象构件角色（component）：给出抽象接口，规范准备接收附加责任的对象； 具体构件角色（Concrete Component）：定义一个将要接收附加责任的对象： 装饰角色（Decorator）：持有一个构件对象的实例，并且实现了抽线构件规定的接口； 具体装饰角色（Concrete Decorator）：负责给构件对象增加附加的责任； 如何理解装饰器设计模式的运行原理？#在上图中，ConcreteDecoratorA与ConcreteDecoratorB都是具体装饰器，它们的构造函数接收一个具体构件（Concrete Component）角色对象，由于具体装饰器器继承自装饰角色，其内部都声明了一个能够指向具体构件的变量，因此该变量最后会指向我们向装饰器传递的具体构件的对象，而具体装饰器角色对象也有具体构件角色的接口（这就是抽象构件角色所起到的作用之一，规范接口），因此，装饰器就可以调用具体构件的接口了，并且，还可以增加功能。 下面给出一个简单的示例#抽象构件 123public interface Component{ public void operation();} 装饰角色 123456789101112public class Decorator implements Component{ protected Component component; public Decorator(Component component){ this.component = component; } @override public void operation(){ // 可以增加功能，调用具体构件的接口 component.operation(); }} 具体装饰器角色 123456789101112pubic class SpecialDecorator extends Decorator{ public SpecialDecorator(Component component){ super(component); } @override public void operation(){ // 可以增加功能，也可以调用具体构件接口 super.operation(); System.out.print(\"我是具体装饰器角色增加的功能\"); }} 具体构件角色 123456public class ConcreteComponent implements Component{ @override public void operation(){ // 业务代码 }}","link":"/2019/10/11/浅谈装饰器设计模式/"},{"title":"Shell demo on Unix Platform","text":"@[TOC] 一、题目说明#同Cache lab一样，完整的题目说明可以在其官网上找到，在student site当中的for self-study中可以找到所有lab的参考文档，以及一些其它的有用文件，例如GDB调试指南等等。这里附上Shell lab的传送门（注：该链接会直接下载shell lab的self-study handout):Shell Lab self-study handout 二、代码#这个lab的难度在于多进程并发带来的坑以及信号量的处理，为了确保一些操作的原子性，需要使用sigpromask函数来屏蔽掉操作系统内核向进程发送的信号，实际上在csapp书的异常控制流这一章中已经实现了一个非常简易的shell demo,以及一些常见的问题也在书中说明了，例如可以善用volatile关键字来实现全局状态的检测与设置等等。 关于eval函数，思路大致如下： 初始化必要变量并且设置阻塞必要的信号； 解析shell中由用户输入的命令行，设置state标志位（标志着是前台进程还是后台进程）; 若输入的指令是内置指令则立即执行，不需要fork子进程，否则fork子进程并调用execve加载相应的可执行文件并且在shell进程中输出必要的信息，然后退出父进程执行第四步； 将子进程job加入到job list中; 判断是否是bg,若是前台进程调用waifg函数阻塞前台进程运行完成，并且打印消息； 直接上代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715/* * tsh - A tiny shell program with job control * * &lt;Put your name and login ID here&gt; */#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;ctype.h&gt;#include &lt;signal.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;#include &lt;errno.h&gt;/* Misc manifest constants */#define MAXLINE 1024 /* max line size */#define MAXARGS 128 /* max args on a command line */#define MAXJOBS 16 /* max jobs at any point in time */#define MAXJID 1&lt;&lt;16 /* max job ID *//* Job states */#define UNDEF 0 /* undefined */#define FG 1 /* running in foreground */#define BG 2 /* running in background */#define ST 3 /* stopped *//* * Jobs states: FG (foreground), BG (background), ST (stopped) * Job state transitions and enabling actions: * FG -&gt; ST : ctrl-z * ST -&gt; FG : fg command * ST -&gt; BG : bg command * BG -&gt; FG : fg command * At most 1 job can be in the FG state. *//* Global variables */extern char **environ; /* defined in libc */char prompt[] = \"tsh&gt; \"; /* command line prompt (DO NOT CHANGE) */int verbose = 0; /* if true, print additional output */int nextjid = 1; /* next job ID to allocate */char sbuf[MAXLINE]; /* for composing sprintf messages */static volatile sig_atomic_t flag;static pid_t shell_pid;struct job_t { /* The job struct */ pid_t pid; /* job PID */ int jid; /* job ID [1, 2, ...] */ int state; /* UNDEF, BG, FG, or ST */ char cmdline[MAXLINE]; /* command line */};struct job_t jobs[MAXJOBS]; /* The job list *//* End global variables *//* Function prototypes *//* Here are the functions that you will implement */void eval(char *cmdline);int builtin_cmd(char **argv);void do_bgfg(char **argv);void waitfg(pid_t pid);void sigchld_handler(int sig);void sigtstp_handler(int sig);void sigint_handler(int sig);/* Here are helper routines that we've provided for you */int parseline(const char *cmdline, char **argv);void sigquit_handler(int sig);void clearjob(struct job_t *job);void initjobs(struct job_t *jobs);int maxjid(struct job_t *jobs);int addjob(struct job_t *jobs, pid_t pid, int state, char *cmdline);int deletejob(struct job_t *jobs, pid_t pid);pid_t fgpid(struct job_t *jobs);struct job_t *getjobpid(struct job_t *jobs, pid_t pid);struct job_t *getjobjid(struct job_t *jobs, int jid);int pid2jid(pid_t pid);void listjobs(struct job_t *jobs);void usage(void);void unix_error(char *msg);void app_error(char *msg);typedef void handler_t(int);handler_t *Signal(int signum, handler_t *handler);/* * main - The shell's main routine */int main(int argc, char **argv){ char c; char cmdline[MAXLINE]; int emit_prompt = 1; /* emit prompt (default) */ /* Redirect stderr to stdout (so that driver will get all output * on the pipe connected to stdout) */ dup2(1, 2); /* Parse the command line */ while ((c = getopt(argc, argv, \"hvp\")) != EOF) { switch (c) { case 'h': /* print help message */ usage(); break; case 'v': /* emit additional diagnostic info */ verbose = 1; break; case 'p': /* don't print a prompt */ emit_prompt = 0; /* handy for automatic testing */ break; default: usage(); } } /* Install the signal handlers */ /* These are the ones you will need to implement */ Signal(SIGINT, sigint_handler); /* ctrl-c */ Signal(SIGTSTP, sigtstp_handler); /* ctrl-z */ Signal(SIGCHLD, sigchld_handler); /* Terminated or stopped child */ /* This one provides a clean way to kill the shell */ Signal(SIGQUIT, sigquit_handler); /* Initialize the job list */ initjobs(jobs); /* Get shell pid */ shell_pid=getpid(); /* Execute the shell's read/eval loop */ while (1) { /* Read command line */ if (emit_prompt) { printf(\"%s\", prompt); fflush(stdout); } if ((fgets(cmdline, MAXLINE, stdin) == NULL) &amp;&amp; ferror(stdin)) app_error(\"fgets error\"); if (feof(stdin)) { /* End of file (ctrl-d) */ fflush(stdout); exit(0); } /* Evaluate the command line */ eval(cmdline); fflush(stdout); fflush(stdout); } exit(0); /* control never reaches here */}/* * eval - Evaluate the command line that the user has just typed in * * If the user has requested a built-in command (quit, jobs, bg or fg) * then execute it immediately. Otherwise, fork a child process and * run the job in the context of the child. If the job is running in * the foreground, wait for it to terminate and then return. Note: * each child process must have a unique process group ID so that our * background children don't receive SIGINT (SIGTSTP) from the kernel * when we type ctrl-c (ctrl-z) at the keyboard.*/void eval(char *cmdline){ int bg,state; sigset_t mask_all,prev_mask,mask_one; pid_t pid; char buf[MAXLINE]; char *argv[MAXARGS]; struct job_t *job_ptr=NULL; strcpy(buf,cmdline); bg=parseline(buf,argv); if(argv[0]==NULL)return; if(!builtin_cmd(argv)){ // 不是内置指令 sigemptyset(&amp;mask_one); sigaddset(&amp;mask_one,SIGCHLD); // 阻塞SIGCHLD信号 sigprocmask(SIG_BLOCK,&amp;mask_one,&amp;prev_mask); if((pid=fork())==0){ // in subprocess // restore SIGNAL SIGCHLD sigprocmask(SIG_SETMASK,&amp;prev_mask,NULL); setpgid(0,0); if(execve(argv[0],argv,environ)&lt;0){ printf(\"%s: Command not found.\\n\", argv[0]); fflush(stdout); } } if(pid!=0){ // in parent process state=bg?BG:FG; // job state sigfillset(&amp;mask_all); // block all SIGNAL sigprocmask(SIG_BLOCK,&amp;mask_all,&amp;prev_mask); addjob(jobs,pid,state,cmdline); // 将该子进程加入job list job_ptr=getjobpid(jobs,pid); sigprocmask(SIG_SETMASK,&amp;prev_mask,NULL); // restore if(bg){ // 如果是后台进程，就输出后台进程的信息 printf(\"[%d] (%d) %s\", job_ptr-&gt;jid,job_ptr-&gt;pid,job_ptr-&gt;cmdline); fflush(stdout); }else{ // 如果是前台进程，就调用waitfg()等待前台进程终止 waitfg(pid); } } } return;}/* * parseline - Parse the command line and build the argv array. * * Characters enclosed in single quotes are treated as a single * argument. Return true if the user has requested a BG job, false if * the user has requested a FG job. */int parseline(const char *cmdline, char **argv){ static char array[MAXLINE]; /* holds local copy of command line */ char *buf = array; /* ptr that traverses command line */ char *delim; /* points to first space delimiter */ int argc; /* number of args */ int bg; /* background job? */ strcpy(buf, cmdline); buf[strlen(buf)-1] = ' '; /* replace trailing '\\n' with space */ while (*buf &amp;&amp; (*buf == ' ')) /* ignore leading spaces */ buf++; /* Build the argv list */ argc = 0; if (*buf == '\\'') { buf++; delim = strchr(buf, '\\''); } else { delim = strchr(buf, ' '); } while (delim) { argv[argc++] = buf; *delim = '\\0'; buf = delim + 1; while (*buf &amp;&amp; (*buf == ' ')) /* ignore spaces */ buf++; if (*buf == '\\'') { buf++; delim = strchr(buf, '\\''); } else { delim = strchr(buf, ' '); } } argv[argc] = NULL; if (argc == 0) /* ignore blank line */ return 1; /* should the job run in the background? */ if ((bg = (*argv[argc-1] == '&amp;')) != 0) { argv[--argc] = NULL; } return bg;}/* * builtin_cmd - If the user has typed a built-in command then execute * it immediately. */int builtin_cmd(char **argv){ sigset_t mask_all,prev_mask; if(!strcmp(argv[0],\"quit\")){ // 指令为quit，终止shell进程 kill(shell_pid,SIGQUIT); return 1; }else if(strcmp(argv[0],\"fg\")==0||strcmp(argv[0],\"bg\")==0){ do_bgfg(argv); return 1; }else if(!strcmp(argv[0],\"jobs\")){ sigfillset(&amp;mask_all); sigprocmask(SIG_SETMASK,&amp;mask_all,&amp;prev_mask); listjobs(jobs); sigprocmask(SIG_SETMASK,&amp;prev_mask,NULL); return 1; } return 0; /* not a builtin command */}/* * do_bgfg - Execute the builtin bg and fg commands */void do_bgfg(char **argv){ // 让一个已停止的后台作业运行 // 或者让一个已停止或正在运行的后台作业变为前台作业 sigset_t mask_all,prev_mask; int argc=0,id,is_pid; char *temp_ptr=argv[0]; struct job_t *job_ptr=NULL; while(temp_ptr)argc++; // 参数个数 if(argc&lt;2){ printf(\"%s command requires PID or %%jobid argument\\n\", argv[0]); fflush(stdout); return; } is_pid=(argv[1][0]=='%')?0:1; id=is_pid?atoi(argv[1]):atoi(argv[1]+1); if(id==0){ printf(\"%s:argument must be a PID or %%jobid\\n\", cmd); fflush(stdout); return; } // 阻塞所有信号 sigfillset(&amp;mask_all); sigprocmask(SIG_BLOCK,&amp;mask_all,&amp;prev_mask); if(is_pid){ id=pid2jid(id); // 如果给出的是pid，则转换为其相应的jid } if((job_ptr=getjobjid(jobs,id)){ if(strcmp(argv[0],\"bg\")){ // 命令为bg switch(job_ptr-&gt;state){ case ST: job_ptr-&gt;state=BG; kill(-(job_ptr-&gt;pid),SIGCONT); printf(\"[%d] (%d) %s\", job_ptr-&gt;jid, job_ptr-&gt;pid, job_ptr-&gt;cmdline); break; case UNDEF: case FG: // debug unix_error(\"error in function do_bgfg()\\n\"); break; default: break; } }else if(strcmp(argv[0],\"fg\")){ // 命令为fg switch(job_ptr-&gt;state){ case ST: // 如果前台进程为停止状态，则调用重启该前台进程并且调用waitfg() job_ptr-&gt;state=FG; kill(-(job_ptr-&gt;pid),SIGCONT); waitfg(job_ptr-&gt;pid); break; case BG: // 如果是后台进程，就将其转为前台进程并且调用waitfg() job_ptr-&gt;state=FG; waitfg(job_ptr-&gt;pid); break; default: // debug unix_error(\"error in function do_bgfg()\\n\"); break; } } }else{ printf(\"(%s): No such process\\n\", argv[1]); fflush(stdout); } sigprocmask(SIG_SETMASK,&amp;prev_mask,NULL); // restore return;}/* * waitfg - Block until process pid is no longer the foreground process */void waitfg(pid_t pid){ sigset_t mask_one,prev_mask; // 阻塞SIGCHLD，以避免在调用sigsuspend之前对SIGCHLD做出反应进入相应的 // 信号处理程序，从而导致主进程永远被挂起 sigemptyset(&amp;mask_one); sigaddset(&amp;mask_one,SIGCHLD); sigprocmask(SIG_BLOCK,&amp;mask_one,&amp;prev_mask); flag=pid; while(flag) // sigsuspend函数实际上等价于不可中断的： // sigprocmask(SIG_SET_MASK,&amp;mask,&amp;prev); // pause(); // sigprocmask(SIG_SETMASK,&amp;prev,NULL sigsuspend(&amp;prev_mask); // 此时已经回收了终止的子进程 // optionally unblock SIGCHLD sigprocmask(SIG_SETMASK,&amp;prev_mask,NULL); return;}/***************** * Signal handlers *****************//* * sigchld_handler - The kernel sends a SIGCHLD to the shell whenever * a child job terminates (becomes a zombie), or stops because it * received a SIGSTOP or SIGTSTP signal. The handler reaps all * available zombie children, but doesn't wait for any other * currently running children to terminate. */void sigchld_handler(int sig){ // 值得注意的是,sigchld_handler不仅要回收显式等待的前台进程，而且也要 // 回收后台中停止或终止的进程 int olderrno=errno,status; sigset_t mask_all,prev_mask; struct job_t *job_ptr=NULL; pid_t pid; while((pid=waitpid(-1,&amp;status,WUNTRACED|WNOHANG))&gt;0){ sigfillset(&amp;mask_all); sigprocmask(SIG_BLOCK,&amp;mask_all,&amp;prev_mask); job_ptr=getjobpid(jobs,pid); if(job_ptr-&gt;pid==flag){ // 回收的前台作业 flag=0; } if(WIFSTOPPED(status)){ // 停止 job_ptr-&gt;state=ST; }else{ // 终止 deletejob(jobs,pid); } printf(\"Job [%d] (%d) terminated by signal %d\\n\", job_ptr-&gt;jid, job_ptr-&gt;pid, WSTOPSIG(status)); fflush(stdout); sigprocmask(SIG_SETMASK,&amp;prev_mask,NULL); } errno=olderrno; return;}/* * sigint_handler - The kernel sends a SIGINT to the shell whenver the * user types ctrl-c at the keyboard. Catch it and send it along * to the foreground job. */void sigint_handler(int sig){ int olderrno=errno,fg_pid; sigset_t mask_all,prev_mask; sigfillset(&amp;mask_all); sigprocmask(SIG_SETMASK,&amp;mask_all,&amp;prev_mask); fg_pid=fgpid(jobs); sigprocmask(SIG_SETMASK,&amp;prev_mask,NULL); if(fg_pid){ // 存在前台进程,将该信号发送给前台进程组 kill(-fg_pid,SIGINT); } errno=olderrno; return;}/* * sigtstp_handler - The kernel sends a SIGTSTP to the shell whenever * the user types ctrl-z at the keyboard. Catch it and suspend the * foreground job by sending it a SIGTSTP. */void sigtstp_handler(int sig){ int olderrno=errno,fg_pid; sigset_t mask_all,prev_mask; sigfillset(&amp;mask_all); sigprocmask(SIG_SETMASK,&amp;mask_all,&amp;prev_mask); fg_pid=fgpid(jobs); sigprocmask(SIG_SETMASK,&amp;prev_mask,NULL); if(fg_pid){ // 存在前台进程，挂起该前台进程组 kill(-fg_pid,SIGTSTP); } errno=olderrno; return;}/********************* * End signal handlers *********************//*********************************************** * Helper routines that manipulate the job list **********************************************//* clearjob - Clear the entries in a job struct */void clearjob(struct job_t *job) { job-&gt;pid = 0; job-&gt;jid = 0; job-&gt;state = UNDEF; job-&gt;cmdline[0] = '\\0';}/* initjobs - Initialize the job list */void initjobs(struct job_t *jobs) { int i; for (i = 0; i &lt; MAXJOBS; i++) clearjob(&amp;jobs[i]);}/* maxjid - Returns largest allocated job ID */int maxjid(struct job_t *jobs){ int i, max=0; for (i = 0; i &lt; MAXJOBS; i++) if (jobs[i].jid &gt; max) max = jobs[i].jid; return max;}/* addjob - Add a job to the job list */int addjob(struct job_t *jobs, pid_t pid, int state, char *cmdline){ int i; if (pid &lt; 1) return 0; for (i = 0; i &lt; MAXJOBS; i++) { if (jobs[i].pid == 0) { jobs[i].pid = pid; jobs[i].state = state; jobs[i].jid = nextjid++; if (nextjid &gt; MAXJOBS) nextjid = 1; strcpy(jobs[i].cmdline, cmdline); if(verbose){ printf(\"Added job [%d] %d %s\\n\", jobs[i].jid, jobs[i].pid, jobs[i].cmdline); } return 1; } } printf(\"Tried to create too many jobs\\n\"); return 0;}/* deletejob - Delete a job whose PID=pid from the job list */int deletejob(struct job_t *jobs, pid_t pid){ int i; if (pid &lt; 1) return 0; for (i = 0; i &lt; MAXJOBS; i++) { if (jobs[i].pid == pid) { clearjob(&amp;jobs[i]); nextjid = maxjid(jobs)+1; return 1; } } return 0;}/* fgpid - Return PID of current foreground job, 0 if no such job */pid_t fgpid(struct job_t *jobs) { int i; for (i = 0; i &lt; MAXJOBS; i++) if (jobs[i].state == FG) return jobs[i].pid; return 0;}/* getjobpid - Find a job (by PID) on the job list */struct job_t *getjobpid(struct job_t *jobs, pid_t pid) { int i; if (pid &lt; 1) return NULL; for (i = 0; i &lt; MAXJOBS; i++) if (jobs[i].pid == pid) return &amp;jobs[i]; return NULL;}/* getjobjid - Find a job (by JID) on the job list */struct job_t *getjobjid(struct job_t *jobs, int jid){ int i; if (jid &lt; 1) return NULL; for (i = 0; i &lt; MAXJOBS; i++) if (jobs[i].jid == jid) return &amp;jobs[i]; return NULL;}/* pid2jid - Map process ID to job ID */int pid2jid(pid_t pid){ int i; if (pid &lt; 1) return 0; for (i = 0; i &lt; MAXJOBS; i++) if (jobs[i].pid == pid) { return jobs[i].jid; } return 0;}/* listjobs - Print the job list */void listjobs(struct job_t *jobs){ int i; for (i = 0; i &lt; MAXJOBS; i++) { if (jobs[i].pid != 0) { printf(\"[%d] (%d) \", jobs[i].jid, jobs[i].pid); switch (jobs[i].state) { case BG: printf(\"Running \"); break; case FG: printf(\"Foreground \"); break; case ST: printf(\"Stopped \"); break; default: printf(\"listjobs: Internal error: job[%d].state=%d \", i, jobs[i].state); } printf(\"%s\", jobs[i].cmdline); } }}/****************************** * end job list helper routines ******************************//*********************** * Other helper routines ***********************//* * usage - print a help message */void usage(void){ printf(\"Usage: shell [-hvp]\\n\"); printf(\" -h print this message\\n\"); printf(\" -v print additional diagnostic information\\n\"); printf(\" -p do not emit a command prompt\\n\"); exit(1);}/* * unix_error - unix-style error routine */void unix_error(char *msg){ fprintf(stdout, \"%s: %s\\n\", msg, strerror(errno)); exit(1);}/* * app_error - application-style error routine */void app_error(char *msg){ fprintf(stdout, \"%s\\n\", msg); exit(1);}/* * Signal - wrapper for the sigaction function */handler_t *Signal(int signum, handler_t *handler){ struct sigaction action, old_action; action.sa_handler = handler; sigemptyset(&amp;action.sa_mask); /* block sigs of type being handled */ action.sa_flags = SA_RESTART; /* restart syscalls if possible */ if (sigaction(signum, &amp;action, &amp;old_action) &lt; 0) unix_error(\"Signal error\"); return (old_action.sa_handler);}/* * sigquit_handler - The driver program can gracefully terminate the * child shell by sending it a SIGQUIT signal. */void sigquit_handler(int sig){ printf(\"Terminating after receipt of SIGQUIT signal\\n\"); exit(1);}","link":"/2019/11/17/Shell-demo-on-Unix-Platform/"},{"title":"踩过的Mybatis坑及一些注意事项总结","text":"文章目录# 一、Mybatis注意事项以及踩过的坑 Mybatis主配置文件注意事项 package SqlSession select insert,update,delete sql resultMap结果映射（最关键也非常重要） 不使用resultMap标签配置结果映射 一对一 一对多 多对多 二、Mybatis缓存机制 一级缓存 二级缓存 三、Mybatis延迟加载 一、Mybatis注意事项以及踩过的坑#Mybatis主配置文件注意事项# 配置项标签的顺序很重要，不按照文档中介绍的顺序来配置就会报错（但是可以缺少配置项）。 如果想要使用第三方DataSource，那么就可以通过实现DataSourceFactory接口来使用第三方数据源，例如Druid连接池等。然后再在dataSource type属性中配置上该实现类的名称即可，另外，为该第三方数据源配置的配置项根据使用数据源的不同而有所不同，Mybatis只是解析你所配置的属性。以Druid连接池为例，通过自己实现DataSourceFactory接口，里面有两个方法，一个是setProperties，这个方法的参数properties是mybatis自动解析了主配置文件中你所配置的属性得到的（可以自己输出验证一下，确实是这样），而Druid连接池产生DataSource往往通过DruidDataSourceFactory.createDataSource(properties)，因此你就能理解我前面所说的配置项要根据使用数据源的不同而有所不同的含义啦。 package#在mybatis主配置文件的别名配置中使用package标签可以配置包名，通过这种方式能够简化对该包下的类的访问。例如在主配置文件配置了，那么在以后需要引用到该包下的JavaBean的时候，就不要加上这个包名了，直接使用类的名称即可。 SqlSession# 默认情况下，SqlSession是不会开启autocommit的，即默认情况下，一个SqlSession就是一个事务，因此，若更新了数据库就需要调用SqlSession.commit()来提交,若更新发生异常需要调用SqlSession.rollback()进行事务的回滚（在这里发现了一个MySQL自增主键的坑，由于自增主键的值是存放在内存当中的，并且不会因为事务的回滚而使自增主键的值减小，因此倘若插入失败，那么就会导致自增主键的值在数据库中不再连续） 通常我们在使用mybatis时，都是定义dao层接口，以及相应的sql语句，让mybatis来帮我们完成数据的查询与封装，而实际上，当你调用getmapper方法时，实际上在mybatis的内部会把调用getmapper的sqlsession对象的this引用传递到底层的函数，到最后，实际上就是调用了sqlsession的那些方法完成数据的查询的：例如selectList等（可以自己查看源码验证）。因此，除了使用mybatis提供的代理对象的方式，还可以自己实现Dao层接口，在内部直接使用sqlsession的那些方法然后再自己完成封装同样也能完成Dao层的功能。 select# id名不能够相同（update等同理），因此通过Mybatis来实现Dao层接口没法实现方法的重载，通过看一些博客，发现可以通过在Service层实现方法的重载，但是在Dao层不使用重载，这时候又会产生一个新的问题，如果希望能够在Service层实现重载，那么Dao层提供的接口必然就需要查询很多参数，那应该如何实现接口的高可用性呢？目前我觉得可以使用Mybatis的动态SQL的特性来解决，让Dao层的接口可以接受很多的必要的参数，但是可以传入无效值，例如Null，然后通过动态SQL的IF等达到动态构建SQL语句的功能。 parameterType是可选参数，即便不写，Mybatis也可以通过类型处理器（TypeHandler）来推断出具体传入语句的参数 如果希望能够有多个参数，那么有几种实现方式，（1）直接使用arg0-argn(n的取值取决于Dao层接口方法的参数个数）；（2）在Dao层接口的参数配置上@Param注解，这样就可以在Mapper的配置文件中使用你在@Param中为该参数设置的名称了；（【注】我个人觉得根据不同的情况前面两种方式实际上都可行）；（3）在Dao层接口中传入Map，通过设置Map的K-V来实现多参数，这样就可以在Mapper的配置文件中使用Map的K值了（不推荐这种方式，绝对代码维护火葬场） 如果参数允许null值，那么根据JDBC的规范，必须在参数中指定JDBC Type，例如#{age,jdbcType=NUMERIC} insert,update,delete#在这三种映射标签中，会让人产生疑惑的是useGeneratedKeys和keyProperty两个属性，实际上就是当数据库表的主键是自动增长的时候（例如MySQL中的autoincrement），调用insert或者update的时候是肯定没办法拿到该主键的，那么这时候就可以通过设置userGeneratedKeys为true，并且为keyProperty设置一个名字（例如可以设置为keyProperty=“id_autoIncrement”）那么执行该SQL语句之后会返回主键值，在Java代码中就能够获取该主键对应的对象的属性值（即通过我所配置的keyProperty的值“id_autoIncrement”）。例如，UserDao接口定义了int addUser(User user)方法，一开始user对象的id值尚未初始化，因为该user还没有被添加进数据库，因此它还没有id，但是执行了insert方法之后，由于设置上面那个属性，这时调用user.getId()就会返回该user对象插入到数据库之后由数据库自动增长生成的Id值，相反，如果没有设置上面那两个属性，调用user.getId()就不会返回Id值。还有我猜测addUser方法返回的结果是不是也是Id值？经验证不是，只是插入成功的行数而已。 sql#搭配include标签可重复利用SQL代码段。没有什么特别的注意事项吧，看看官方文档还有博客就行。 resultMap结果映射（最关键也非常重要）#不使用resultMap标签配置结果映射#数据库中的列名与相应的JavaBean中的属性名不匹配怎么办？（1）用select as别名的方式；（2）使用resultMap标签来创建数据库列名到JavaBean的属性名的映射关系，然后在相应的SQL语句映射里面的resultMap属性配置上你使用resultMap标签创建的映射关系即可。 一对一#associate标签用来描述“一对一”的关系。例如，一个人有一个博客，在项目domain中可能有User和Blog，这时想要查询User对象以及对应的Blog，SQL语句有可能是这样的：select u.*,b.id as bid,b.title,b.brief from user u,blog b where u.id=b.id;相应的，若要建立相应的结果映射ResultMap就应当是这样的： 1234567891011&lt;resultMap id=\"user_blog_resultmap\" type=\"User\"&gt; &lt;id property=\"id\" column=\"id\"/&gt; &lt;result property=\"username\" column=\"username\"/&gt; &lt;result property=\"password\" column=\"password\"/&gt; &lt;result property=\"telephone\" column=\"telephone\"/&gt; &lt;spanssociate property=\"blog\" column=\"id\" javatype=\"Blog\"&gt; &lt;id property=\"id\" column=\"bid\"/&gt; &lt;result property=\"title\" column=\"title\"/&gt; &lt;result property=\"brief\" column=\"brief\"/&gt; &lt;/associate&gt;&lt;/resultMap&gt; 一对多#collection标签用来描述“一对多”的关系。例如，一个人可以有多个账单，假设在项目的domain中User有一个私有成员private List&lt;bill&gt; bills;那么此时对应的查询SQL语句可能是这样的： 123select u.*,b.id as bid,b.date as date,b.money as money from user u left outer join blog b on u.id = b.uid``` 并且最终的结果映射可能是这样的： 123456789101112131415161718### &lt;span id=\"1_7_4\"&gt;多对多&lt;/span&gt;“多对多”的关系同样可以用collection标签来描述。例如考虑这样一个应用场景，一个人可以有多种角色（例如职员，董事等），而一个角色也能够被赋予给多个人，假设在项目中的domain中对“人”以及“角色”有相应的JavaBean如下所示(省略getter和setter等方法，懒得写）： ```javapackage cn.uestc.domainpublic class User{ private int id; private String password; private String telephone; private List&lt;Role&gt; roles;}package cn.uestc.domainpublic class Role{ private in id; private String roleName; private List&lt;User&gt; users;} 而在数据库当中，除了对应的User表和Role表之外，由于是M:N的关系，需要有第三张表描述这个关系： 123456create table if not exist user_role(uid int not null,rid int not null,constraint user_role_uid_fk_ref_user foreign key (uid) references user(id) on delete cascade on update cascade,constraint user_role_rid_fk_ref_role foreign key (rid) references role(id) on delete cascade on update cascade)engine=InnoDB; 那么想实现，查询user以及该user被赋予的角色最终的Sql语句可能是这样的: 123select u.*,r.id as rid,r.rolename as rolename from user u left join user_role ur on u.id=ur.uid left join role r on ur.rid=r.id; 那么结果映射可能就是这样的： 123456789&lt;resultMap id=\"userAndCorrospondingRoles\" type=\"User\"&gt; &lt;id property=\"id\" column=\"id\"/&gt; &lt;result property=\"password\" column=\"password\"/&gt; &lt;result property=\"telephone\" column=\"telephone\"/&gt; &lt;collection property=\"roles\" ofType=\"Role\"&gt; &lt;id property=\"id\" column=\"rid\"/&gt; &lt;result property=\"roleName\" column=\"roleName\"/&gt; &lt;/collection&gt;&lt;/resultMap&gt; 同理，想要查询role以及被赋予了role角色的user最终的sql语句可能是这样的： 123select u.*,r.id as rid,r.rolename as rolename from role r left join user_role ur on r.id=ur.ridleft join user u on u.id=ur.uid; 相应的结果映射为： 123456789&lt;resultMap id=\"roleAndUsers\" type=\"Role\"&gt; &lt;id property=\"id\" column=\"rid\"/&gt; &lt;result property=\"roleName\" column=\"roleName\"/&gt; &lt;collection property=\"users\" ofType=\"User\"&gt; &lt;id property=\"id\" column=\"id\"/&gt; &lt;result property=\"password\" column=\"password\"/&gt; &lt;result property=\"telephone\" column=\"telephone\"/&gt; &lt;/collection&gt;&lt;/resultMap&gt; 二、Mybatis缓存机制#Mybatis有两级缓存，默认仅开启一级会话缓存，而二级缓存需要自己配置。 一级缓存#一级缓存的作用域是SqlSession对象，在每个SqlSession对象中都有一个Map作为缓存，当在同一个SqlSession对象上执行同样的查询操作时，第二次不会执行SQL语句，而是直接从SqlSession内部的Map当中取出对象返回，可以这样来验证： 1234567891011121314151617181920212223public class Test{ @Test public void test0(){ SqlSession sqlSession0 = MybatisUtil.getSqlSession(); UserDao userDao0 = sqlSession0.getMapper(UserDao.class); User user0 = userDao0.findUserById(1); User user1 = userDao0.findUserById(1); sqlSession0.close(); SqlSession sqlSession1 = MybatisUtil.getSqlSession(); UserDao userDao1 = sqlSession1.getMapper(UserDao.class); User user2 = userDao1.findUserById(1); if(user0==user1){ System.out.println(\"Yes\"); } if(user0!=user2){ System.out.println(\"No\"); } }}输出结果应该是：YesNo 因此关闭了SqlSession，相应的一级缓存也会被清空。 二级缓存#二级缓存的作用域是mapper，默认是不会开启二级缓存的，需要在mapper配置中加上&lt;cache/&gt;标签，并且对Sql语句使用useCache属性，这样就能开启二级缓存了，关于二级缓存的特性与更多配置，在Mybatis的官方文档解释得非常清楚，就不再多说，仅仅记录几个关键的点： 二级缓存作用域是mapper，跨sqlsession； 开启了二级缓存之后，一级缓存就失效了，查询语句都直接从二级缓存中拿数据； 二级缓存能够将对象序列化，因此Domain的JavaBean需要实现Serializable接口，否则会报错； 二级缓存能够自定义，只需要实现Cache接口就行，例如可以用Redis来实现一个分布式的二级缓存； 当调用了插入，更新等语句之后会清空二级缓存，注意上面说到二级缓存是作用域是mapper，也就是该mapper的二级缓存都会清空，因此，为了提高性能，有时候需要将那些不常更新的数据单独放在一个mapper当中。 三、Mybatis延迟加载#在Django框架的ORM系统中，同样有着这样的机制，即查询是“惰性”的，只有需要用到的时候才会执行查询，没有用到的时候不会执行查询，从而优化内存的使用。Mybatis的延迟加载也是类似的，但是Mybatis并不是默认这样的机制，需要在主配置文件的settings中进行配置才行，在Mybatis官方文档中对于延迟加载这个配置项这样描述： lazyLoadingEnabled：延迟加载的全局开关。当开启时，所有关联对象都会延迟加载,特定关联关系中可通过设置 fetchType 属性来覆盖该项的开关状态。aggressiveLazyLoading：当开启时，任何方法的调用都会加载该对象的所有属性。 否则，每个属性会按需加载（参考 lazyLoadTriggerMethods)。 因此想要使用延迟加载，首先需要在主配置文件当中将lazyLoadingEnabled与aggressiveLazyLoading设为true。其次，在配置resultMap时不能够完全按照上面来，以上面所说的“一对一”的关系为例： 1234567891011&lt;resultMap id=\"user_blog_resultmap\" type=\"User\"&gt; &lt;id property=\"id\" column=\"id\"/&gt; &lt;result property=\"username\" column=\"username\"/&gt; &lt;result property=\"password\" column=\"password\"/&gt; &lt;result property=\"telephone\" column=\"telephone\"/&gt; &lt;spanssociate property=\"blog\" column=\"id\" javatype=\"Blog\"&gt; &lt;id property=\"id\" column=\"bid\"/&gt; &lt;result property=\"title\" column=\"title\"/&gt; &lt;result property=\"brief\" column=\"brief\"/&gt; &lt;/associate&gt;&lt;/resultMap&gt; 若想实现延迟加载需要这样来配置： 1234567&lt;resultMap id=\"user_blog_resultmap\" type=\"User\"&gt; &lt;id property=\"id\" column=\"id\"/&gt; &lt;result property=\"username\" column=\"username\"/&gt; &lt;result property=\"password\" column=\"password\"/&gt; &lt;result property=\"telephone\" column=\"telephone\"/&gt; &lt;spanssociate property=\"blog\" column=\"id\" javatype=\"Blog\" select=\"selectBlog\"/&gt;&lt;/resultMap&gt; 并且除此之外还需要实现一个selectBlog（额外思考，这是如何实现的?我觉得是使用了代理，代理了JavaBean对象，并且拦截了getBlog()方法，并且假如的确是使用了代理，考虑到Java动态代理仅能对接口生效，因此，这里必然是使用CGLIB来完成代理功能的，实际上也确实是这样的，可去查看源码！）： 123&lt;select id=\"selectBlog\" resultType=\"Blog\"&gt; select * from blog where id=#{id};&lt;/select&gt; 相应的还需要一个SQL语句： 1select * from user 这时，当业务调用查询user的Dao层接口时，不会立即将blog查询，而是当用到的时候才会执行（例如执行完查询user之后返回的user对象，调用user.getBlog()方法，将导致上面的selectBlog执行）。此外，这里有一个点，就是associate标签中的column应该怎么取数据库中的哪一列？官方文档是这么解释的： select：用于加载复杂类型属性的映射语句的 ID，它会从 column 属性中指定的列检索数据，作为参数传递给此 select 语句。具体请参考关联元素。 答案就很明显了，可以看到selectBlog中使用到id作为参数，那么associate中也要对应，并且更重要的是，查询列表得有叫id的列，从resultMap的配置来看，显然是满足了这些要求的。 不过这样的方式对于大数据集存在N+1的问题，并且会产生严重的性能问题。Mybatis推荐了另外一种方式，resultMap的嵌套映射，详情可参考Mybatis官方文档。同样继续改进上面的那个例子： 12345678910111213&lt;resultMap id=\"user_blog_resultmap\" type=\"User\"&gt; &lt;id property=\"id\" column=\"id\"/&gt; &lt;result property=\"username\" column=\"username\"/&gt; &lt;result property=\"password\" column=\"password\"/&gt; &lt;result property=\"telephone\" column=\"telephone\"/&gt; &lt;spanssociate property=\"blog\" column=\"id\" javaType=\"Blog\" resultMap=\"blogMap\"/&gt;&lt;/resultMap&gt;&lt;resultMap id=\"blogMap\" type=\"Blog\"&gt; &lt;id property=\"id\" column=\"bid\"/&gt; &lt;result property=\"title\" column=\"title\"/&gt; &lt;result property=\"brief\" column=\"brief\"/&gt;&lt;/resultMap&gt; 此时就不能像上面用select属性一样，单独有一个SQL语句，而应该这样使用整体的SQL语句，但是，这种方式没有延迟加载的效果，其实也能发现和之前直接放入associate，不使用associate的resultMap属性是完全一样的，不同的是，这样可以复用resultMap，所以也很不错： 1select u.*,b.id as bid,b.title as title,b.brief as brief from user u,blog b where u.id=b.uid;","link":"/2019/11/25/踩过的Mybatis坑及一些注意事项总结/"},{"title":"浅谈Java线程池","text":"文章目录# 浅谈Java线程池（jdk1.8) 线程池状态部分 构造函数中的参数部分 线程池提供的hook function 初探execute(Runnable command)方法 线程池的核心:Worker 理清脉络 浅谈Java线程池（jdk1.8)# 本博客来源于自己在看JDK线程池源码时，边看边同步写下的笔记，因此排版基本没有，希望见谅； 仅仅只是分析了比较核心的实现，限于个人目前的水平，尚有不理解之处，写的内容也可能有差错，非常乐意接受您的指正与建议； 对于线程终止，shutdown()与shutdownNow()我觉得没必要说，因为源代码很清晰，阅读者这部分代码也没什么难度，因此没有说这一部分 线程池状态部分# 使用一个AtomicInteger类型的ctl来存储wokerCount和线程池运行状态runSate，其中高3位用来存储runState，而低29位存储wokerCount，因此在jdk1.8的设计当中，有效线程数量最多是2^29-1,而不是2^31-1; 线程池有五种运行状态： RUNNING:能够接受新的任务并且能够处理队列中的任务。数值为0xE0 00 00 00(也就是高三位为1，后29位为0); SHUTDOWN:不能接受新的任务，但是还能处理队列中的任务。数值为0x00 00 00 00; STOP:不能接受新的任务，也不能处理队列中的任务，等待终止正在进行中的任务。数值为0x20 00 00 00; TIDYING:所有的任务都已经终止，wokerCount等于0。数值为0x40 00 00 00; TERMINATED:terminated()方法已经完成，则进入该状态。数值为0x50 00 00 00; 之所以这样安排线程池的运行状态的数值，是为了方便通过数值大小的比较，可以发现从数值上来说RUNNING&lt;SHUTDOWN&lt;STOP&lt;TIDYING&lt;TERMINATED。线程池的状态只可能这样转换： RUNNING -&gt; SHUTDOWN（显式调用shutdown()或者隐式地通过finalize()方法来自动调用； RUNNING or SHUTDOWN -&gt; STOP（显式调用shutdownNow()) SHUTDOWN -&gt; TIDYING（当线程池为空） TIDYING -&gt; TERMINATED（当terminated()钩子方法调用结束，terminated()方法是一个protected的空方法，可以通过继承来重写该方法，当线程池状态转变为TIDYING时将会调用该方法，该方法调用完成之后线程池就会进入TERMINATED状态，当线程池进入TERMINATED状态时awaitTermination()方法才会返回； （TEMP）检测线程池是否能从SHUTDOWN进入TIDYING状态有trick,（在队列非空之后可能变为空，在关闭状态下，队列也可能变为空，但是我们只能在wokerCount为0(有时需要重新检查)的情况下才能终止）； 1234567891011121314151617181920private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3;private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1;private static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS;private static int runStateOf(int c) { return c &amp; ~CAPACITY; }private static int workerCountOf(int c) { return c &amp; CAPACITY; }private static int ctlOf(int rs, int wc) { return rs | wc; }private static boolean runStateLessThan(int c, int s) {return c &lt; s;}private static boolean runStateAtLeast(int c, int s) {return c &gt;= s;}private static boolean isRunning(int c) {return c &lt; SHUTDOWN;} 因此可以看到runStateOf(int c)实际上就是返回了c的高三位，因为CAPACITY数值为0x1F FF FF FF; workerCountOf(int c)实际上就是返回了c的低29位，也就是worker的数量； ctlOf(int rs,int wc)实际上就是将runState与wokerCount组合起来的一个整数返回，也就是ctl的值； 同时也注意到线程池初始状态为RUNNING，且wokerCount初始为0； 构造函数中的参数部分#直接看代码： 1234567891011121314151617181920212223242526272829303132private final BlockingQueue&lt;Runnable&gt; workQueue;private volatile ThreadFactory threadFactory;private volatile RejectedExecutionHandler handler;private volatile long keepAliveTime;private volatile int corePoolSize;private volatile int maximumPoolSize; public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null?null:AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; } 关于corePoolSize和maximumPoolSize,当一个任务到达时，线程数量小于corePoolSize，即便有其它空闲的线程，也会直接创建一个新线程，并且该任务不会入队，而是直接创建线程来处理该任务。当且仅当没有空闲线程并且workQueue已满的时候才会创建超出corePoolSize的线程，而keepAliveTime则指定了超出corePoolSize数量的线程在处理完任务之后的空闲状态维持的时间，超出该时间则该线程会被销毁（注：后续这里最好用实际的代码来说明） workQueue存储execute提交的任务，如果处理任务的线程数量小于corePoolSize，那么该任务不会入队而是尝试直接创建一个新线程来处理该任务 threadFactory提供了创建线程的方式，如果没有指定，则会提供一个默认的线程工厂，并且所有线程都属于同一个threadGroup，非守护线程，具有相同的优先级等，如果希望自定义这些参数，则需要自己提供一个实现了ThreadFactory接口的自定义的线程工厂 handler定义了如何处理在线程池调用了shutdown()方法之后提交的任务的策略，通常有四种方式（这里就不再赘述，可自行查看文档，其实通过名字也能大概知道这些策略的意思了）： ThreadPoolExecutor.AbortPolicy(默认策略） ThreadPoolExecutor.CallerRunsPolicy ThreadPoolExecutor.DiscardPolicy ThreadPoolExecutor.DiscardOldestPolicy 线程池提供的hook function# 线程池还提供了几个未实现的空的钩子函数，通过继承线程池类并且重写这些方法就能创建一个在功能上实现了扩展的自定义线程池，这些方法有： beforeExecute(Thread, Runnable) afterExecute(Runnable, Throwable) terminated() …… 初探execute(Runnable command)方法#当我们指定一系列参数实例化一个线程池对象之后，通常就会调用execute方法来提交任务，因此，我也以这样的顺序来分析。直接上代码： 123456789101112131415161718192021222324252627282930313233343536373839404142public void execute(Runnable command) { if (command == null) throw new NullPointerException(); // 在下方之所以多次查询线程池的运行状态，完全就是因为并发所要求的，因 // 为没有同步机制，所以无法确保下一时刻的状态和判断时查询的状态一致， // 但是实际上这种方法似乎并不能完全确保得到的状态是正确的，只是可能在 // 这个系统的设计上认为这样的差异是可以忍受的，完全没有必要为了确保得 // 到的状态正确而使用锁，导致性能上的下降 int c = ctl.get(); // 若wokerCount小于corePoolSize，则直接尝试创建新线程(core型)来处理, // 线程创建成功则会直接返回 if (workerCountOf(c) &lt; corePoolSize) { if (addWorker(command, true)) return; c = ctl.get(); } // 若线程池处于运行状态并且向workQueue中提交任务成功，则再一次检查线程池 // 的运行状态，若此时线程池不再处于运行状态了(!isRunning(recheck))，就尝试 // 从workQueue中移除该任务，若移除成功，则调用reject(command)方法，该方法 // 实际上就是调用了handler中的rejectedExecution方法，通过提供不同的饱和策略 // RejectedExecutionHandler，可以有不同的处理方法。相反，若此时系统仍处于运行状态 // 并且工作线程数量为0时，创建一个新线程 // 相反，若任务入队失败，则尝试创建一个线程（没有设置core为true，则只会检查是否 // 运行线程数量是否已达上限），若失败，则表明此时线程池已经shutdown或者饱和了 // (并不是指队列满了而是线程数量已达上限)，因此直接调用reject(command) if (isRunning(c) &amp;&amp; workQueue.offer(command)) { int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); } else if (!addWorker(command, false)) reject(command); }final void reject(Runnable command) { handler.rejectedExecution(command, this); } 可以看到，注释说得就已经非常地清楚了，首先ctl是一个AtomicInteger类，因此保证了原子性与可见性，可以看到，当woker的数量小于corePoolSize的时候，会尝试直接创建新线程，即addWorker(command,true),true标记该线程是core线程，core线程即便空闲了也不会被销毁，如果成功创建线程处理该command，那么函数直接返回。 其实接下来的思路很明显了，根据我们使用线程池的方式，初始化之后提交任务即可创建线程，运行线程，实现线程复用，因此想要了解线程池是如何实现线程复用的，那么关键就必然在worker以及addWorker中，因此，虽然在ThreadPoolExecutor中有那么多函数，但是就我们的目的而言，其它函数基本就可以不看了。 线程池的核心:Worker#123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107// Worker的部分定义，对于Woeker中定义的其它函数，不需要去了解是怎么实现的 private final class Worker extends AbstractQueuedSynchronizer implements Runnable{ final Thread thread; Runnable firstTask; // 统计该worker成功执行的任务数,线程封闭,为线程内部的局部变量，不会产生安全性问题 volatile long completedTasks; // 可以看到worker创建之后即持有一个线程工厂产生的线程对象，并且该线程运行的 // 就是worker的run方法，而worker的run方法实际调用的是线程池的runWorker方法 // 因此实现线程复用的关键必然就在runWorker方法之中 Worker(Runnable firstTask) { setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); } // public void run() { runWorker(this); // 传递该worker本身 } }// !!!线程池实现线程复用的核心函数!!!// Worker的run方法实际上所调用的函数,删掉了部分异常处理，为了更清楚地看到运行逻辑final void runWorker(Worker w) { Thread wt = Thread.currentThread(); // 获取运行线程 Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try { // 结合对之前execute的分析，worker初始化可能有任务，可能没有 // 因此这里可以看到，这里判断该worker初始是否有task，初始没有 // task就尝试从wokerQueue中获取task，这其实就是实现线程复用的 // 关键，创建的线程就是消費者，从生产者workQueue中获取任务来执行 // 执行完毕之后继续循环; // !!!但是考虑这样一种情况，task为null并且在调用getTask时也为null // 当你查看getTask函数源码时，你也会发现，当workeQueue为空时 // getTask函数中就会调用compareAndDecrementWorkerCount，并且返回null, // 结合这里的while循环你就懂了，若getTask返回null,则该worker线程必然 // 就结束while循环终止了，那么就可能使线程池中的worker数量小于 // corePoolSize，这显然不对，因此processWorkerExit函数中就会对这个 // 情况进行处理 while (task != null || (task = getTask()) != null) { w.lock(); if ((runStateAtLeast(ctl.get(), STOP) ||(Thread.interrupted()&amp;&amp;runStateAtLeast(ctl.get(), STOP)))&amp;&amp;!wt.isInterrupted()) wt.interrupt(); try { beforeExecute(wt, task); // 钩子函数，默认没有实现 Throwable thrown = null; task.run(); // 由我们提交的任务的run方法在这里被调用 // 注：实际上这里是有try..catch块的，这里删掉了，方便看代码 // 在这里的try..catch..finall块中的finally方法实际还调用了 // afterExecute(wt,task)钩子函数 } finally { task = null; w.completedTasks++; // 该worker完成的任务数加1 w.unlock(); } }// while completedAbruptly = false; } finally { processWorkerExit(w, completedAbruptly); } }private void processWorkerExit(Worker w, boolean completedAbruptly) { // 查看runWorker方法 if (completedAbruptly) // If abrupt, then workerCount wasn't adjusted decrementWorkerCount(); // 互斥地访问所有线程共享的变量，统计已经完成的任务的数量 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { completedTaskCount += w.completedTasks; workers.remove(w); } finally { mainLock.unlock(); } tryTerminate(); int c = ctl.get(); // 在RUNNING,SHUTDOWN状态下，仍然要维护worker的数量，否则 // 可能有这种情况发生：即所有worker线程都已经进入终止状态，但是 // workQueue中的任务还没有处理完，相反，如果线程池已经进入STOP状态 // 那么就只需要等待所有任务执行完毕即可 if (runStateLessThan(c, STOP)) { if (!completedAbruptly) { // 可以看到线程池至少会维护一个worker来执行任务 int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; // 运行线程数量大于min，则无需创建新线程以达到线程池中线程数的最低要求 if (workerCountOf(c) &gt;= min) return; } // 可以看到这里还能够增加worker，正是解决了在runWorker中所提到的问题 addWorker(null, false); } } 到了这里，可能会有疑问，线程只有在调用start方法之后才算开启线程，那么start方法是在哪里调用的，其实很显然，是在addWorker函数中实现的： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364private boolean addWorker(Runnable firstTask, boolean core) { retry: for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) { int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop } } boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try { w = new Worker(firstTask); // 创建新worker final Thread t = w.thread; // 获取worker持有的线程 if (t != null) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) { if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); // workers是线程池中的一个HashSet,用来存储Worker int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; } } finally { mainLock.unlock(); } if (workerAdded) { t.start(); // 在这里启动线程 workerStarted = true; } } } finally { if (! workerStarted) addWorkerFailed(w); } return workerStarted; } 理清脉络#通过上面的分析，对线程池实现线程复用的方式以及线程的创建与维护的逻辑基本上就理个大概了，下面就从提交任务开始，从头理一下整个程序大致上运行的逻辑（忽略了很多细节，只是为了理清脉络）: 提交任务execute -&gt; 调用addWorker或者将任务入队(workQueue) -&gt; 创建Worker对象，该Worker对象持有一个线程对象，并且该线程对象最终调用的就是该Worker对象的run方法，而Worker对象的run方法中就仅仅只是调用了线程池的成员函数runWorker -&gt; runWorker就是消費者，向生产者workQueue索要任务，拿到任务之后，就调用该任务的run方法（这个就是由我们初始向execute中传递的Runnable对象的run方法) -&gt; 执行完毕之后再向workQueue索要任务 所以这就是实现线程复用的基本原理，其实单纯考虑原理很简单，不是很准确地说（个人理解）：就是采用生产者-消费者的模式，创建消费者线程，在该线程中使用一个while循环向生产者workQueue索要任务执行。","link":"/2019/10/28/浅谈Java线程池/"},{"title":"HashMap+ConcurrentHashMap+同步HashMap","text":"文章目录:# 一、概述 二、Hash算法概述 三、红黑树原理 四、HashMap源码分析 内部Node结点 putVal方法 获取散列桶索引值的方法 整个put方法流程图 为什么自己定义的类作为键值需要重写hashCode()以及equals()方法？ get方法 resize方法 计算新的散列表容量以及实际能容纳的键值对的数量的阈值 对一个给定值p，如何计算相应的小于P的2的幂的最大值？如何计算大于p的2的幂的最小值？ 需要改变位置的键值对放置到散列桶中 五、同步容器SynchronizedMap 六、使用了“魔法”的并发容器ConcurrentHashMap “黑魔法”sun.misc.Unsafe Volatile table element access 多线程环境下初始化散列表initTable() putVal helpTransfer[to do] addCount[to do] 参考资料 一、概述# 二、Hash表概念回顾# 【1】哈希表：根据设定的哈希函数H(key)和处理冲突的方法将一组关键字映像到一个有限的连续的地址集（区间）上，并以关键字在地址集中的“像”作为记录在表中的存储位置，这种表便称为哈希表，这一映像过程称为哈希造表或散列，所得存储位置称为哈希地址或散列地址。 常见的几种哈希函数的构造方法： 直接定址法：取关键字或关键字的某个线性函数值为哈希地址。即： *H(key)=key或H(key)=a·key+b* 数字分析法：假设关键字是以r为基的数，并且哈希表中可能出现的关键字都是事先知道的，则可取关键字的若干数位组成哈希地址。 平方取中法：取关键字平方后的中间几位为哈希地址。 折叠法：将关键字分割成位数相同的几部分，然后取这几部分的叠加和作为哈希地址。 除留取余法：取关键字被某个不大于哈希表表长m的数p除后所得余数为哈希地址，通常取素数，因为使用素数会降低发生哈希冲突的概率。即： *H(key)=key MOD p,p","link":"/2019/12/05/HashMap-ConcurrentHashMap-同步HashMap/"},{"title":"代理模式以及它与装饰模式的异同","text":"文章目录# 一、代理设计模式 组成 分类 静态代理UML结构图 静态代理模式示例 静态代理的局限性 动态代理 动态代理UML结构图 Additional Thinking 二、装饰设计模式 三、二者异同 参考资料 一、代理设计模式#组成#代理模式包含如下角色： Subject：抽象角色。通过接口或抽象类声明真实角色实现的业务方法。 Proxy：代理角色。实现抽象角色，是真实角色的代理，通过真实角色的业务逻辑方法来实现抽象方法，并可以附加自己的操作。 RealSubject：真实角色。实现抽象角色，定义真实角色所要实现的业务逻辑，供代理角色调用。 分类#代理可分为静态代理和动态代理，静态代理需要自己按照上面的UML类图来实现，并且在是在编译时就已经确定了代理，而Java提供了动态代理的方式，在反射包下面的DynamicProxy中，可以通过Proxy来运行时完成动态代理。 静态代理UML结构图# 静态代理模式示例#首先创建抽象角色： 1234567/** 抽象主题角色* 为真实主题角色以及代理主题角色统一接口* */public interface Subject { void doSomething();} 然后创建真实角色并实现抽象角色接口 12345678910/** 真实角色* 实现了抽线角色接口* */public class RealSubject implements Subject,SubjectAnother { @Override public void doSomething() { System.out.println(\"RealSubject doSomething.\"); }} 其次再创建代理角色，同样也实现抽象角色接口，并且代理角色持有真实角色 123456789101112131415161718192021/** 代理角色* */public class Proxy implements Subject { /* * 持有一个真实角色的引用 * */ private Subject realSubject; public Proxy(Subject realSubject){ this.realSubject = realSubject; } @Override public void doSomething() { // 在真实角色接口前附加职责 System.out.println(\"Before realSubject.doSomething().\"); realSubject.doSomething(); // 调用真实角色的相应接口 System.out.println(\"After realSubject.doSomething().\"); }} 最后让我们测试静态代理的效果： 123456789101112131415public class Main { public static void main(String[] args) { // 创建真实角色对象 Subject realSubject = new RealSubject(); // 用代理对象代理真实角色对象 Subject proxySubject = new Proxy(realSubject); // 调用抽象角色定义的接口 proxySubject.doSomething(); }}// 输出结果为：Before realSubject.doSomething().RealSubject doSomething.After realSubject.doSomething(). 静态代理的局限性# 重复性。需要代理的接口越多就要去重复生成一些模板化的代码，不仅麻烦而且不易维护。 脆弱性。一旦接口的定义修改，实现了该接口的真实角色以及代理角色的定义也要修改。 动态代理#JVM可以在运行器件动态生成类字节码（名字为$Proxy0），这种动态生成的类通常用来作为代理类，即动态代理类。JVM生成的动态代理类必须实现一个或多个接口，所以JVM生成的动态类只能用作具有相同接口的目标类的代理，如果要为一个没有实现接口的类生成动态代理类，可以使用CGLIB（实际上这也是SPRING框架除了JDK Proxy之外采用的另外一种生成代理类的方法），这里不对CGLIB作具体介绍。 动态代理UML结构图#Java动态代理运用示例（就用刚才静态代理定义的接口以及真实角色）：首先自定义调用处理器（对代理对象的方法的调用最终都会被委派到自定义调用处理器上）： 12345678910111213141516171819/** 自定义调用处理器，必须实现InvocationHandler接口* */public class InvocationHandlerImp implements InvocationHandler { // 被代理对象 private Object object; public InvocationHandlerImp(Object object){ this.object = object; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(\"Invoke class \"+proxy.getClass()+\" and method \"+method); // Method是在代理对象上调用的方法对应的Method对象 // args是参数列表 return method.invoke(object,args); }} 然后有两种方式创建代理对象:方法一： 12345678910111213141516171819202122public class ProxyTest1 { public static void main(String[] args) { // 实际对象(即要被代理的对象) Subject subject = new RealSubject(); // 调用处理器，传入被代理对象 InvocationHandler invocationHandler = new InvocationHandlerImp(subject); // 为SubjectAnother接口以及Subject接口创建代理Class对象 // 【TIPS】注意接口的传入顺序，并且也要注意到SubjectAnother与Subject有着一个相同的方法签名doSomething() Class&lt;?&gt; proxyClass = Proxy.getProxyClass(ProxyTest1.class.getClassLoader(), SubjectAnother.class, Subject.class); try { // 获取代理对象的构造器 Constructor&lt;?&gt; constructor = proxyClass.getConstructor(InvocationHandler.class); // 通过构造器获取动态代理对象 // 这里不通过Class对象的newInstance()方法创建代理对象的原因是其只能够调用无参构造方法，而Constructor对象则可调用任意构造方法（有参无参多参） Subject proxySubject = (Subject) constructor.newInstance(invocationHandler); // 调用代理对象的接口，最终都会被委派到InvocationHandlerImp中的invoke方法当中 proxySubject.doSomething(); } catch (NoSuchMethodException | InvocationTargetException | InstantiationException | IllegalAccessException e) { e.printStackTrace(); } }} 方法二（实际上就是将方法一的步骤封装起来，可查看源码验证）： 12345678910public class ProxyTest { public static void main(String[] args) { InvocationHandler invocationHandler = new InvocationHandlerImp(new RealSubject()); // Proxy.newProxyInstance方法为我们封装了那一系列步骤 Subject proxySubject = (Subject) Proxy.newProxyInstance(ProxyTest.class.getClassLoader(), new Class[]{SubjectAnother.class, Subject.class}, invocationHandler); proxySubject.doSomething(); }} 为了验证一些在JDK DOC中提到的一些动态代理中的坑，可以看到RealSubject实现了两个接口Subject与SubjectAnother，其中SubjectAnother接口定义如下所示： 123public interface SubjectAnother { void doSomething();} 可以看到SubjectAnother接口定义了一个与Subject接口中方法签名一样的方法。结果输出如下所示（两种方法创建的代理对象调用doSomething结果一致）： 12Invoke class class com.sun.proxy.$Proxy0 and method public abstract void com.qin.proxyTest.SubjectAnother.doSomething()RealSubject doSomething. 可以发现一个问题，无论是在方法一还是在方法二中，我向Handler中传递的都是Subject类型的真实对象的引用，并且代理对象都被我强制转换为Subject接口类型了，那么按道理被代理的接口类型应当是Subject才对，但是从输出结果来看，调用的doSomething()实际上是SubjectAnother中的定义，这是为什么？其实在JDK DOC中已经对这个trick作了说明如下： 【引用来自JDK8 DOC】When two or more interfaces of a proxy class contain a method with the same name and parameter signature, the order of the proxy class’s interfaces becomes significant. When such a duplicate method is invoked on a proxy instance, the Method object passed to the invocation handler will not necessarily be the one whose declaring class is assignable from the reference type of the interface that the proxy’s method was invoked through. This limitation exists because the corresponding method implementation in the generated proxy class cannot determine which interface it was invoked through. Therefore, when a duplicate method is invoked on a proxy instance, the Method object for the method in the foremost interface that contains the method (either directly or inherited through a superinterface) in the proxy class’s list of interfaces is passed to the invocation handler’s invoke method, regardless of the reference type through which the method invocation occurred. 可以注意到我代理接口时是先传入了SubjectAnother.class再传入了Subject.class，由于二者有着一样的方法签名doSomething()，而根据JDK8 DOC的解释，最终传入invoke的Method对象的应用将是传入顺序在前的SubjectAnother接口的doSomething()方法，这与验证结果保持一致。 Additional Thinking#Q：invoke方法中的proxy参数是什么？通过翻阅参考文档以及从参数名就可以推测proxy实际就是生成的动态代理类的引用，还记得我们在动态代理示例中的输出吗，在InvocationHandler的invoke方法中调用proxy.getClass()输出的信息是class com.sun.proxy.$Proxy0，这就是动态代理类，下面可以去验证一下： 首先修改之前的InvocationHandlerImp中的invoke方法，将生成的动态代理类proxy的字节码保存到.class文件当中： 12345678910111213141516171819202122/** 自定义调用处理器，必须实现InvocationHandler接口* */public class InvocationHandlerImp implements InvocationHandler { // 被代理对象 private Object object; public InvocationHandlerImp(Object object){ this.object = object; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { String simpleName = proxy.getClass().getSimpleName(); byte[] bytes = ProxyGenerator.generateProxyClass(simpleName, proxy.getClass().getInterfaces()); // 将代理类proxy的字节码文件保存到$Proxy0.class文件中 BufferedOutputStream ops = new BufferedOutputStream(new FileOutputStream(\"./\"+ simpleName+\".class\")); ops.write(bytes); ops.close(); return method.invoke(object,args); }} 然后就能够得到一个$Proxy0.class文件：然后反编译该字节码文件：javap -p $Proxy0.class 得到结果如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public final class $Proxy0 extends Proxy implements SubjectAnother, Subject { private static Method m1; private static Method m3; private static Method m2; private static Method m0; public $Proxy0(InvocationHandler var1) throws { super(var1); } public final boolean equals(Object var1) throws { try { return (Boolean)super.h.invoke(this, m1, new Object[]{var1}); } catch (RuntimeException | Error var3) { throw var3; } catch (Throwable var4) { throw new UndeclaredThrowableException(var4); } } public final void doSomething() throws { try { super.h.invoke(this, m3, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final String toString() throws { try { return (String)super.h.invoke(this, m2, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final int hashCode() throws { try { return (Integer)super.h.invoke(this, m0, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } static { try { m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", Class.forName(\"java.lang.Object\")); m3 = Class.forName(\"com.qin.proxyTest.SubjectAnother\").getMethod(\"doSomething\"); m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\"); m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\"); } catch (NoSuchMethodException var2) { throw new NoSuchMethodError(var2.getMessage()); } catch (ClassNotFoundException var3) { throw new NoClassDefFoundError(var3.getMessage()); } }} 在静态代码块里对m0,m1,m2,m3进行了初始化，可以看到，不仅被代理接口自己声明的doSomething接口会被委派到invoke函数，被代理对象从Object继承的equals(),toString()以及hashCode()方法也会被自动委派（实际上这个在API文档中有提到！） 然后我们查看该代理类的doSomething()方法，实际上就执行了这一行： 1super.h.invoke(this, m3, (Object[])null); 而super.h实际上就是父类Proxy中的一个保护成员： 1234/*** 此声明来源于JDK8 Proxy类的源码*/protected InvocationHandler h; 因此上面那行代码实际上就是调用了我们自定义的InvocationHandlerImp中定义的invoke方法，而给proxy参数传递的引用是this，也就是生成的动态代理类$Proxy0的对象的this引用，可见proxy参数就是代理类的引用！ 二、装饰设计模式#在我的另外一篇博文中已经讨论过：浅谈装饰器设计模式Java I/O结合装饰器模式的一点理解 三、二者异同#关于二者异同，由于个人水平所限，我查阅了很多资料，但是似乎没有一个特别标准的回答，在这里，我会将自己所看到的大多数人都认同的点进行简单的归纳（或许会持续更新），以及附上原文链接。相同点： 如你所见，二者的结构是类似的 不同点： 应用场景不同。Proxy常用来延迟实例化(Lazy-instantiate)被代理对象，隐藏远程服务( Hide Remote Service)，控制对被代理对象的访问权限等，典型例如Hibernate框架的延迟加载就是通过动态代理实现的；而Decorator又称为“智能代理”(Smart Proxy)，它使得你可以在运行时向对象添加功能，典型例如new BufferedInputStream(new FileInputStream(...))等。 Decorator通常允许“链式叠加”（非准确描述），而Proxy则不允许。例如在C++中的Stream* aStream = new CompressingStream(new ASCII7Stream(new FileStream(&quot;fileName.dat&quot;)))，而代理往往不能够这样; Decorator强调的是职责附加(Additional Responsibility)，提供增强的接口(enhanced interface)而Proxy往往强调对被代理对象的访问控制等并提供相同的接口(Same interface) 参考资料 【StackOverflow】Differences between Proxy and Decorator Pattern【StackOverflow】How do the Proxy, Decorator, Adapter, and Bridge Patterns differ?","link":"/2019/11/19/代理模式以及它与装饰模式的异同/"},{"title":"关于动态规划的一点简单思考","text":"文章目录# 零、鸣谢 一、写这篇博客的背景 二、要不，先上个萝卜丁开开胃？ 例子概览 Maximal Square Brust balloons version-0 回溯法未优化版 version-1 记忆优化版本回溯 version-2 动态规划版本 Shortest Common Supersequence Wildcard Matching 三、别问，问就是使劲刷题 四、没什么用的技巧总结 五、动态规划入门模型回顾 参考资料 零、鸣谢#感谢室友祁挣斌友情制作动态图 一、写这篇博客的背景#为了面试，这段时间，在leetcode上刷刷算法题，做了很多道题之后，在Best Time to Buy and Sell Stock IV这道题始终超内存不知该如何解决的时候，在讨论区看到了Most consistent ways of dealing with the series of stock problems用同一个套路解决leetcode中六道关于股票买卖的题目，让我大开眼界，也让我只能感叹自己之前解决的几个股票买卖的解法就是shit。总而言之，这篇非常优秀的文章给予了我打算写这篇博客的源动力，其次，就是想把这几天集中训练动态规划题目的一点小小收获与感想记录下来，便于日后复习。 二、要不，先上个小菜？#俗话说，”talk is cheap,show me the code”，因此通过几个例子来完整记录一下自己对几个典型题目的解决方式。(不会附上题目，可通过点击链接进入leetcode主页自行查看题目描述)用到了4个题目作为例子，难度为中等、困难、困难以及困难，如下所示： 例子概览# #221 Maximal Square #312 Brust balloons #1092 Shortest Common Supersequence #44 Wildcard Matching Maximal Square#题目描述：Maximal Square 这道题很简单，定义： dp[i][j]为以matrix[i][j]为左上角的最大正方形的边长 边界条件： $dp[rowThresh - 1][k] = matrix[rowThresh - 1][k] - ‘0', 0≤ k &lt;columnThresh$; $dp[k][columnThresh - 1] = matrix[k][columnThresh - 1] - ‘0', 0 ≤ k &lt; rowThresh$; 状态转移方程： dp[i][j]取决于dp[i + 1][j]与dp[i][j + 1]以及可能存在的右下角的方格中元素是否为’1’，具体看图： 有两种情况，灰色为当前matrix[i][j]所处位置，对应于dp[i][j]，红色以及黄色代表右侧的正方形与下方的正方形，优先挑小的正方形的边长为len，并且可能会多出右下角的小方块没有验证是否为1：根据不同的情况，最终dp[i][j]的值可更新为（绿色表示应当选择的正方形）： 状态的枚举顺序：这种本身题目二维数组就提示了动态规划状态的设计思路以及子状态通常也只会与临近方块相关，并且按照常规方式枚举也不会有太大问题，不需要什么枚举子状态的特殊技巧。由于我将dp[i][j]定义为以matrix[i][j]为左上角的最大正方形的边长，因此只需要从右下角往左上角遍历状态即可。 代码： 123456789101112131415161718192021222324252627282930313233343536class Solution { public int maximalSquare(char[][] matrix) { if(matrix == null || matrix.length == 0 || matrix[0].length == 0)return 0; int rowThresh,columnThresh,maxLen = 0; rowThresh = matrix.length - 1; columnThresh = matrix[0].length - 1; int[][] dp = new int[rowThresh + 1][columnThresh + 1]; // 初始化边界条件，我所采取的是从右下角往左上角递推，因此初始化右、下两条边的边界条件 for(int i = 0;i &lt;= columnThresh; ++i){ dp[rowThresh][i] = matrix[rowThresh][i] - '0'; if(dp[rowThresh][i] == 1)maxLen = 1; } for(int i = 0;i &lt;= rowThresh; ++i){ dp[i][columnThresh] = matrix[i][columnThresh] - '0'; if(dp[i][columnThresh] == 1)maxLen = 1; } // 递推 for(int i = rowThresh - 1;i &gt;= 0; --i){ for(int j = columnThresh - 1;j &gt;= 0; --j){ if(matrix[i][j] == '1'){ int possibleLen = Math.min(dp[i + 1][j], dp[i][j + 1]); if(possibleLen &gt; 0 &amp;&amp; matrix[i + possibleLen][j + possibleLen] == '1'){ dp[i][j] = possibleLen + 1; }else{ dp[i][j] = possibleLen &gt; 1?possibleLen:1; } if(dp[i][j] &gt; maxLen)maxLen = dp[i][j]; } } } return maxLen * maxLen; }} 时间复杂度：O(rowThresh * columnThresh)空间复杂度：O(rowThresh * columnThresh) Brust balloons#题目描述：Brust balloons这道题，看第一眼就想到用回溯法应该如何做了，并且也能够预计到单纯递归必然超时，但是动态规划第一眼没什么头绪，只能先写出递归，再通过记忆化优化，最后找出状态转移方程了。 version-0 回溯法未优化版#1234567891011121314151617181920public int recursively(int[] nums,int size){ if(size == 0)return 0; int result = 0,leftBalloonValue,righBalloontValue,originValue,j,i; for(i = 0;i &lt; nums.length; ++i){ if(nums[i] &gt;= 0){ // 找左右气泡 for(j = i - 1;j &gt;= 0 &amp;&amp; nums[j] &lt; 0; --j); leftBalloonValue = j &lt; 0?1:nums[j]; for(j = i + 1;j &lt; nums.length &amp;&amp; nums[j] &lt; 0; ++j); righBalloontValue = j &gt;= nums.length?1:nums[j]; originValue = nums[i]; nums[i] = -1; result = Math.max(result, recursively(nums, size - 1) + leftBalloonValue * originValue * righBalloontValue); nums[i] = originValue; } } return result;} 解法很好理解，对于气球[i,j],戳破某一个气球k，k∈(i,j)之前，先计算出其子问题即，把气球(i,k)以及气球(k,j)戳破完能得到的最大值，并且为了避免气球k被重复戳破，将气球k的权值标为-1，表明其已被戳破（因为题目指明了气球的权值为非负数），并且在计算完子问题，将气球k的权值恢复，以便后续递归。用图来说明就是: 现在单纯考虑气球(i,j)之间，若要求得戳破i,j之间所有气球的最大值，就需要枚举i,j之间的所有的气球也即function(i,j) = max{function(i,k)+function(k,j)+nums[i]×nums[k]×nums[j]}, k∈(i,j) 时间复杂度：假设共有n个气球，则第一层，可戳破n个，第二层，可戳破(n-1)个，因此该算法至少是n(n-1)(n-2)······1即n!的时间复杂度空间复杂度：递归栈最多n层，因此为O(n) version-1 记忆化优化版本回溯#单纯暴力回溯时间复杂度过大，但是经过上面递归版本的描述，很容易发现，在计算子问题时会发生许多重复计算，考虑到在递归的某一层气球(i,j)结束的时候，戳破(i,j)之间气球能得到的最多硬币数就已知了，因此，将该值记录下来，当再递归到(i,j)的时候，直接返回记录的值，就能减少大量的重复计算了。 123456789101112131415161718192021//记忆化之后能够顺利通过，已经无法通过减少乘法计算次数来优化执行时间了，优化到极限了private int[][] memory;public int maxCoins1(int[] nums){ int len; if(nums == null || (len = nums.length) == 0)return 0; memory = new int[len + 2][len + 2]; return recursively(nums,-1,len);}private int recursively(int[] nums, int left, int right){ if(left == right || left + 1 == right)return 0; if(memory[left + 1][right + 1] &gt; 0)return memory[left + 1][right + 1]; int result = 0, leftBalloonValue = (left &lt;= -1?1:nums[left]), rightBalloontValue = (right &gt;= nums.length?1:nums[right]); int base = leftBalloonValue * rightBalloontValue; for(int k = left + 1;k &lt; right; ++k){ result = Math.max(result, recursively(nums, left, k) + recursively(nums, k, right) + base * nums[k]); } return memory[left + 1][right + 1] = result;} 时间复杂度：由于记忆化的存在，任意两个气球之间仅被枚举了一次,因此时间复杂度为O(${C_{n}^{2}}$)空间复杂度：递归栈最多为n层，以及记忆化结果的消耗为$n^2$，因此总的空间复杂度为O($n^2$) version-2 动态规划版本#事实上，写完version-0之后，状态转移方程就已经出现了。因此定义状态： $dp[i][j]$为戳破(i,j)之间的气球能够得到的最大硬币数 边界条件： $dp[i][j] = 0,(j-i)≤1$,其实只需要关注dp[i][i+1]必然等于0即可，因为按照上面的定义，中间没有气球，那么最大硬币数自然也为0 状态转移方程： $dp(i,j) = max\\lbrace dp(i,k)+dp(k,j)+nums[i]×nums[k]×nums[j]\\rbrace, k∈(i,j)$ 然而如何枚举从而确保在枚举到(i,j)的时候i,j之间的子状态已经计算完毕了呢？例如，这样枚举就会发生错误： )这是一个很容易被忽视的点，很多人都应该做过经典动态规划题目“最长回文子串”，它和这题的枚举似乎很类似，都是(i,j)区间之间依赖于更小的区间，因此这里也可以考虑采用“最长回文子串”枚举状态的方法，即定区间长度，首先求出所有长度为len的区间的解，再解决长度为len+1的区间的解，看起来会像这样： 12345678for(int len = 2;i &lt; maxLen; ++len){ for(int i = 0; i + len - 1 &lt; maxLen; ++i){ int j = i + len - 1; for(int k = i + 1;k &lt; j; ++k){ ...... } }} 但是对于此题，除了定长区间，还有两种状态枚举方式可行,这里结合我后面给出的代码给出一种正确的枚举方式，希望你能理解我的意思，那么另外一种也就不难写出了： 代码： 123456789101112131415161718192021222324252627282930313233343536373839class Solution { // version-3 version-2的等价版本 // 时间复杂度:O(n^3) // 空间复杂度:O(n^2) public int maxCoins(int[] nums){ int len, i, j, k; if(nums == null || (len = nums.length) == 0)return 0; int[][] dp = new int[len + 2][len + 2]; for(j = 1;j &lt;= len; ++j){ for(i = j - 2;i &gt;= -1; --i){ int left = i + 1, right = j + 1, max = 0, base = (i &lt;= -1?1:nums[i]) * (j &gt;= len?1:nums[j]); for(k = j - 1;k &gt;= i + 1; --k){ max = Math.max(max, dp[left][k + 1] + dp[k + 1][right] + base * nums[k]); } dp[left][right] = max; } } return dp[0][len + 1]; } // version-2 动态规划版 public int maxCoins0(int[] nums){ int len, i, j, k; if(nums == null || (len = nums.length) == 0)return 0; int[][] dp = new int[len + 2][len + 2]; for(i = len - 2;i &gt;= -1; --i){ for(j = i + 2;j &lt;= len; ++j){ int left = i + 1, right = j + 1, max = 0, base = (i &lt;= -1?1:nums[i]) * (j &gt;= len?1:nums[j]); for(k = i + 1;k &lt; j; ++k){ max = Math.max(max, dp[left][k + 1] + dp[k + 1][right] + base * nums[k]); } dp[left][right] = max; } } return dp[0][len + 1]; }} 时间复杂度：这种是典型的$\\sum_{i=1}^{n}\\sum_{j=i+1}^{n}\\sum_{k=i}^{j}$类型的循环嵌套，因此该算法时间复杂度为O($n^3$);空间复杂度：O($n^2$) Shortest Common Supersequence#题目描述：Shortest Common Supersequence这道题我确实做了很久！好几个小时就在画表推导关系，事实上，这题让我一直比较卡住的是如何构造最终结果。下面是我完整的思路： 看到题一瞬间，捕捉关键词，’Common,sequence’，于是可以大胆猜测这道题是不是最长公共子序列（Longest Common Subsequence,LCS)的变形，题目描述给的例子让我坚信了这一点，因为，无论如何，当我完整构造出最长公共子序列的dp表之后，我至少能解决：1、题目给出的两个字符串的最长公共子序列是什么，以及其长度maxCommonLen；2、最后该最短公共超序列的长度一定是$S1.length + S2.length - maxCommonLen$； 动态规划解决LCS不难，问题在于，我如何构造SCS呢（SCS是最短公共超序列的简写）？下面的想法都是我按照时间线逐个尝试过的： 首先找出两个字符串的公共字符串，尝试将第二个字符串在公共字符串的帮助下插入到第一个字符串中（！失败，太复杂，逻辑也不好理） 同样找出公共字符串，然后枚举该公共字符串，当str1与str2的字符不等于该字符串时，就将其放入到结果字符串中，相等后，加入该字符，并且str1指针与str2字符都后移（！失败，额。。。就是有些例子通不过） 由于画表推导了许多遍，’two years later!XD‘最后找到了直接复用dp表直接推出结果的方法！ 状态定义：这种双字符串的题，通常情况下，状态设计都较为套路。 dp[i][j]定义为str1的前i个字符与str2的前j个字符的最大公共子序列的长度 临界条件：实际上也就是lcs的临界条件 $dp[0][k] = dp[j][0] = 0, k∈[0, str2.length), j∈[0, str1.length)$ 状态转移方程：lcs的转移方程，许多人碰到字符串的题目时，常常想不通状态转移方程，其实，有的时候，先画个表，推一推，答案直接出来了，然后再反过来去想为什么反而更好理解！（XD，没错，就是这么暴力） $dp[i][j] = \\lbrace_{dp[i-1][j-1],str1[i-1] == str2[j-1]}^{max\\lbrace dp[i-1][j],dp[i][j-1]\\rbrace+1,str1[i-1] != str2[j-1]}$ 状态枚举：这题状态枚举没什么注意事项。 代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091class Solution { public String shortestCommonSupersequence(String str1, String str2) { if(str1 == null)return str2; int str1Len = str1.length(), str2Len = str2.length(), i, j; int[][] dp = new int[str1Len + 1][str2Len + 1]; // lcs打表 for(i = 1;i &lt;= str1Len; ++i){ for(j = 1;j &lt;= str2Len; ++j){ if(str1.charAt(i - 1) == str2.charAt(j - 1)){ dp[i][j] = dp[i - 1][j - 1] + 1; }else{ dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]); } } } // 通过上述动态规划，此时lcsLen = dp[str1Len][str2Len]即为两字符串的最大公共子序列 StringBuilder sb = new StringBuilder(); i = str1Len; j = str2Len; // 反向递推构造最短公共超序列，在后文有示意图 while(i &gt; 0 || j &gt; 0){ // i==0或j==0抵达边界时，没得选，一条道走到黑 if(i == 0){ sb.append(str2.charAt(--j)); }else if(j == 0){ sb.append(str1.charAt(--i)); }else{ // 此时未抵达边界 if(str1.charAt(i - 1) == str2.charAt(j - 1)){ // 如果相等，只能取一个字符 sb.append(str1.charAt(--i)); --j; }else if(dp[i - 1][j] &gt;= dp[i][j - 1]){ // 只有优先选择大的路径才对！回想lcs的递推式！ sb.append(str1.charAt(--i)); }else{ sb.append(str2.charAt(--j)); } } } return sb.reverse().toString(); } /* version-0 保留版本，未通过 public String shortestCommonSupersequence(String str1, String str2) { if(str1 == null)return str2; int str1Len = str1.length(), str2Len = str2.length(), i, j, lcsLen = 0; int[][] dp = new int[str1Len + 1][str2Len + 1]; ArrayList&lt;Character&gt; lcs = new ArrayList&lt;&gt;(); for(i = 1;i &lt;= str1Len; ++i){ for(j = 1;j &lt;= str2Len; ++j){ if(str1.charAt(i - 1) == str2.charAt(j - 1)){ dp[i][j] = dp[i - 1][j - 1] + 1; if(dp[i][j] &gt; lcsLen){ lcsLen = dp[i][j]; lcs.add(str1.charAt(i - 1)); } }else{ dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]); } } } // debug int resultLen = str1Len + str2Len - lcsLen; System.out.println(\"lcsLen=\"+lcsLen+\" and str1Len=\"+str1Len+\" and str2Len=\"+str2Len + \"and resultLen should be \"+resultLen); for(char c:lcs){ System.out.print(c + \" \"); } System.out.println(); // 通过上述动态规划，此时lcsLen = dp[str1Len][str2Len]即为两字符串的最大公共子序列 StringBuilder sb = new StringBuilder(); i = j = 0; for(char c:lcs){ while(i &lt; str1Len &amp;&amp; str1.charAt(i) != c)sb.append(str1.charAt(i++)); while(j &lt; str2Len &amp;&amp; str2.charAt(j) != c)sb.append(str2.charAt(j++)); sb.append(c); ++i; ++j; } // 剩余的str1与str2的字符 while(i &lt; str1Len)sb.append(str1.charAt(i++)); while(j &lt; str2Len)sb.append(str2.charAt(j++)); String result = sb.toString(); // debug System.out.println(\"final acctually resultLen is \"+result.length()); return sb.toString(); } */} 通过lcs打表构造scs的示意图（注意！由于疏忽，该表的行列被搞反了，该图完全转置后才能和上面的代码对应起来，或者更新代码也是行的）： 上面两个字符串按照示意图最终生成的scs逆序之后的结果为bbababbaaba 时间复杂度：O($str1Len * str2Len$)空间复杂度：O($str1Len * str2Len$) Additional Thinking:有没有可能输出所有可能的最短公共子序列？在上面的代码里，其实我们能够很容易发现，存在可分支的情况，就是当dp[i-1][j] == dp[i][j-1]的时候，从代码上来看，无论是选择向左走还是向上走似乎都不会错，既然有分支，那么就可能有多解！不妨再单独写一个递归函数来输出所有的结果！ 12345678910111213141516171819202122232425262728293031323334353637383940414243// 实际上就是暴力把上面的代码转述了一下，代码未优化private void lookUp(int[][] dp, String str1, String str2, StringBuilder sb, ArrayList&lt;String&gt; result, int i, int j){ if(i == 0 &amp;&amp; j == 0){ result.add(sb.reverse().toString()); return; } char c; if(i == 0){ c = str2.charAt(j - 1); sb.append(c); lookUp(dp, str1, str2, sb, result, i, j - 1); sb.deleteCharAt(sb.length() - 1); }else if(j == 0){ c = str1.charAt(i - 1); sb.append(c); lookUp(dp, str1, str2, sb, result, i - 1, j); sb.deleteCharAt(sb.length() - 1); }else if(str1.charAt(i - 1) == str2.charAt(j - 1)){ c = str1.charAt(i - 1); sb.append(c); lookUp(dp, str1, str2, sb, result, i - 1, j - 1); sb.deleteCharAt(sb.length() - 1); }else if(dp[i - 1][j] &gt; dp[i][j - 1]){ c = str1.charAt(i - 1); sb.append(c); lookUp(dp, str1, str2, sb, result, i - 1, j); sb.deleteCharAt(sb.length() - 1); }else if(dp[i - 1][j] &lt; dp[i][j - 1]){ c = str2.charAt(j - 1); sb.append(c); lookUp(dp, str1, str2, sb, result, i, j - 1); sb.deleteCharAt(sb.length() - 1); }else{ c = str1.charAt(i - 1); sb.append(c); lookUp(dp, str1, str2, sb, result, i - 1, j); sb.deleteCharAt(sb.length() - 1); c = str2.charAt(j - 1); sb.append(c); lookUp(dp, str1, str2, sb, result, i, j - 1); sb.deleteCharAt(sb.length() - 1); }} 可惜，最终结果不对： 12345678910111213141516171819202122str1:bbbaaaba str2:bbababbbIndex SCS Valid? Repeat?0---- bbababbaaba √ No1---- bbababababb × --2---- bbabaabbabb × --3---- bbbabaababb √ No4---- bbababaabbb × --5---- bbabaabbabb × --6---- bbbabaababb √ Yes-3-67---- bbabaaabbbb × --8---- bbbabaababb √ Yes-3-6-89---- bbbaabbabbb × --10--- bbababaabab √ No11--- bbabaabbabb × --12--- bbbabaababb √ Yes-3-6-8-1213--- bbabaaabbbb × --14--- bbbabaababb √ Yes-3-6-8-12-1415--- bbbaabbabbb × --16--- bbabaaababb √ No17--- bbbabaababb √ Yes-3-6-8-12-14-1718--- bbbaabbabbb × --19--- bbbaaababbb √ No 从上面的结果来看，不仅有错误的答案，还有很多重复，其实有重复很容易理解，但是有错误似乎不太好理解，上面动态规划的代码似乎与递归代码一致呀，其实不是，容易忽略的一点是，递推的代码，在判断到dp[i - 1][j]与dp[i][j - 1]的关系的时候，自始至终都是遵循了一致的选择方向，当判断到dp[i - 1][j] == dp[i][j - 1]时，都是自始至终选择dp[i - 1][j]，或者换另外一种写法之后，自始至终选择dp[i][j - 1]那么代码提交结果就不会有错，可是递归并不是遵循了这种策略。从上面的结果来看，最终有效的SCS有6个。（对于如何高效求解所有可能的解，到这里我也迷茫了…） Wildcard Matching#题目描述：Wildcard Matching该题与Regular Expression Matching基本一模一样，都是困难难度，所以建议你先把这题做一遍，或者看我三、别问，问就是使劲刷题中对该题的解析之后再来看这道题，你就会发现掌握套路之后，这题其实就是送分题。另外，可以告诉你的是，在leetcode上，这种字符串类型的题目，按照上面Shortest Common Supersequence的那个动态图将表画出来，基本都能解出来，甚至有时你都不需要明白状态转移方程为什么是这样的，比如这题就是这样的，当然，如果你有经验，不用画表也能做出来这道题，在这里，因为这题简单，就不附上表格了。 状态定义： $dp[i][j]$定义为字符串s的前i个字符是否能够与模式串p的前j个字符匹配 边界状态： $dp[0][0] = true$ $dp[k][0] = false, k ∈ [1, s.length]$ $dp[0][k] = dp[0][k - 1] &amp;&amp; p[k - 1] == ‘*‘$【例如：****“就能匹配空字符串】 状态转移方程： 当s[i-1] == p[j-1]或者p[j-1] == ‘?’时：dp[i][j] = dp[i - 1][j - 1] 当s[i-1] != p[j-1]并且p[j-1] == ‘*‘时：dp[i][j] = dp[i - 1][j] || dp[i][j - 1],分别对应于’*‘匹配多个字符或者’*‘不匹配字符时的情况【注：因为题目说明了’*‘可匹配多个字符或者不匹配】 综上有：$dp[i][j] = \\lbrace_{dp[i-1][j-1],s[i-1] == p[j-1] || p[j-1] == ?}^{dp[i-1][j] || dp[i][j-1], p[j-1] == *}$ 状态枚举：无注意事项。 代码： 12345678910111213141516171819202122232425class Solution { public boolean isMatch(String s, String p) { int sLen = (s == null?0:s.length()), pLen = (p == null?0:p.length()); boolean[][] dp = new boolean[sLen + 1][pLen + 1]; // init-state int i,j; dp[0][0] = true; for(i = 1; i &lt;= pLen; ++i){ dp[0][i] = dp[0][i - 1] &amp;&amp; p.charAt(i - 1) == '*'; } // transition function for(i = 1;i &lt;= sLen; ++i){ for(j = 1; j &lt;= pLen; ++j){ if(s.charAt(i - 1) == p.charAt(j - 1) || p.charAt(j - 1) == '?'){ dp[i][j] = dp[i - 1][j - 1]; }else if(p.charAt(j - 1) == '*'){ dp[i][j] = dp[i - 1][j] || dp[i][j - 1]; // *匹配多个或者不匹配 } } } return dp[sLen][pLen]; }} 时间复杂度：O($sLen * pLen$)空间复杂度：O($sLen * pLen$) 三、别问，问就是使劲刷题#上面我通过实例完整的描述一遍如何解决动态规划的问题，其实这几题只是我做的题中的一点点，从我在leetcode上做过的题目中，我挑出了4个很经典的题： #10 Regular Expression Matching #72 Edit Distance #87 Scramble String #174 Dungeon Game 以表格的形式说明其状态定义、边界条件、状态转移方程： 除此之外，还有很多好题，鉴于篇幅所限，就不放了，其次就是，建议Leetcode刷了之后，刷一刷Pat，Zoj（现在好像迁移到PTA上了），或者《算法竞赛入门经典》这本书，一定会有更深的理解！ 四、没什么用的技巧总结#如果你认真地独立思考把这些题都做了一遍，那么你一定会发现这些题很多都有独特的特点，而这些特点就代表了一类题型，无论是从状态定义、状态转移还是枚举方式，纯粹以刷leetcode的视角，都有着相对较为死板的套路，如下表所示（注：建议阅读我在本博客顶部“写这篇博客的背景”中提到的Most consistent ways of dealing with the series of stock problems） leetcode上大部分题都较为基础，因此其状态设计都很套路，除此之外，还很重要的是如何枚举状态，保证在当前状态下子状态都已经枚举完毕，见下总结： dp[i]的普通枚举,dp[i][j]的普通枚举（通常这类问题都是多阶段决策问题，因此按照定义枚举不会出错，甚至于有时可转换为滚动数组，将二维数组优化为一维数组），这类题目按照定义枚举不会出错，通常看起来会像这样： 12345678910111213141516171819202122232425// dp[i]普通for(int i = 1; i &lt; threshold; ++i){ ......}// dp[i]稍复杂for(int i = 1; i &lt; threshold; ++i){ for(int j = i; j &gt;= 0; --j){ ...... }}// dp[i][j] ↘方向for(int i = 0; i &lt; iThreshold; ++i){ for(int j = 0; j &lt; jThreshold; ++j){ ...... }}// dp[i][j] ↖方向for(int i = iThreshold - 1; i &gt;= 0; --i){ for(int j = jThreshold - 1;j &gt;= 0; --j){ ...... }} 定长区间类似问题的枚举技巧，这类问题通常与区间有关，往往要将任意len长度的区间的结果都要枚举出来，例如经典的“最长回文子串”问题，以及上面解析的“戳气球问题”，“Scramble String(扰乱字符串)”都能用到这种技巧！： 12345678910111213141516171819202122/*** 技巧1：外嵌循环定长区间*/for(int len = 1; len &lt; maxLen; ++len){ for(int i = 0; i + len - 1 &lt; iThreshold; ++i){ int j = i + len - 1; for(int k = i + 1; k &lt; j; ++k){ ...... } }}/*** 技巧2：使用上文\"戳气球\"用到的那种枚举方式,同样能做到技巧1的效果，详情可参* 见上文动态图*/for(int j = 1; j &lt; jThreshold; ++j){ for(int i = j - 1; i &gt;= 0; --i){ for(int k = i; k &lt; j; ++k){ ...... } }} 五、竞赛入门-动态规划入门模型#非竞赛党，一年多以前出于提升代码能力的目的，之前也刷过《算法竞赛入门经典》这本书，虽然只看了基础篇还有竞赛篇的三章，不过既然都写动态规划的博客了，就简单回顾下动态规划初步这章的几个基本模型概念吧。 记忆化搜索与递推。典型的就是斐波那契数列，还有数字三角形，事实上就是递归的过程中有许多需要重复计算的地方，因此通过记忆化，使其不再被重复计算，就像上文”Brust Balloon”一样，由于暴力递归产生大量重复解，通过记忆化能将其时间复杂度大幅度优化。 DAG模型。许多问题都能抽象成DAG上的最长路、最短路、路径计数问题。（至今清晰记得这种解法，因为确实好用！）例如经典的0-1背包问题也能看作一种DAG模型。 多阶段决策问题。无论是在回溯法当中还是递归当中，有时在某一层结点会涉及到不同的决策，从而在该结点上产生不同的解答树，这就是多阶段决策问题，不同阶段，不同决策，决策做完，完整的解浮出水面。例如Leetcode的那6道买卖股票的问题，“戳气球”等都算是一种多阶段决策问题（其实，感觉自己后面对这个的概念都比较模糊) 线性结构上的动态规划。这个就不引用书里的话了，其实leetcode有大量这样的题，典型的那些“最长公共子序列”、“最长回文子串”、“最长连续子序列”等等都是线性结构上的动态规划。 树上的动态规划和复杂状态的动态规划基本忘了，leetcode上这类题目也比较少….额，就不复习了吧，博客写累了。 参考资料#【1】 《算法竞赛入门经典-第二版》，刘汝佳著【2】 LeetCode讨论区文章：Most consistent ways of dealing with the series of stock problems","link":"/2019/12/17/关于动态规划的一点简单思考/"},{"title":"MIT-6.828-LAB1 Booting a PC","text":"文章目录# Part 1:PC Bootstrap Exercise 2 Key point My answer for exercise 2 Part 2:The Boot Loader Exercise 3 Key point My answer for exercise 3 Exercise 4,5,6 Key point My answer for exercise 4 My answer for exercise 5 My answer for exercise 6 Part 3：The Kernel Exercise 7 Key point My answer for exercise 7 Exercise 8 My answer for exercise 8 GDB debugging process for exercise 8.3 Exercise 9 My answer for exercise 9 Exercise 10 Key point My answer for exercise 10 Exercise 11,12 My answer for exercise 11,12 参考资料 Part 1:PC Bootstrap# Exercise 2#Key point# When the BIOS runs, it sets up an interrupt descriptor table and initializes various devices such as the VGA display. This is where the “Starting SeaBIOS” message you see in the QEMU window comes from.After initializing the PCI bus and all the important devices the BIOS knows about, it searches for a bootable device such as a floppy, hard drive, or CD-ROM. Eventually, when it finds a bootable disk, the BIOS reads the boot loader from the disk and transfers control to it. 什么是实模式real mode?什么是保护模式protected mode？它们的区别是什么？根据MIT官方文档的指示，参阅其给出的pc-asm-book.pdf的1.2.6等： In real mode,a selector value is a paragragh number of physical memory.In protected mode,a selector value is an index into a descriptor table.In both modes, programs are divided into segments. In real mode, these segments are at fixed positions in physical memory and the selector value denotes the paragraph number of the beginning of the segment. In protected mode, the segments are not at fixed positions in physical memory. In fact, they do not have to be in memory at all!Protected mode uses a technique called virtual memory. My answer for exercise 2#注：下面会涉及到许多IO端口号，我查询了Wiki百科，找到I/O_PORTS，该页面简单介绍了各地址范围的I/O端口的作用，在其底部的外部链接中Boch’s map of I/O ports to functions中则是各I/O端口的详细说明，当然也可以参考Mit给的参考文档Phil Storrs I/O Ports Description,但是不太详细 12345cli # 屏蔽了所有中断cld # 操作方向标志位DF,使DF复位为0mov $0x8f,%eax # 0x8f &lt;=&gt; 1000 1111out %al,$0x70 # 将%al中的一个字节写入0x70端口in $0x71,%al # 从IO端口0x71读取一个字节 该IO端口0x70是一个CMOS RAM/RTC(Real Time Clock),通过查询上面所说的页面可以发现，0x8f表明其禁止了NMI中断，并且选择了CMOS register number为0xf 123in 0x92,%al # 从0x92端口读取一个字节or $0x2,%al # 将上面读出的字节的第二位设置为1,激活A20地址线out %al,$0x92 # 将该字节重新写入0x92端口 查阅得知，0x92是PS/2 system control port A，并且激活A20地址线，关于A20，建议阅读Quora:What is the A20 gate in a CPU，通过该回答大致了解到A20是为了向后兼容8086等时仅有20条地址线的情况，并且在操作系统需要进入到protected mode时，A20 Gate应当被使能,但是值得注意的是此时仍然工作在实模式下。 12lidtw %cs:0x6ab8 # 加载IDT的24位基地址和16位限长值到IDTR寄存器lgdtw %cs:0x6a74 # 加载GDT的24位基地址和16位限长值到GDTR寄存器 因为是lidtw，随后这两行仍然是16bit操作数，参考x86-lidt and lgdt可知，若为16位操作数，那么lidt(lgdt)会将16位限长值与24位基地址加载到寄存器IDTR(GDTR),建议阅读百度百科：中断描述符表IDT以及Wiki:GDT,因此简单来说，这两行就是加载IDT和GDT。 123mov %cr0,%eaxor $0x1,%eax # 将%cr0寄存器中的值的最低位设置为1mov %eax,%cr0 # 处理器进入Protected mode 上面三行很显然是将%cr0寄存器中的值的最低位设置为1，参阅Wiki:Control register发现，这个操作就是使处理器进入Protected mode。 123456789ljmpl $0x8,$0xfd18f # 这里这样跳转是x86加载GDT之后的硬性规定mov $0x10,%eaxmov %eax,%ds # 设置段寄存器mov %eax,%es # ~mov %eax,%ss # ~mov %eax,%fs # ~mov %eax,%gs # ~mov %ecx,%eaxjmp *%edx # 间接跳转 同样参阅Wiki:GDT，能了解到，加载了GDT之后，必须通过长跳转（far jump)来重新加载段寄存器，也就是DS,ES,SS,FS,GS。 从jmp *%edx开始，后面的汇编代码就是很类似于C语言编译后的汇编代码，并且后续汇编代码极其之长，但是通过si单步调试，发现基本都是很类似的结构，例如我把后续汇编代码截取了一部分，会发现二者很相似。 123456789101112131415161718192021222324252627282930313233=&gt; 0xf34c2: push %ebx=&gt; 0xf34c3: sub $0x2c,%esp=&gt; 0xf34c6: movl $0xf5b5c,0x4(%esp)=&gt; 0xf34ce: movl $0xf447b,(%esp)=&gt; 0xf34d5: call 0xf099e=&gt; 0xf099e: lea 0x8(%esp),%ecx=&gt; 0xf09a2: mov 0x4(%esp),%edx=&gt; 0xf09a6: mov $0xf5b58,%eax=&gt; 0xf09ab: call 0xf0574=&gt; 0xf0574: push %ebp =&gt; 0xf0575: push %edi=&gt; 0xf0576: push %esi=&gt; 0xf0577: push %ebx =&gt; 0xf0578: sub $0xc,%esp=&gt; 0xf057b: mov %eax,0x4(%esp)=&gt; 0xf057f: mov %edx,%ebp=&gt; 0xf0581: mov %ecx,%esi =&gt; 0xf0583: movsbl 0x0(%ebp),%edx # 这里开始到ret都是重复代码=&gt; 0xf0587: test %dl,%dl =&gt; 0xf0589: je 0xf0758=&gt; 0xf058f: cmp $0x25,%dl=&gt; 0xf0592: jne 0xf0741=&gt; 0xf0741: mov 0x4(%esp),%eax=&gt; 0xf0745: call 0xefc70=&gt; 0xefc70: mov %eax,%ecx=&gt; 0xefc72: movsbl %dl,%edx =&gt; 0xefc75: call *(%ecx) =&gt; 0xefc65: mov %edx,%eax=&gt; 0xefc67: mov 0xf693c,%dx=&gt; 0xefc6e: out %al,(%dx) # 向0x402端口写入一字节(0x53)=&gt; 0xefc6f: ret =&gt; 0xefc77: ret 上面这段汇编代码在ret尚未执行时的完整栈结构如下所示： 至于为什么我会画出栈？因为我想尝试读懂，结果发现是我想多了。为什么栈是从0x7000地址处开始？因为在整个汇编代码的起始处，%esp寄存器就被赋值为0x7000。 1234567891011121314151617181920=&gt; 0xf074a: mov %ebp,%ebx=&gt; 0xf074c: jmp 0xf0750=&gt; 0xf0750: lea 0x1(%ebx),%ebp =&gt; 0xf0753: jmp 0xf0583=&gt; 0xf0583: movsbl 0x0(%ebp),%edx # 这里开始是重复代码=&gt; 0xf0587: test %dl,%dl =&gt; 0xf0589: je 0xf0758=&gt; 0xf058f: cmp $0x25,%dl=&gt; 0xf0592: jne 0xf0741=&gt; 0xf0741: mov 0x4(%esp),%eax=&gt; 0xf0745: call 0xefc70 =&gt; 0xefc70: mov %eax,%ecx) =&gt; 0xefc72: movsbl %dl,%edx =&gt; 0xefc75: call *(%ecx)=&gt; 0xefc65: mov %edx,%eax =&gt; 0xefc67: mov 0xf693c,%dx=&gt; 0xefc6e: out %al,(%dx) # 向向0x402端口写入一字节(0x65)=&gt; 0xefc6f: ret =&gt; 0xefc77: ret 可以看到随后一段汇编代码，出现了大量的重复，并且最后也是向0x402端口（注：这里out %al,(%dx)的语法我并不是很了解，但是通过输出寄存器的值，此时%dx当中的确都是0x402。后面有大量的代码都会重复这一段，但是我能力有限，无法知道这一段的具体含义，但是根据MIT在这部分的描述： When the BIOS runs, it sets up an interrupt descriptor table and initializes various devices such as the VGA display. 我只能够猜测这一段就是初始化各种BIOS已知的设备。 Part 2:The Boot Loader# Exercise 3#Key point# When the BIOS finds a bootable floppy or hard disk, it loads the 512-byte boot sector into memory at physical addresses 0x7c00 through 0x7dff, and then uses a jmp instruction to set the CS:IP to 0000:7c00, passing control to the boot loader.(注：0x7c00-0x7dff为512字节，也就是说BIOS将Boot sector加载到0x7c00为起始地址的连续512个字节，并且随后跳转到0x7c00去执行Boot Sector中的代码) Like the BIOS load address, these addresses are fairly arbitrary - but they are fixed and standardized for PCs.The boot loader consists of one assembly language source file, boot/boot.S, and one C source file, boot/main.cThe boot loader must perform two main functions: the boot loader switches the processor from real mode to 32-bit protected mode, because it is only in this mode that software can access all the memory above 1MB in the processor’s physical address space. the boot loader reads the kernel from the hard disk by directly accessing the IDE disk device registers via the x86’s special I/O instructions. My answer for exercise 3#在这部分当中给出了四个问题需要回答： At what point does the processor start executing 32-bit code? What exactly causes the switch from 16- to 32-bit mode? What is the last instruction of the boot loader executed, and what is the first instruction of the kernel it just loaded? Where is the first instruction of the kernel? How does the boot loader decide how many sectors it must read in order to fetch the entire kernel from disk? Where does it find this information? 通过对Part A的汇编代码的仔细研读，再理解boot/boot.S这个文件也就不难了，并且代码中还给了注释，只有一个注意的点： 12345678910111213141516171819 # Enable A20: # For backwards compatibility with the earliest PCs, physical # address line 20 is tied low, so that addresses higher than # 1MB wrap around to zero by default. This code undoes this.seta20.1: inb $0x64,%al # Wait for not busy testb $0x2,%al jnz seta20.1 movb $0xd1,%al # 0xd1 -&gt; port 0x64 outb %al,$0x64seta20.2: inb $0x64,%al # Wait for not busy testb $0x2,%al jnz seta20.2 movb $0xdf,%al # 0xdf -&gt; port 0x60 outb %al,$0x60 这一段，直接看注释就能知道它的作用是使能A20 Gate，为切换到保护模式做准备，查询端口表，0x64号端口的bit 1位置的含义是： 0064: KB controller read status (ISA, EISA)bit 1 = 1 input buffer full (input 60/64 has data for 8042) 再查向0x64端口写入0xd1和0xdf有什么作用： D1 dbl: write output port. next byte written to 0060will be written to the 804x output port; the original IBM AT and many compatibles use bit 1 of the output port to control the A20 gate.DF sngl enable address line A20 (HP Vectra only???) 由此，上面这段代码就是检测input buffer直到其空闲，然后使能A20 Gate。 通过该文件，能够回答第一个问题： 123456789101112# Switch from real to protected mode, using a bootstrap GDT# and segment translation that makes virtual addresses# identical to their physical addresses, so that the# effective memory map does not change during the switch.lgdt gdtdescmovl %cr0, %eaxorl $CR0_PE_ON, %eaxmovl %eax, %cr0# Jump to next instruction, but in 32-bit code segment.# Switches processor into 32-bit mode.ljmp $PROT_MODE_CSEG, $protcseg 从ljmp $PROT_MDOE_CSEG, $protcseg开始，由于设置了%cr0控制寄存器，使得处理器从实模式切换为保护模式，开始执行32-bit code。 随后，进入bootmain()，我们来深究一下bootmain这个函数： 1readseg((uint32_t) ELFHDR, SECTSIZE*8, 0); 首先，从第一个扇区(sector)读取ELF中的Program Header，（此处建议参考由Mit推荐的参考页面Wiki:Executable and Linkable Format），读取SECTSIZE * 8个字节的数据，并且将其加载到物理内存地址0x10000，为什么是0x10000，在注释的解释是scratch space，直译的话不知道是什么鬼，google translate给的翻译是“暂存空间”，这样就合理多了。 1234567// is this a valid ELF?if (ELFHDR-&gt;e_magic != ELF_MAGIC) goto bad;// load each program segment (ignores ph flags)ph = (struct Proghdr *) ((uint8_t *) ELFHDR + ELFHDR-&gt;e_phoff);eph = ph + ELFHDR-&gt;e_phnum; 随后校验所读取的ELF是否有效，有效则计算Program Header的起始地址，以及结束地址，以便后续遍历Program Header并且将每一段（segment)加载到内存当中，因此下面这段代码就是这样的功能,将ph-&gt;p_offset出开始的ph-&gt;p_memsz个字节读取到以ph-&gt;p_pa为起始地址的物理内存地址上： 1234for (; ph &lt; eph; ph++) // p_pa is the load address of this segment (as well // as the physical address) readseg(ph-&gt;p_pa, ph-&gt;p_memsz, ph-&gt;p_offset); 然后我们进入readseg，来看看它是如何做到将扇区的内容加载到内存中的： 1234uint32_t end_pa;end_pa = pa + count;// round down to sector boundarypa &amp;= ~(SECTSIZE - 1); 首先，计算物理内存地址的结束地址（这里实际上是结束地址的下一个地址）,并且将物理内存地址的起始地址向下舍入到sector boundary(若SECTSIZE是512，其实也就等价于pa &amp; 0xffffffe0,那它为什么要这么写，因为这么写有强大的兼容性啊，无论是对32位机器还是64位机器都是适用的。 1offset = (offset / SECTSIZE) + 1; 然后将需要读取的字节数，转换为扇区编号。 123456789while (pa &lt; end_pa) { // Since we haven't enabled paging yet and we're using // an identity segment mapping (see boot.S), we can // use physical addresses directly. This won't be the // case once JOS enables the MMU. readsect((uint8_t*) pa, offset); pa += SECTSIZE; offset++;} 遍历加载每个扇区的内容，注意这里的注释，在此时，页表机制还没加载，因此，这里不是使用虚拟内存，而是直接的物理内存地址。其次，这里出现了readsect函数，该函数是Exercise 3要求必须完全弄懂的函数，下面就进入readsect来看看它到底做了什么： 123456789101112131415161718192021222324252627voidwaitdisk(void){ // wait for disk reaady while ((inb(0x1F7) &amp; 0xC0) != 0x40) /* do nothing */;}void readsect(void *dst, uint32_t offset){ // wait for disk to be ready waitdisk(); outb(0x1F2, 1); // count = 1 outb(0x1F3, offset); outb(0x1F4, offset &gt;&gt; 8); outb(0x1F5, offset &gt;&gt; 16); outb(0x1F6, (offset &gt;&gt; 24) | 0xE0); outb(0x1F7, 0x20); // cmd 0x20 - read sectors // wait for disk to be ready waitdisk(); // read a sector insl(0x1F0, dst, SECTSIZE/4);} readsect和waitdisk直接与硬件交互，向设备端口写入数据，同样查询之前的端口表，这里用到的端口梳理如下： 因此，waitdisk中期待从0x1F7端口读出的一字节与0xC0相与的结果为0x40，也就是drive is ready，等待硬盘准备完毕。后续outb(0x1F2, 1);选择需要读取的扇区数量为1，outb(0x1F3, offset);选择扇区编号，向0x1F4,0x1F5,0x1F6写入的数据应该是操作disk选择相应的柱面、磁道等，然后outb(0x1F7, 0x20);读取扇区数据，随后等待磁盘准备完毕，再从磁盘数据读取到指定的物理内存地址dst。 12345678910111213static inline voidinsl(int port, void *addr, int cnt){ asm volatile(\"cld\\n\\trepne\\n\\tinsl\" 7cc9: 8b 7d 08 mov 0x8(%ebp),%edi 7ccc: b9 80 00 00 00 mov $0x80,%ecx 7cd1: ba f0 01 00 00 mov $0x1f0,%edx 7cd6: fc cld 7cd7: f2 6d repnz insl (%dx),%es:(%edi) // read a sector insl(0x1F0, dst, SECTSIZE/4);} insl直接采用了在c中嵌入汇编代码的形式，前三条mov指令准备函数参数，最核心的就是repnz insl (%dx),%es:(%edi)，通过查阅Mit给的i386.pdf： REPNE/REPNZ ── Repeat while not equal or not zeroThe primitive string operations operate on one element of a string. A string element may be a byte, a word, or a doubleword. The string elements are addressed by the registers ESI and EDI. After every primitive operation ESI and/or EDI are automatically updated to point to the next element of the string. If the direction flag is zero, the index registers are incremented; if one, they are decremented. The amount of the increment or decrement is 1, 2, or 4 depending on the size of the string element. 简而言之，被该指令修饰的指令能够自动重复执行，直到相应的结束条件被满足，这样你也能理解为什么先要执行cld使direction flag复位为0，为的是使index register增长而不是减小，这样就能够将数据按照物理内存地址从到大存放了，虽然能猜出来它做了什么，但是这里对insl的具体语意仍然存疑，只能用GDB调试了。 由于直接看C代码能看懂绝大部分了，因此，这里不按照官方文档提示的将断点打在0x7c00，vi boot.asm打开obj/boot.asm文件，:?insl找到insl函数，可以看到for循环是从0x7d51开始的，readseg定义在0x7cdc，readsect定义在0x7c7c，而insl的第一条指令定义在0x7cc9处，由于我的目的是了解insl函数的具体过程，因此将断点打在0x7cc9处，然后单步运行至第一条repnz insl (%dx),%es:(%edi)前，输出寄存器内容: 然后执行第一次repnz insl (%dx),%es:(%edi),再次输出寄存器内容： 很明显了，insl指令将4个字节的数据从扇区读出来到0x1f0端口，然后将其存放到以%edi为起始物理内存地址的地方，然后将%edi寄存器中的数据加4，%ecx寄存器中的数据减1，并且会检测%ecx寄存器中是否为0，若为0，则达到了repnz终止的条件，换而言之，若的确是这样，那么该指令就会执行128次，因为初始时%ecx寄存器值为128（恰巧，insl函数的第三个参数就是128，都对上了！），为了验证的确将数据复制了，输出以0x10000为起始地址的10个双字的数据，再执行9条指令，再次输出寄存器内容以及内存信息： 此时repnz insl (%dx),%es:(%edi)已经执行了10次，应当再执行118次就会终止，si 117验证： 从上面的结果完全证明了我的猜测是正确的。后续就是执行相同的循环来读取扇区内容到内存，就不再赘述。 为了找出Boot Loader执行的最后一条指令以及Kernel执行的第一条指令，将断点打在readseg处，随后经过调试，可以发现，执行了4次之后，再单步调试，然后可以找到bootmain最后执行的代码((void (*)(void)) (ELFHDR-&gt;e_entry))();对应的汇编代码： 然后能找到bootmain最后执行的代码对应的汇编代码的入口 然后继续向下调试，发现最终进入了kern/entry.S。 那么从call *0x10018一直到jmp *%eax之间的指令做了什么呢？ 1movw $1234,0x472 不是很确定这条指令做什么的，不过在entry.S中有注释是warm kernel? 12mov $0x110000,%eaxmov %eax,%cr3 不妨再回去看一看Wiki:Control register，或者如果你看过mit给的xv6-book.pdf,那么你就明白，0x110000即为entrypgdir的物理地址，它与虚拟内存的实现息息相关。 123mov %cr0,%eaxor $0x80010001,%eaxmov %eax,%cr0 同样参考Wiki页面，明白了吗，这段代码设置了%cr0控制寄存器的PE,WP,PG位，即开启Protected Mode,Write Protect以及Paging,也就是开启了Paging功能，能够将物理地址映射为虚拟地址 Exercise 3到这里基本告一段落，下面是我对四个问题的解答（若有误烦请指正）： 从ljmp $PROT_MDOE_CSEG, $protcseg开始，由于设置了%cr0控制寄存器，使得处理器从实模式切换为保护模式，开始执行32-bit code。 Boot loader执行的最后一条指令应该是call *0x10018,加载内核之后的第一条指令应该是movl $0x1234,0x472 内核的第一条指令位于kern/entry.S Boot loader通过ELF的Program Header中存储的各种信息，例如p_paddr,p_memsz,p_offset等可以确定需要加载多少sector。 Exercise 4,5,6#key point# An ELF binary starts with a fixed-length ELF header, followed by a variable-length program header listing each of the program sections to be loaded. The C definitions for these ELF headers are in inc/elf.h. The program sections we’re interested in are: .text: The program’s executable instructions. .rodata: Read-only data, such as ASCII string constants produced by the C compiler. (We will not bother setting up the hardware to prohibit writing, however.) .data: The data section holds the program’s initialized data, such as global variables declared with initializers like int x = 5; My answer for exercise 4#关于C指针的练习我就不写了。但是按照文档要求，反汇编了一下 obj/kern/kernel,obj/boot/boot.out,obj/kern/kernel三个文件: 将kernel的代码加载到物理内存地址0x100000对应于虚拟地址0xf0100000。 与kernel不同，boot程序运行时还没有虚拟内存，页面等机制，因此，虚拟地址就是物理内存地址。 这个就是Kernel的Program Header,LOAD标识的segment会被加载到内存当中。 My answer for exercise 5#将Makefrag中的boot loader的link address修改为0x7c2d,然后make clean清除之前的编译信息，make重新编译后，再用GDB调试，发现这次，程序会一直卡在ljmp指令上无法运行了： My answer for exercise 6#问题是： Reset the machine (exit QEMU/GDB and start them again). Examine the 8 words of memory at 0x00100000 at the point the BIOS enters the boot loader, and then again at the point the boot loader enters the kernel. Why are they different? What is there at the second breakpoint? 其实很好解释，参考exercise 4反汇编的kernel的.text节，当boot loader进入kernel的时候，此时0x100000起始的物理内存空间已经被加载了内核代码，而当BIOS进入boot loader时，BIOS只是将boot loader的代码加载到了0x7c00起始的物理内存空间，并且此时还运行在real mode之下，那么这时候输出0x100000内存地址的内容，当然是0，不妨验证一下： Part 3：The Kernel# Exercise 7#Key point# Many machines don’t have any physical memory at address 0xf0100000, so we can’t count on being able to store the kernel there. Instead, we will use the processor’s memory management hardware to map virtual address 0xf0100000 (the link address at which the kernel code expects to run) to physical address 0x00100000 (where the boot loader loaded the kernel into physical memory). This way, although the kernel’s virtual address is high enough to leave plenty of address space for user processes, it will be loaded in physical memory at the 1MB point in the PC’s RAM, just above the BIOS ROM.In fact, in the next lab, we will map the entire bottom 256MB of the PC’s physical address space, from physical addresses 0x00000000 through 0x0fffffff, to virtual addresses 0xf0000000 through 0xffffffff respectively. You should now see why JOS can only use the first 256MB of physical memory.For now, we’ll just map the first 4MB of physical memory. My answer for exercise 7#事实上，在exercise3当中，通过对%cr0控制寄存器各bit作用的说明，就已经知道movl %eax, %cr0这条指令最终设置了PE,WP,PG位，最重要的是启用了Paging功能，能够将虚拟地址映射到物理地址，按照exercise 7的要求，进行gdb调试。 可以发现，在这一行开启了Paging功能之后，0xf0100000虚拟内存地址被映射到了物理地址0x100000，倘若我们注释掉movl %eax, %cr0，很显然，此时没有开启Paging，没有映射关系，那么此时一定无法执行后续指令，不妨验证一下： 可以看到注释了那一行之后，直接导致qemu出错终止了！ Exercise 8#My answer for exercise 8#修改为（然后make qemu可以验证输出结果）: 123num = getuint(&amp;ap, lflag);base = 8;goto number; Explain the interface between printf.c and console.c. Specifically, what function does console.c export? How is this function used by printf.c? printf.c调用了console.c中定义的cputchar(int c)，用它输出字符c到屏幕上。 Explain the following from console.c: crt_pos指向字符当前位置（相对于屏幕而言的），CRT_COLS为一行能容纳字符的大小，CRT_SIZE是整个屏幕能容纳的字符。当屏幕上的字符已经满了的时候（比如整个屏幕都是文字的时候，你再打字，是不是最上面一行就会消失并且下面空出了一行，这里就是做这种操作），因此memmove(crt_buf, crt_buf + CRT_COLS, (CRT_SIZE - CRT_COLS) * sizeof(uint16_t))给我的感觉很像“滑动窗口”的感觉，简而言之就是屏幕将crt_buf+CRT_COLS起始处的(CRT_SIZE-CRT_COLS)个字符显示出来，后续for循环不断执行crt_buf[i] = 0x0700 | ' ';将最后新出现的一行填充上空格(这里0x0700是用来控制字符的样式的，这里0x0700是黑底白字，但因为是空格，不会有效果），这时候crt_pos应该在屏幕的最后位置，于是crt_pos -= CRT_COLS;将其移动到最后一行的开头处。 For the following questions you might wish to consult the notes for Lecture 2. These notes cover GCC’s calling convention on the x86.Trace the execution of the following code step-by-step: 3.1:In the call to cprintf(), to what does fmt point? To what does ap point? fmt指向格式字符串”x %d, y %x, z %d\\n”（这部分存储在ELF Header的.rodata当中，因此在实际进程中，其内存地址不在栈中，而是在text and data那一部分),ap指向x，也即存储的是x的地址。 3.2:List (in order of execution) each call to cons_putc, va_arg, and vcprintf. For cons_putc, list its argument as well. For va_arg, list what ap points to before and after the call. For vcprintf list the values of its two arguments. 直接将代码添加在kern/init.c当中，为了方便查看obj/kern/kernel.asm时找到我们添加的代码，在代码中使用”exercise8_for_lab1:”标记好，然后在cons_putc,vcprintf以及va_arg的函数入口地址处打上断点（注：由于编译器的优化，会将getint和getuint优化成inline function，因此必须取消这种优化才便于调试，将static删除），调试过程见下方GDB调试过程。以下为完整答案： （题目略）代码输出结果是”He110 Worldentering test_backtrace 5”,因为57616的16进制表示为0xe110,而由于x86是小端机器，因此unsigned int i=0x00646c72中的i在内存中（内存地址从小到大）为”72 6c 64 00”,查询ASCII表可知结果对应为”rld\\0”。相反如果是大端机器，则需要内存中布局不变，那么就需把代码改成unsigned int i=0x726c6400,而57616不需要改变。 （题目略）按照8.3的方法添加代码，执行make qemu，我的结果是”x=3 y=1600”。按照调试8.3的经验，1600(0x640)应该是紧接着3所在的内存地址处的值,验证见下图,可以看到0x3处紧邻的0x640即为y的输出值: （题目略）x86完全使用栈来传递函数参数，并且从上面的调试过程我们能发现，x86的函数入栈是从右向左入栈的，而6则让我们想一想若将参数传递改成从左向右（即按照参数的声明顺序），需要改动什么才能实现可变数量的参数。关键问题在于若参数数量不确定，那么被调用函数就没办法在栈中顺利找到传递给它的固定参数值（因为偏移量是不确定的），或许可以在参数都入栈之后，再由编译器在其后存储上实际调用过程中添加的可变参数的数量的值，这样就能够确定偏移量了，额…感觉我的办法有点笨，不过也没有办法验证。 Challenge Enhance the console to allow text to be printed in different colors.事实上，在前面我们发现console.c中就有设置字符样式的代码，通过改变字符的高16位，来提示CGA字符的样式，默认是c |= 0x0700;，尝试将其改为c |= 0x0600，结果如下，成功改变颜色！ GDB debugging process for exercise 8.3#在kernel.asm中找到添加的代码，其地址为0xf01000d3。 验证0xf0101872处是格式字符串。 然后查看传递给vcprintf的参数，可以看到为0xf0101872以及0xf010ffd4,8.3.1解决！ 将断点打在0xf0100300即可找到第一个cons_putc函数的入口处。 发现传递给cons_putc的参数值为0x78,显然，即为字符’x’! 由于va_arg是一个宏定义，没办法打断点，只能够将断点打在getuint和getint函数上，然后会发现，每一个va_arg对应的汇编代码大概都是这样，很明显，将ap的值加4后又赋值给ap,例如开始ap为0xf010ffd4,那么通过va_arg宏，ap改变为0xf010ffd8。 后续都是重复过程，就不再赘述。 Exercise 9#My answer for exercise 9#回想之前几个exercise，应该在entry.S当中初始化栈，结合obj/kern/kernel.asm以及inc/memlayout.h还有inc/mmu.h很容易找到答案：在0xf0100034处mov $0xf0110000,%esp初始化内核栈，对应于entry.S中的mov $(bootstacktop),%esp,并且在inc/mmu.h中定义了PGSIZE=4096,在inc/memlayout.h中定义了内核栈的大小KSTKSIZE=8*PGSIZE即2^15即0x8000,因此内核栈的内存区域为0xf0110000~0xf0108000. Exercise 10#Key point# The ebp (base pointer) register, in contrast, is associated with the stack primarily by software convention. On entry to a C function, the function’s prologue code normally saves the previous function’s base pointer by pushing it onto the stack, and then copies the current esp value into ebp for the duration of the function. If all the functions in a program obey this convention, then at any given point during the program’s execution, it is possible to trace back through the stack by following the chain of saved ebp pointers and determining exactly what nested sequence of function calls caused this particular point in the program to be reached. This capability can be particularly useful, for example, when a particular function causes an assert failure or panic because bad arguments were passed to it, but you aren’t sure who passed the bad arguments. A stack backtrace lets you find the offending function. My answer for exercise 10#test_backtrace定义在地址0xf0100040,将断点打在此处，然后调试即可。下图是该递归函数进入到第二层的栈结构，可以得出以下结论，每一层都需要8个字的空间，即8*4=32字节。正如官方文档所说，每个函数调用入口都会保存调用者的栈帧地址%ebp（被调用者保存寄存器）,因此能够轻松地向上回溯到需要的地方，拿到想要的值: Exercise 11,12#My answer for exercise 11 and 12#因为在kern/entry.S中能发现，内核初始化内核栈时，首先执行了mov $0,%ebp，因此，栈顶保存的%ebp的值为0，这就是终止条件。代码实现很简单。 在kern/kdebug.c中添加的代码为(其中N_SLINE定义在stab.h当中）： 123stab_binsearch(stabs,&amp;lline,&amp;rline,N_SLINE,addr); if(lline &gt; rline)return -1; info-&gt;eip_line = stabs[lline].n_desc; 下面就是完整的实现，有两个注意点： 此时不能使用malloc函数，因为还没实现呢！ 注意uintptr_t等价于uint32_t，查看inc/type.h就能发现，二者是等价的。 1234567891011121314151617int mon_backtrace(int argc, char **argv, struct Trapframe *tf){ // Your code here. struct Eipdebuginfo eipInfo; uintptr_t ebp = read_ebp(),*t; int count = 0; while(ebp != 0){ t = (uintptr_t*)ebp; if(debuginfo_eip((uintptr_t)t[1],&amp;eipInfo) &gt;= 0){ cprintf(\"ebp %x eip %x args %08x %08x %08x %08x %08x\\n\", ebp, t[1],t[2],t[3],t[4],t[5],t[6]); cprintf(\"\\t%s:%d: %.*s+%d\\n\",eipInfo.eip_file,eipInfo.eip_line,eipInfo.eip_fn_namelen,eipInfo.eip_fn_name,eipInfo.eip_fn_addr); ++count; } ebp=t[0]; } return count;} 最后别忘了在kern/monitor.c当中添加上该指令： 12345static struct Command commands[] = { { \"help\", \"Display this list of commands\", mon_help }, { \"kerninfo\", \"Display information about the kernel\", mon_kerninfo }, { \"mon_backtrace\", \"Display the stack frame\", mon_backtrace },}; 参考资料# 【1】：Intel 80386 Reference Programmer’s Manual【2】：xv6 - a simple, Unix-like teaching operating system - Reference Book【3】：PC Assembly Language.Paul A. Carter【4】：Boch’s map of I/O ports to functions【5】：Phil Storrs I/O Ports Description【6】：Quora:What is the A20 gate in a CPU【7】：x86-lidt and lgdt【8】：Wiki:GDT【9】：Wiki:Control register【10】：Wiki:Executable and Linkable Format【11】：Phil Storrs PC Hardware book - Understanding the CMOS【12】：《Computer Systems: A Programmer’s Perspective (3rd Edition)》.Randal E.Bryant / David O’Hallaron.【13】：《Modern Opeation Systems (Fourth Edition)》.Andrew S.Tanenbaum / Herbert Bos.","link":"/2019/12/28/MIT-6-828-LAB1-Booting-a-PC/"},{"title":"MIT-6.828-LAB3 User Environments","text":"Contents# Part A:User Environments and Exception Handling Exercise 1 Exercise 2 Exercise 3 Exercise 4 Challenge Question Part B:Page Faults,Breakpoint Exceptions and System Calls Exercise 5 Exercise 6 Challenge Question Exercise 7 Exercise 8 Exercise 9 Exercise 10 TEST REFERENCES Part A:User Environments and Exception Handling# Exercise 1#同pages一样，需要在物理内存中为User Environments分配内存来保存Env信息，在Lab2中，在Boot Loader引导加载了内核数据以及代码之后，我们在其后给Kernel Page Directory和Page Info分配了物理内存。 Exercise1实际上就是完成了上图Environments内存的分配，并且将其映射到了图示位置，按道理来说，envs此时应该指向Environments的起始地址，但是由于boot_alloc()返回的是虚拟地址，即实际的物理地址+KERNBASE，因此envs对应的实际物理内存地址需要用宏PADDR(envs)得到。（在KERNBASE之上映射了从0开始的最多2GB的物理内存空间！）除此之外，还有几个细节部分： Kernel Page Directory的物理地址同样会保存在控制寄存器%cr3中，这样通过向%cr3控制寄存器写入不同的值，就能在User Page Directory和Kernel Page Directory之间切换了，并且能辅助实现用户环境的切换，因为正如许多操作系统课程所说，每个进程都会有一张独立的Page Directory，这也是后续的Exercise需要实现的。 Cur.Page Table是每个User Program独有的Page Table，也就是说，当创建一个environment时，会使用page_alloc()为该environment分配一页作为其独立的Page Table，并且将其映射到UVPT，同时将这种映射关系写入到每个environment独立的Page directory中，你可能注意到，并没有地方映射每个environment的Page directory，因此需要environment自己保留相应的page directory虚拟地址，在具体实现中就是Env结构体的env_pgdir指针了。 代码实现：为environment分配内存： 1envs = (struct Env *)boot_alloc(sizeof(struct Env) * NENV); 完成映射关系，写入kern_pgdir： 1boot_map_region(kern_pgdir, UENVS, PTSIZE, PADDR(envs), (PTE_U | PTE_P)); Exercise 2#首先将exercise 1中分配的environments组成链表，以便后续的env的创建和销毁： 123456789101112131415void env_init(void){ // Set up envs array env_free_list = envs; env_free_list-&gt;env_id = 0; struct Env *tail = envs, *start = envs + 1, *end = envs + NENV; for(;start &lt; end; ++start){ tail-&gt;env_link = start; tail = tail-&gt;env_link; tail-&gt;env_id = 0; } // Per-CPU part of the initialization env_init_percpu();} 然后，正如上面所讨论的一样，需要每个environment维护一个独立的page directory，因此首先分配一页用来存储page directory，并且直接将kern page direcotyr复制过来，但是仅允许该environment对自己的page direcory有读取权限（除此之外，就是mem_init对user给与的权限，例如图1的READ-ONLY Pages和READ-ONLY ENVS） 1234567891011121314151617181920static int env_setup_vm(struct Env *e){ int i; struct PageInfo *p = NULL; // Allocate a page for the page directory if (!(p = page_alloc(ALLOC_ZERO))) return -E_NO_MEM; // Now, set e-&gt;env_pgdir and initialize the page directory. e-&gt;env_pgdir = (pde_t *)page2kva(p); memcpy(e-&gt;env_pgdir, kern_pgdir, PGSIZE); // Just copy the kern_pgdir because they are mostly the same. ++p-&gt;pp_ref; // UVPT maps the env's own page table read-only. // Permissions: kernel R, user R e-&gt;env_pgdir[PDX(UVPT)] = PADDR(e-&gt;env_pgdir) | PTE_P | PTE_U; return 0;} 随后实现region_alloc作用和boot_map_region很类似，但是除了按照指定的虚拟地址建立映射关系之外，还要按照指定的大小来分配页面。 123456789static void region_alloc(struct Env *e, void *va, size_t len){ void* end = ROUNDUP(va + len, PGSIZE); for(void *start = ROUNDDOWN(va, PGSIZE); start &lt; end; start += PGSIZE){ struct PageInfo *pg = page_alloc(ALLOC_ZERO); if(!pg)panic(\"All pages were assigned!\"); page_insert(e-&gt;env_pgdir, pg, start, (PTE_W | PTE_U | PTE_P)); }} 有了region_alloc之后就能够完成load_code来完成可执行文件的加载了，但是现在还没实现文件系统，因此这里加载的是MIT提供的静态二进制文件而不是通常意义上的.o文件。这部分参考boot loader的实现即可： 1234567891011121314151617181920212223242526272829static void load_icode(struct Env *e, uint8_t *binary){ struct Proghdr *ph, *eph; struct Elf *elfHeader = (struct Elf*)binary; // is this a valid ELF? assert(elfHeader-&gt;e_magic == ELF_MAGIC); ph = (struct Proghdr *)(binary + elfHeader-&gt;e_phoff); eph = ph + elfHeader-&gt;e_phnum; lcr3(PADDR(e-&gt;env_pgdir)); // switch to this environment's address space.cr3 register must be physical address. for(; ph &lt; eph; ++ph){ if(ph-&gt;p_type == ELF_PROG_LOAD){ // assert(ph-&gt;p_filesz &lt;= ph-&gt;p_memsz); region_alloc(e, (void *)ph-&gt;p_va, ph-&gt;p_memsz); memset((void *)ph-&gt;p_va, 0, ph-&gt;p_memsz); // cleard to zero memcpy((void *)ph-&gt;p_va, (void *)(binary + ph-&gt;p_offset), ph-&gt;p_filesz); // copy contents according to comments above. } } // set current trap frame's eip(PC) of this environment with elfHeader-&gt;e_entry to // make sure that the environment starts executing there. e-&gt;env_tf.tf_eip = elfHeader-&gt;e_entry; // Now map one page for the program's initial stack // at virtual address USTACKTOP - PGSIZE. region_alloc(e, (void *)(USTACKTOP - PGSIZE), PGSIZE); // map user stack. lcr3(PADDR(kern_pgdir)); // switch to kernel's address space.} 当具备了向用户环境中加载代码和数据的能力之后，就能完成environment的创建功能了，分配环境并加载代码和数据： 12345678910void env_create(uint8_t *binary, enum EnvType type){ struct Env *env; int32_t flag; if((flag = env_alloc(&amp;env, (envid_t)0)) &lt; 0){ panic(\"env_create:%e\", flag); } env-&gt;env_type = type; load_icode(env, binary); // restore this binary image to corresponding memory.} 最后实现env_run: 123456789101112void env_run(struct Env *e){ if(curenv &amp;&amp; curenv-&gt;env_status == ENV_RUNNING){ // is a context switch. curenv-&gt;env_status = ENV_RUNNABLE; } curenv = e; curenv-&gt;env_status = ENV_RUNNING; ++curenv-&gt;env_runs; // update the times of the environment has run. lcr3(PADDR(curenv-&gt;env_pgdir)); // switch to this new environment's address space. env_pop_tf(&amp;(curenv-&gt;env_tf)); // restore the environment's registers and drop into the user mode in the environment.} Exercise 3# Read Chapter 9, Exceptions and Interrupts in the 80386 Programmer’s Manual (or Chapter 5 of the IA-32 Developer’s Manual) 对Lab3最重要的 Exercise 4#正如exercise 3所讨论的，为了处理Interruption，我们需要设置IDT以及相应的Handler，并且为Handler传入它所需要的参数，并且保存现场，以便返回到被中断的Procedure或者Task，这部分给Handler传入的参数等实际上可通过Trapframe来访问。 1234567891011121314151617181920212223+------------------------------------------+ +---------------------------+| Interrupt Signal detected by processor's | Invoke corresponding handler | The Handler will push the | Each Handler will jump to _alltraps| hardware such as APIC(processor with on- | by Iterrupt vector and IDT | the interrupt vector | defined by kern/trapentry.S| chip local APIC),NMI pins or INTR pins. | ============================&gt; | number onto kernel stack | ===================================&gt;+------------------------------------------+ +---------------------------++-------------------------------------------+ +---------------------------+| _alltraps should push the rest necessary | _alltrps call trap function | trap will save some states| trap pass control to| arguments in struct Trapframe such as %ds | defined in kern/trap.c | such as trapframe. | trap_dispatch| %es and some registers. | ===========================&gt; | | ====================&gt;+-------------------------------------------+ +---------------------------++------------------------------------------------------------------------------------+| trap_dispatch invoke handler function(differs from the handler in trapentry.S) || we defined such as page_fault_handler in kern/trap.c and monitor in kern/monitor.c |+------------------------------------------------------------------------------------+*****************************************ABOVE ALL,below is a simple call flow:*****************************************+-----------------+ +------------------+ +-------------------------+ +---------------------------+ +-----------------+ +--------------------------+ +----------------+|procedure or task|=&gt;|processor hardware|=&gt;|handler(kern/trapentry.S)|=&gt;|_alltraps(kern/trapentry.S)|=&gt;|trap(kern/trap.c)|=&gt;|trap_dispatch(kern/trap.c)|=&gt;|handler function|+-----------------+ +------------------+ +-------------------------+ +---------------------------+ +-----------------+ +--------------------------+ +----------------+ 首先，为每个Interrupt vector编写相应的Handler，这里可以直接使用在trapentry.S中定义的宏，其中有两个宏，一个是不要error code的Interrupt，但是为了保持trapframe的格式一致性，需要存放一个值占位，这两个宏的作用都是直接定义Handler函数，.global的作用就是定义全局符号，这样才能在后续trap_init中绑定Interrupt vector和相应的Handler函数。至于哪些需要error code，哪些不需要，在IA-32 Developer’s mannual中写的很清楚。 12345678910111213141516171819202122232425.text// Exceptions without error code.TRAPHANDLER_NOEC(divideErrorHandler, T_DIVIDE);TRAPHANDLER_NOEC(debugHandler, T_DEBUG);TRAPHANDLER_NOEC(NMIHandler, T_NMI);TRAPHANDLER_NOEC(breakpointHandler, T_BRKPT);TRAPHANDLER_NOEC(overflowHandler, T_OFLOW);TRAPHANDLER_NOEC(BOUNDRangeExceededHandler, T_BOUND);TRAPHANDLER_NOEC(invalidOpcodeHandler, T_ILLOP);TRAPHANDLER_NOEC(deviceNotAvailableHandler, T_DEVICE);// Exceptions with error code.You can find this information in chapter 9.10 of 80386 programmer's references mannual.TRAPHANDLER(doubleFaultHandler, T_DBLFLT);// TRAPHANDLER_NOEC(coprocessorSegmentOverrunHandler, T_COPROC); reserved,just ignore.TRAPHANDLER(invalidTSSHandler, T_TSS);TRAPHANDLER(segmentNotPresentHandler, T_SEGNP);TRAPHANDLER(stackFaultHandler, T_STACK);TRAPHANDLER(generalProtectionHandler, T_GPFLT);TRAPHANDLER(pageFaultHandler, T_PGFLT);// Exceptions without error code.TRAPHANDLER_NOEC(floatingPointErrorHandler, T_FPERR);TRAPHANDLER_NOEC(alignmentCheckHandler, T_ALIGN);TRAPHANDLER_NOEC(machineCheckHandler, T_MCHK);TRAPHANDLER_NOEC(SIMDFloatingPointExceptionHandler, T_SIMDERR); 实现_alltraps汇编代码（因为这段代码对所有trap都一样，所以才将其剥离出来）： 1234567891011121314151617181920/* * Key point from lab reference: * 1. push values to make the stack look like a struct Trapframe; * 2. load GD_KD into %ds and %es; * 3. pushl %esp to pass a pointer to the Trapframe as an argument to trap(); * 4. call trap (can trap ever return?Yes); * According to inc/trap.h and the macro TRAPHANDLER,we can know that we should push %ds and %es register after * the tf_trapno because the tf_trapno was pushed onto stack by x86 hardware. * TIPS:pushal instruction will save all registers that trapframe need. */.global _alltraps_alltraps: pushl %ds pushl %es pushal movw $GD_KD, %ax movw %ax, %ds movw %ax, %es pushl %esp call trap 最后在kern/trap.c的trap_init中设置idt，绑定Interrupt vector和Handler(虽然我们在trapentry.S中定义了trap handler function，为了在trap.c中引用到这些handler，我们还需要在trap.c中声明这些函数签名，这样才能够在编译阶段做符号解析时才能不报错，或者声明在头文件中也可以)，这里暂时先将所有Gate的Descriptor privileged level设置为0（内核级）： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647voidtrap_init(void){ extern struct Segdesc gdt[]; // Generate corresponding exception handler function's signature. void divideErrorHandler(); void debugHandler(); void NMIHandler(); void breakpointHandler(); void overflowHandler(); void BOUNDRangeExceededHandler(); void invalidOpcodeHandler(); void deviceNotAvailableHandler(); void doubleFaultHandler(); void invalidTSSHandler(); void segmentNotPresentHandler(); void stackFaultHandler(); void generalProtectionHandler(); void pageFaultHandler(); void floatingPointErrorHandler(); void alignmentCheckHandler(); void machineCheckHandler(); void SIMDFloatingPointExceptionHandler(); // set IDT with macro SETGATE in inc/mmu.h SETGATE(idt[T_DIVIDE], 0, GD_KT, divideErrorHandler, 0); SETGATE(idt[T_DEBUG], 0, GD_KT, debugHandler, 0); SETGATE(idt[T_NMI], 0, GD_KT, NMIHandler, 0); SETGATE(idt[T_BRKPT], 0, GD_KT, breakpointHandler, 0); SETGATE(idt[T_OFLOW], 0, GD_KT, overflowHandler, 0); SETGATE(idt[T_BOUND], 0, GD_KT, BOUNDRangeExceededHandler, 0); SETGATE(idt[T_ILLOP], 0, GD_KT, invalidOpcodeHandler, 0); SETGATE(idt[T_DEVICE], 0, GD_KT, deviceNotAvailableHandler, 0); SETGATE(idt[T_DBLFLT], 0, GD_KT, doubleFaultHandler, 0); SETGATE(idt[T_TSS], 0, GD_KT, invalidTSSHandler, 0); SETGATE(idt[T_SEGNP], 0, GD_KT, segmentNotPresentHandler, 0); SETGATE(idt[T_STACK], 0, GD_KT, stackFaultHandler, 0); SETGATE(idt[T_GPFLT], 0, GD_KT, generalProtectionHandler, 0); SETGATE(idt[T_PGFLT], 0, GD_KT, pageFaultHandler, 0); SETGATE(idt[T_FPERR], 0, GD_KT, floatingPointErrorHandler, 0); SETGATE(idt[T_ALIGN], 0, GD_KT, alignmentCheckHandler, 0); SETGATE(idt[T_MCHK], 0, GD_KT, machineCheckHandler, 0); SETGATE(idt[T_SIMDERR], 0, GD_KT, SIMDFloatingPointExceptionHandler, 0); // Per-CPU setup trap_init_percpu();} Challenge# trap_init太多重复代码了，可以通过在trapentry.S中的.data节中定义一段内存来存储Gate相关参数，从而在trap_init函数中直接通过数组来获取这些参数，然后直接通过一个循环完成Interrupt vector和Handler的绑定。这里我一开始实现的时候，没有考虑太多，仅仅只存储了Handler的函数指针，因此导致后面exercise 7需要为系统调用添加Handler的时候，还是得额外写SETGATE，因此，建议可以多存储一些信息，例如Handler name以及Interrupt vector还有DPL。首先实现自己宏，实际就是添加了.data节用来存储数据。然后定义全局符号entryPointOfTraps以便后续在trap.c中引用数据。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/* * My own macro for exercise 4's chanllenge of lab3. */#define TRAPHANDLER_MINE(name, num) \\.data; \\ .long name; /* entry point's symbol */ \\.text; \\ .global name; /* define global symbol for 'name' */ \\ .type name, @function; /* symbol type is function */ \\ .align 2; /* align function definition */ \\name: /* function starts here */ \\ pushl $(num); \\ jmp _alltraps#define TRAPHANDLER_NOEC_MINE(name, num) \\.data; \\ .long name; \\.text; \\ .global name; /* define global symbol for 'name' */ \\ .type name, @function; /* symbol type is function */ \\ .align 2; /* align function definition */ \\name: /* function starts here */ \\ pushl $0; \\ pushl $(num); \\ jmp _alltraps.data .global entryPointOfTraps entryPointOfTraps:.text// Exceptions without error code.TRAPHANDLER_NOEC_MINE(divideErrorHandler, T_DIVIDE);TRAPHANDLER_NOEC_MINE(debugHandler, T_DEBUG);TRAPHANDLER_NOEC_MINE(NMIHandler, T_NMI);TRAPHANDLER_NOEC_MINE(breakpointHandler, T_BRKPT);TRAPHANDLER_NOEC_MINE(overflowHandler, T_OFLOW);TRAPHANDLER_NOEC_MINE(BOUNDRangeExceededHandler, T_BOUND);TRAPHANDLER_NOEC_MINE(invalidOpcodeHandler, T_ILLOP);TRAPHANDLER_NOEC_MINE(deviceNotAvailableHandler, T_DEVICE);TRAPHANDLER_MINE(doubleFaultHandler, T_DBLFLT);TRAPHANDLER_NOEC_MINE(coprocessorSegmentOverrunHandler, T_COPROC);// Just padding.TRAPHANDLER_MINE(invalidTSSHandler, T_TSS);TRAPHANDLER_MINE(segmentNotPresentHandler, T_SEGNP);TRAPHANDLER_MINE(stackFaultHandler, T_STACK);TRAPHANDLER_MINE(generalProtectionHandler, T_GPFLT);TRAPHANDLER_MINE(pageFaultHandler, T_PGFLT);TRAPHANDLER_MINE(reserved, T_RES); // Just padding.TRAPHANDLER_NOEC_MINE(floatingPointErrorHandler, T_FPERR);TRAPHANDLER_NOEC_MINE(alignmentCheckHandler, T_ALIGN);TRAPHANDLER_NOEC_MINE(machineCheckHandler, T_MCHK);TRAPHANDLER_NOEC_MINE(SIMDFloatingPointExceptionHandler, T_SIMDERR);TRAPHANDLER_NOEC_MINE(syscallHandler, T_SYSCALL); 随后trap.c中就可以直接用循环来设置idt了： 1234567891011121314151617voidtrap_init(void){ extern struct Segdesc gdt[]; extern void(*entryPointOfTraps[])(); int32_t i; for(i = 0; i &lt; 20; ++i){ if(i == T_BRKPT){ SETGATE(idt[i], 0, GD_KT, entryPointOfTraps[i], 3); }else SETGATE(idt[i], 0, GD_KT, entryPointOfTraps[i], 0); } // set syscall gate SETGATE(idt[T_SYSCALL], 0, GD_KT, entryPointOfTraps[i], 3); // syscall entry was in index 20. // Per-CPU setup trap_init_percpu();} 【更新-2020/1/25】：由于之前的不合理考虑，后面的LAB4我增加了这里Challenge中保存的信息，方便后续的设置： 12345678910111213141516171819202122232425/* * My own macro for exercise 4&apos;s chanllenge of lab3. */#define TRAPHANDLER_MINE(name, num) \\.data; \\ .long name, num; /* entry point&apos;s symbol */ \\.text; \\ .global name; /* define global symbol for &apos;name&apos; */ \\ .type name, @function; /* symbol type is function */ \\ .align 2; /* align function definition */ \\name: /* function starts here */ \\ pushl $(num); \\ jmp _alltraps#define TRAPHANDLER_NOEC_MINE(name, num) \\.data; \\ .long name, num; \\.text; \\ .global name; /* define global symbol for &apos;name&apos; */ \\ .type name, @function; /* symbol type is function */ \\ .align 2; /* align function definition */ \\name: /* function starts here */ \\ pushl $0; \\ pushl $(num); \\ jmp _alltraps 可以看到实际上就是增加了Exception Vector的存储。后续在kern/trap.c中初始化trap handler: 123456789101112131415voidtrap_init(void){ extern struct Segdesc gdt[]; extern long *entryPointOfTraps[2]; int32_t i; for(i = 0; i &lt;= 20; ++i){ if(entryPointOfTraps[i][1] == T_BRKPT || entryPointOfTraps[i][1] == T_SYSCALL){ SETGATE(idt[entryPointOfTraps[i][1]], 0, GD_KT, entryPointOfTraps[i][0], 3); }else SETGATE(idt[entryPointOfTraps[i][1]], 0, GD_KT, entryPointOfTraps[i][0], 0); } // Per-CPU setup trap_init_percpu();} Question# 1.What is the purpose of having an individual handler function for each exception/interrupt? (i.e., if all exceptions/interrupts were delivered to the same handler, what feature that exists in the current implementation could not be provided?) 在SETGATE中，不仅仅是将每个exception/interrupt的vector与相应的handler function绑定，并且Interrupt gate用了一些bit来作为控制位，例如DPL能标识能够调用该Interrupt gate对应的handler function需要的特权级别(privileged level)，这样就能够提供一些保护。以下内容引自Lab reference: The Interrupt Descriptor Table. The processor ensures that interrupts and exceptions can only cause the kernel to be entered at a few specific, well-defined entry-points determined by the kernel itself, and not by the code running when the interrupt or exception is taken.An interrupt’s vector is determined by the source of the interrupt: different devices, error conditions, and application requests to the kernel generate interrupts with different vectors. The CPU uses the vector as an index into the processor’s interrupt descriptor table (IDT), which the kernel sets up in kernel-private memory, much like the GDT. From the appropriate entry in this table the processor loads: the value to load into the instruction pointer (EIP) register, pointing to the kernel code designated to handle that type of exception. the value to load into the code segment (CS) register, which includes in bits 0-1 the privilege level at which the exception handler is to run. (In JOS, all exceptions are handled in kernel mode, privilege level 0.) 显然，如果所有的exceptions/interrupts都绑定到相同的handler function，那么这样的机制就没办法实现。 2.Did you have to do anything to make the user/softint program behave correctly? The grade script expects it to produce a general protection fault (trap 13), but softint’s code says int $14. Why should this produce interrupt vector 13? What happens if the kernel actually allows softint’s int $14 instruction to invoke the kernel’s page fault handler (which is interrupt vector 14)? 虽然user/softint是通过int指令，想要触发page fault，但是，由于user/softint运行在用户态下，而page fault的Interrupt descriptor中的DPL标识调用page fault的handler function需要内核级别特权，即0，因此，根据Intel IA-32 developer’s manual，会由硬件检测出general protection exception： 【Intel IA-32 developer’s manual:5.12.1.1】The processor does not permit transfer of execution to an exception- or interrupt-handler procedure in a less privileged code segment(numerically greater privilege level) than the CPL.An attempt to violate this rule results in a general-protection exception.The processor checks the DPL of the interrupt or trap gate only if an exception or interrupt is generated with an INT n, INT 3, or INTO instruction. Here, the CPL must be less than or equal to the DPL of the gate. This restriction prevents application programs or procedures running at privilege level 3 from using a software interrupt to access critical exception handlers, such as the page-faulthandler. 因此如果想要触发page fault而不是general-protection exception，可以在trap_init初始化Interrupt Gate时，将page fault的DPL设置为3即可，这样就能满足CPL &lt;= DPL的要求了。 Part B:Page Faults,Breakpoint Exceptions and System Calls# Exercise 5#还记得Exercise 4中的Call Flow吗，它能够帮助你理解trap_dispatch所处的位置和所起到的作用。实际上，此时trap_dispatch根据tf-&gt;tf_trapno(实际上就是Interrupt vector)来调用相应的处理函数即可（这里的处理函数不等价于前面SETGATE绑定的Handler function） 1234567891011121314151617181920212223static void trap_dispatch(struct Trapframe *tf){ // Handle processor exceptions. switch(tf-&gt;tf_trapno){ case T_PGFLT:page_fault_handler(tf);return; case T_BRKPT:monitor(tf);return; case T_DEBUG:monitor_debug(tf);return; case T_SYSCALL:{ tf-&gt;tf_regs.reg_eax = syscall(tf-&gt;tf_regs.reg_eax, tf-&gt;tf_regs.reg_edx, tf-&gt;tf_regs.reg_ecx, tf-&gt;tf_regs.reg_ebx, tf-&gt;tf_regs.reg_edi, tf-&gt;tf_regs.reg_esi); return; } default:break; } // Unexpected trap: The user process or the kernel has a bug. print_trapframe(tf); if (tf-&gt;tf_cs == GD_KT) panic(\"unhandled trap in kernel\"); else { env_destroy(curenv); return; }} 上面的代码直接将后续的Exercise都放上去了，对于Exercise 5，只需要添加case T_PGFLT即可。然后修改page_fault_handler即可： 123456789101112131415161718192021void page_fault_handler(struct Trapframe *tf){ uint32_t fault_va; // Read processor's CR2 register to find the faulting address fault_va = rcr2(); // Handle kernel-mode page faults.Beacuse it should never triger page fault in kernel-mode,just panic! if((tf-&gt;tf_cs &amp; 3) == 0){ panic(\"Your kernel triger a page fault!Bad kernel:(\"); } // We've already handled kernel-mode exceptions, so if we get here, // the page fault happened in user mode. // Destroy the environment that caused the fault. cprintf(\"[%08x] user fault va %08x ip %08x\\n\", curenv-&gt;env_id, fault_va, tf-&gt;tf_eip); print_trapframe(tf); env_destroy(curenv);} 内核态之下是绝对不可能触发page fault的! Exercise 6#实现已经在Exercise 5中了。如果make grade在breakpoint test case上失败了，那么可以通过make run-breakpoint或者make run-breakpoint-nox来执行user/breakpoint.c来进行调试。 Challenge#这个Challenge让我们修改monitor从而实现单步调试的功能，根据提示，查阅Intel IA-32 developer’s manual： 【Intel IA-32 developer’s manual:2.3】TF Trap(bit 8)-Set to enablesingle-step mode for debugging;clear to disable single-step mode.In single-step mode,the processor generates a debug exception after each instruction.This allows the execution state of a program to be inspected after each instruction. 这样，就有思路了。触发Breakpoint exception进入monitor之后，需要设置EFLAGS寄存器值的TF位（在实际实现中就是修改trapframe的tf_eflags），随后退出monitor，将控制权交还给被该Breakpoint exception中断的procedure或task，因为将控制权交还给用户程序时，也会把进入中断处理程序时保存的eflags寄存器的值恢复到EFLAGS寄存器之中，而我们在monitor中修改了所保存的eflags寄存器值的TF位，这样后续用户程序再执行一条指令，就会触发Debug Exception，因此，我们还需要修改trap_dispatch，使其能够对Debug Exception进行处理，此时只需要让处理程序继续设置一次TF位然后又返回，这样不断往复，就能够实现逐步调试的功能了。以下是我的实现的简易Call flow: 123456789101112131415161718 +-----------------------------+ +-----------------+ +-----------+ set TF bit |monitor_debug(kern/monitor.c)|==&gt;|run_cmd(buf,tf,1)|==&gt;|debug_stepi|===========&gt; +-----------------------------+ +-----------------+ +-----------+ | ^ | | T_DEBUG | | |+-----------------+ *** +-------------+ T_BRKPT +-----------------------+ +-----------------+ ||procedure or task|====&gt;|trap_dispatch|=========&gt;|monitor(kern/monitor.c)|==&gt;|run_cmd(buf,tf,0)|========|=====+-----------------+ +-------------+ +-----------------------+ +-----------------+ | | ^ | | | Return Control to procefure. | | &lt;================================================================================ | | | | | +---------------------------------+ +-----------------+ +-----------+ set TF bit | | |==&gt;|mon_intoDebugMode(kern/monitor.c)|==&gt;|run_cmd(buf,tf,1)|==&gt;|debug_stepi|============&gt;&lt;=============== || +---------------------------------+ +-----------------+ +-----------+ || |============================================================================================================== 注意mon_intoDebugMode是接在run_cmd(buf,tf,0)之后的。这里就只给出最关键的debug_stepi和debug_continue的代码，完整实现见Github:YanTang Qin 1234567891011121314151617int debug_stepi(int argc, char** argv, struct Trapframe *tf){ // This function service for trap.c at the time when the kernel encounter Debug or Breakpoint exceptions. // Just a simple stpei function. if(tf-&gt;tf_trapno == T_BRKPT || tf-&gt;tf_trapno == T_DEBUG){ tf-&gt;tf_eflags |= FL_TF; // Set EFLAGS register with Trap flag which is a control flag. }else{ cprintf(\"You can only use stepi when the processor encounter Debug or Breakpoint exceptions.\\n\"); } return -1; // must return -1 because we should leave monitor and let user program proceed.}int debug_continue(int argc, char **argv, struct Trapframe *tf){ if(tf-&gt;tf_trapno == T_BRKPT || tf-&gt;tf_trapno == T_DEBUG){ tf-&gt;tf_eflags &amp;= ~FL_TF; } return -1;} Question# 3.The break point test case will either generate a break point exception or a general protection fault depending on how you initialized the break point entry in the IDT (i.e., your call to SETGATE from trap_init). Why? How do you need to set it up in order to get the breakpoint exception to work as specified above and what incorrect setup would cause it to trigger a general protection fault? 事实上，答案已经在上面的Question中的2讨论过了，若想要使其正常工作，就需要CPL &lt;= DPL，因此我们要将Breakpoint Gate的DPL设置为3即可正常工作。 4.What do you think is the point of these mechanisms, particularly in light of what the user/softint test program does? 为了安全吧，避免优先级低的代码段尝试去执行优先级高的代码段，从而进一步限制用户程序对一些内核代码或内存的访问。 Exercise 7#为T_SYSCALL添加GATE在Part A:Exercise 4的Challenge中已经给出，而在trap_dispatch中增加处理也在Exercise 5中给出，这里就不再赘述。 先看一下lib/syscall.c中提供给用户使用的接口做了什么： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152static inline int32_t syscall(int num, int check, uint32_t a1, uint32_t a2, uint32_t a3, uint32_t a4, uint32_t a5){ int32_t ret; // Generic system call: pass system call number in AX, // up to five parameters in DX, CX, BX, DI, SI. // Interrupt kernel with T_SYSCALL. // // The \"volatile\" tells the assembler not to optimize // this instruction away just because we don't use the // return value. // // The last clause tells the assembler that this can // potentially change the condition codes and arbitrary // memory locations. asm volatile(\"int %1\\n\" : \"=a\" (ret) : \"i\" (T_SYSCALL), \"a\" (num), \"d\" (a1), \"c\" (a2), \"b\" (a3), \"D\" (a4), \"S\" (a5) : \"cc\", \"memory\"); if(check &amp;&amp; ret &gt; 0) panic(\"syscall %d returned %d (&gt; 0)\", num, ret); return ret;}void sys_cputs(const char *s, size_t len){ syscall(SYS_cputs, 0, (uint32_t)s, len, 0, 0, 0);}int sys_cgetc(void){ return syscall(SYS_cgetc, 0, 0, 0, 0, 0, 0);}int sys_env_destroy(envid_t envid){ return syscall(SYS_env_destroy, 1, envid, 0, 0, 0, 0);}envid_t sys_getenvid(void){ return syscall(SYS_getenvid, 0, 0, 0, 0, 0, 0);} lib/syscall.c是提供给用户的接口，可以看到sys_cputs等接口是对lib/syscall.c中的syscall的一层封装，而lib/syscall.c:syscall的嵌入汇编代码使用了int触发软件中断（因此根据前面的exercise的讨论，必须将T_SYSCALL对应的Interrupt gate的DPL设置为3，才能正常通过int触发T_SYSCALL软件中断，否则会被处理器检测到General-protection exception）,并且该汇编代码声明了将输入值存放进%eax,%edx,%ecx,%ebx,%edi和%esi，输出值存放至%eax。 除此之外，volatile关键字在并发编程中很常见，它主要有两个作用： 保证内存的可见性； 禁止指令重排序； 但是在这里，根据注释，它的主要作用应该是告诉编译器不要优化，禁止指令重排序。 随之，在lib/syscall.c:syscall触发了T_SYSCALL中断之后，又会进入到之前Exercise 4的call flow，最终进入kern/trap.c:trap_dispatch，并且调用kern/syscall.c:syscall，而这个函数就是该exercise要我们实现的，实现不难，这里就不再赘述： 1234567891011121314// Dispatches to the correct kernel function, passing the arguments.int32_t syscall(uint32_t syscallno, uint32_t a1, uint32_t a2, uint32_t a3, uint32_t a4, uint32_t a5){ // Call the function corresponding to the 'syscallno' parameter. // Return any appropriate return value. switch (syscallno) { case SYS_cputs:sys_cputs((char *)a1, (size_t)a2);return 0; case SYS_cgetc:return sys_cgetc(); case SYS_getenvid:return (envid_t)sys_getenvid(); case SYS_env_destroy:return sys_env_destroy((envid_t)a1); default: return -E_INVAL; }} Exercise 8#在libmain中添加：thisenv = &amp;envs[ENVX(sys_getenvid())];即可。 Exercise 9#cs段寄存器的低两位用来标识privileged level，因此在page_fault_handler中可以通过检查tf-&gt;tf_cs的低两位来判断是kernel mode还是user mode： 123456789101112131415161718192021void page_fault_handler(struct Trapframe *tf){ uint32_t fault_va; // Read processor's CR2 register to find the faulting address fault_va = rcr2(); // Handle kernel-mode page faults.Beacuse it should never triger page fault in kernel-mode,just panic! if((tf-&gt;tf_cs &amp; 3) == 0){ panic(\":( Your kernel triger a page fault at va@0x%08x !Bad kernel\", fault_va); } // We've already handled kernel-mode exceptions, so if we get here, // the page fault happened in user mode. // Destroy the environment that caused the fault. cprintf(\"[%08x] user fault va %08x ip %08x\\n\", curenv-&gt;env_id, fault_va, tf-&gt;tf_eip); print_trapframe(tf); env_destroy(curenv);} 最后就是内存访问权限的校验函数的实现，这部分有点坑，后面花了我很多时间找这个bug，如果不是我在写这部分的时候，就注释了我对这里理解可能有问题的话，可能会花更多时间： 12345678910111213141516171819202122int user_mem_check(struct Env *env, const void *va, size_t len, int perm){ // LAB 3: Your code here. uintptr_t startVa = ROUNDDOWN((uintptr_t)va, PGSIZE), endVa = ROUNDUP((uintptr_t)(va + len), PGSIZE); pte_t *pte; struct PageInfo *pageInfo; uint32_t permissions = perm | PTE_P; for(; startVa &lt; endVa; startVa += PGSIZE){ pageInfo = page_lookup(env-&gt;env_pgdir, (void *)startVa, &amp;pte); if(!pageInfo || startVa &gt; (uintptr_t)ULIM || ((*pte) &amp; permissions) != permissions){ // cprintf(\"startVa=&gt;0x%08x vaFromPte=&gt;0x%08x *pte=&gt;0x%08x\\n\", startVa, KADDR(PTE_ADDR(*pte)), *pte); // if there is an error,set the 'user_mem_check_addr' variable to the first erroneous virtual address. // :( well,sorry I can't really understand the meaning of \"first erroneous virtual address.\" // Holy shit,this takes me really a lot of time to fix this bug to pass the whole test cases. user_mem_check_addr = (startVa &lt; (uintptr_t)va?(uintptr_t)va:startVa); return -E_FAULT; } } return 0;} 此时运行make run-breakpoint并且调用backtrace后会触发page fault: 1234567891011121314151617K&gt; backtrace'ebp efffff00 eip f01008fd args 00000001 efffff28 f01b4000 0a100188 f0105d53 kern/monitor.c:268: runcmd+-267384840ebp efffff80 eip f0100c03 args 00000002 00000000 efffffb0 f0103821 f01b4000 kern/monitor.c:289: monitor+-267383888ebp efffff90 eip f0103821 args f01b4000 efffffbc 00000000 00000082 00000000 kern/trap.c:203: trap+-267372692ebp efffffb0 eip f0103943 args efffffbc 00000000 00000000 eebfdfd0 efffffdc kern/syscall.c:69: syscall+-267372221ebp eebfdfd0 eip 800073 args 00000000 00000000 eebfdff0 00800049 00000000 lib/libmain.c:26: libmain+8388665Incoming TRAP frame at 0xeffffe8ckernel panic at kern/trap.c:271: :( Your kernel triger a page fault at va@0xeebfe008 !Bad kernelK&gt; showMappings 0xeebfe008 0xeebfe008va@start: eebfe000 va@end: eebff000va@page: eebfe000 pa@page: 00000000 @perm:PTE_P 0 PTE_U 0 PTE_W 0; showMappings的其它值都不重要，可以看到0xeebfe008对应的页的起始地址为0xeebfe000，而在memlayout.h中标明了0xeebfe000为USTACKTOP，也就是说backtrace最后触发page fault就是因为其尝试访问高于USTACKTOP的地址了。 Exercise 10#make run-evilhello，如果这个test case无法通过，可能就是上面的user_mem_check那里那个比较坑的地方不对。 TEST# 123456789101112131415161718divzero: OK (2.0s) softint: OK (0.8s) badsegment: OK (1.0s) Part A score: 30/30faultread: OK (2.0s) faultreadkernel: OK (1.0s) faultwrite: OK (1.9s) faultwritekernel: OK (1.2s) breakpoint: OK (1.8s) testbss: OK (2.3s) hello: OK (1.0s) buggyhello: OK (1.7s) buggyhello2: OK (2.5s) evilhello: OK (2.0s) Part B score: 50/50Score: 80/80 REFERENCES#【1】 Intel 80386 Reference Programmer’s Manual【2】 Intel® 64 and IA-32 Architectures Software Developer’s Manual【3】 XV6 - a simple, Unix-like teaching operating system - Reference Book【4】 《Computer Systems: A Programmer’s Perspective (3rd Edition)》.Randal E.Bryant / David O’Hallaron.【5】 《Modern Opeation Systems (Fourth Edition)》.Andrew S.Tanenbaum / Herbert Bos.","link":"/2020/01/16/MIT-6-828-LAB3-User-Environments/"},{"title":"MIT-6.828-LAB4 Preemptive Multitasking","text":"Contents# Part A : Multiprocessor Support and Cooperative Mutitasking Exercise 1 Exercise 2 Question Exercise 3 Exercise 4 Exercise 5 Question Exercise 6 : Round-Robin Scheduling Question Challenge : Extend More Complex Scheduling Policy Fixed-Priority Scheduler Exercise 7 Part B : Copy-on-Write Fork Exercise 8 Exercise 9 Exercise 10 Exercise 11 Exercise 12 Challenge : Implement Shared-Memory sfork Part C : Preemptive Multitasking and Inter-Process Communication(IPC) Exercise 13 Exercise 14 Exercise 15 TEST REFERENCES Part A:Multiprocessor Support and Cooperative Mutitasking# Exercise 1#在LAB4之前，所有的代码都是在同一个处理器上执行的，这个处理器一般叫做Bootstrap Processor(BSP)，BSP是哪个处理器是由BIOS和硬件共同决定的。在LAB4的一开始，我们要通过BSP来增加多处理器的支持，除了BSP之外的其它处理器一般叫做Application Processors(APs)。多处理器共享许多硬件资源，例如内存和I/O总线，但是也有许多硬件资源并不是共享的，例如LAPIC单元，TSS等寄存器，因此需要在BSP初始化好之后再初始化其它APs，当然，此时page等也不再需要初始化了（内存是共享的）。 在LAB4中的内存映射关系如下所示，可以和LAB3的内存映射关系对比来看: 代码很简单，值得注意的是，每个CPU都会调用一次mmio_map_region，因此base需要在每一次完成映射之后把值更新： 123456789101112void *mmio_map_region(physaddr_t pa, size_t size){ static uintptr_t base = MMIOBASE; size_t sizeUp = ROUNDUP(size, PGSIZE); if(sizeUp &gt; (MMIOLIM - base))panic(\"reservation of mmio overflow MMIOLIM!\"); boot_map_region(kern_pgdir, base, sizeUp, pa, (PTE_PCD | PTE_PWT | PTE_W)); // test case in check_page below -check that they don't overlap-reminds me of that base is an static variable and // this function mmio_map_region might be invoked two or more times.See more details in check_page function below. base += sizeUp; return (void *)(base - sizeUp);} Exercise 2#BSP完成了初始化之后（kern/init.c:i386_init），就需要调用boot_aps来完成APs的初始化，这一部分的Control flow如下所示： 12345678+-----------------------+ +----------------------+| kern/init.c:i386_init |==&gt;| kern/init.c:boot_aps |+-----------------------+ +----------------------+ | Pass control to kern/lapic.c:lapic_startap and switch to V the booted processor to execute rest code/instruction.+--------------------+ +------------------------------+| kern/init.c:mp_main|&lt;==| kern/mpentry.S:mpentry_start |+--------------------+ +------------------------------+ 值得注意的是，在kern/lapic.c中发生了处理器的切换，也就是说，从mpentry_start开始就是由被激活的CPU执行的，换而言之，从mpentry_start开始，这部分代码和BSP就是完全并行执行了，这也是为什么在kern/init.c:boot_aps的lapic_startap(c-&gt;cpu_id, PADDR(code))之后，需要BSP不断自旋直到该APs初始化完毕的原因： 12345// kern/init.c:boot_aps// Start the CPU at mpentry_startlapic_startap(c-&gt;cpu_id, PADDR(code));// Wait for the CPU to finish some basic setup in mp_main()while(c-&gt;cpu_status != CPU_STARTED); 同样，这也是为什么在BSP执行boot_aps之前需要申请内核锁的原因： 12345678910111213141516171819voidmp_main(void){ // We are in high EIP now, safe to switch to kern_pgdir lcr3(PADDR(kern_pgdir)); cprintf(\"SMP: CPU %d starting\\n\", cpunum()); lapic_init(); env_init_percpu(); trap_init_percpu(); xchg(&amp;thiscpu-&gt;cpu_status, CPU_STARTED); // tell boot_aps() we're up // Now that we have finished some basic setup, call sched_yield() // to start running processes on this CPU. But make sure that // only one CPU can enter the scheduler at a time! // lock_kernel(); sched_yield();} 从上面的代码可以看出，每个APs初始化完毕之后，使用xchg指令设置该CPU的状态为CPU_STARTED，来通知BSP该APs已经初始化完毕了，此时BSP就能够继续初始化下一个APs或者开始运行第一个User Environment，由于此时至少存在两个处理器是并行地运行，若不使用内核锁来确保同时只能有一个CPU执行一些关键的内核代码，就必然会产生并发错误，例如，在不使用内核锁的情况下，假设两个CPU同时进入了Scheduler，那么就可能导致两个CPU同时执行同一个User Environment的严重的并发错误，除此之外，创建Environment，分配Page等等都可能产生Race Condition，这显然不对。因此BSP在调用boot_aps之前必须申请kernel_lock，这样当所有APs还没初始化成功之前（即BSP的boot_aps还没返回之前）已完成初始化的APs都会被阻塞在mp_main的lock_kernel上，因为此时kernel_lock被BSP持有。 由于mpentry_start一开始将%DS，%ES，%SS设置为0，并且此时各种控制寄存器都尚未初始化，此时只能运行物理内存的低2^16字节地址上的代码，但是mpentry_start代码实际上属于内核代码，因此boot_aps才将mpentry_start这部分代码复制到MPENTRY_PADDR(0x7000)起始处（详情可看本文图 1-1）： 1memmove(code, mpentry_start, mpentry_end - mpentry_start); 正是需要将mpentry_start这部分代码复制到了MPENTRY_START的缘故，因此需要修改page_init，将mpentry_start这部分物理页标记为Not free，这也正是Exercise 2要我们做的： 1234567891011121314voidpage_init(void){ size_t i, extendedFree = PGNUM(PADDR(boot_alloc(0))); for(i = 0; i &lt; npages; ++i){ pages[i].pp_ref = 0; if(i == 0 || (i &gt;= npages_basemem &amp;&amp; i &lt; extendedFree) || i == PGNUM(MPENTRY_PADDR)){ pages[i].pp_link = NULL; }else{ pages[i].pp_link = page_free_list; page_free_list = &amp;pages[i]; } }} Question# 1.Compare kern/mpentry.S side by side with boot/boot.S. Bearing in mind that kern/mpentry.S is compiled and linked to run above KERNBASE just like everything else in the kernel, what is the purpose of macro MPBOOTPHYS? Why is it necessary in kern/mpentry.S but not in boot/boot.S? In other words, what could go wrong if it were omitted in kern/mpentry.S? kern/mentry.S与boot/boot.S主要有以下两点区别： kern/mentry.S不需要使能A20； kern/mentry.S需要使用宏MPBOOTPHYS来计算它所引用的符号（symbol）的绝对地址而不是和boot/boot.S一样依赖于链接器（linker）。 正如前面所提到的，kern/mpentry.S实际上是内核代码，它们的地址都在KERNBASE之上，而mpentry.S作为APs的boot代码，运行在低地址，因此需要使用宏MPBOOTPHYS来计算绝对地址，随后执行mpentry.S时运行在实模式之下。 1#define MPBOOTPHYS(s) ((s) - mpentry_start + MPENTRY_PADDR) 但是在boot/boot.S这部分代码实际上是由BIOS直接加载到了物理地址0x7c00，因此不需要使用宏来计算绝对地址。简单来说就是kern/mpentry.S引用的符号对应的地址是虚拟地址，高于KERNBASE，因此若不使用MPBOOTPHYS计算绝对地址，直接把虚拟地址当成物理地址，那么必然会加载未知的物理内存数据，必然出错。 Exercise 3#每个CPU可以并行地进入Trap，因此必须需要为每个CPU设置独立的内核栈。 123456789static voidmem_init_mp(void){ uint32_t CPU_i = 0; for(;CPU_i &lt; NCPU; ++CPU_i){ uintptr_t startVa = KSTACKTOP - CPU_i * (KSTKSIZE + KSTKGAP) - KSTKSIZE; boot_map_region(kern_pgdir, startVa, KSTKSIZE, PADDR(percpu_kstacks[CPU_i]), (PTE_W | PTE_P)); }} Exercise 4#由于每个CPU有着独立的内核栈，因此我们还需要修改每个CPU对应的TSS（Task State Segment）,并且将CPU对应的TSS descriptor写入到GDT中: 12345678910111213141516171819voidtrap_init_percpu(void){ // Setup a TSS so that we get the right stack when we trap to kernel. thiscpu-&gt;cpu_ts.ts_esp0 = KSTACKTOP - thiscpu-&gt;cpu_id * (KSTKSIZE + KSTKGAP); thiscpu-&gt;cpu_ts.ts_ss0 = GD_KD; thiscpu-&gt;cpu_ts.ts_iomb = sizeof(struct Taskstate); // Initialize the TSS slot of the gdt. gdt[(GD_TSS0 &gt;&gt; 3) + thiscpu-&gt;cpu_id] = SEG16(STS_T32A, (uint32_t)(&amp;(thiscpu-&gt;cpu_ts)), sizeof(struct Taskstate) - 1, 0); gdt[(GD_TSS0 &gt;&gt; 3) + thiscpu-&gt;cpu_id].sd_s = 0; // Load the TSS selector (like other segment selectors, the // bottom three bits are special; we leave them 0) ltr(GD_TSS0 + 8 * thiscpu-&gt;cpu_id); // low 3 bits was special. // Load the IDT lidt(&amp;idt_pd);} Exercise 5#从Exercise 2的讨论中，我们知道了在kern/init.c:i386_init中调用boot_aps之前BSP需要申请内核锁的原因是为了避免对内核一些关键资源的申请和分配产生错误，换而言之，后续从Kernel mode进入User mode时需要释放Kernel Lock，否则从一开始，所有的APs都会在mp_main中被阻塞，只有BSP一个CPU在做实际工作。另外，用户态也可以通过Trap陷入内核态，在执行关键内核代码之前，也需要申请Kernel Lock以避免并发错误。 因此，不考虑吞吐量和性能的前提条件下，在以下四个地方申请Kernel Lock或者释放Kernel Lock即可避免并发错误： In i386_init(), acquire the lock before the BSP wakes up the other CPUs. In mp_main(), acquire the lock after initializing the AP, and then call sched_yield() to start running environments on this AP. In trap(), acquire the lock when trapped from user mode. To determine whether a trap happened in user mode or in kernel mode, check the low bits of the tf_cs. In env_run(), release the lock right before switching to user mode. Do not do that too early or too late, otherwise you will experience races or deadlocks. 为什么在trap中可能需要申请Kernel Lock?在LAB3中我们设置的Trap Control Flow如下： 12345678+-----------------+ +------------------+ +-------------------------+ +---------------------------+|procedure or task|=&gt;|processor hardware|=&gt;|handler(kern/trapentry.S)|=&gt;|_alltraps(kern/trapentry.S)|+-----------------+ +------------------+ +-------------------------+ +---------------------------+ | |+------------------+ +----------------------------+ +-------------------+ || handler function |&lt;=| trap_dispatch(kern/trap.c) |&lt;=| trap(kern/trap.c) |&lt;============+------------------+ +----------------------------+ +-------------------+ 从processor hardware(APIC)探测到的Exception Vector根据我们在LAB3设置的IDT可以找到对应的Interrupt Descriptor，而该Interrupt Descriptor中保存有我们设置的handler(kern/trapentry.S)地址，也就是说，从处理器开始执行handler(kern/trapentry.S)的代码开始，实际上就已经陷入内核态了。在handler(kern/trapentry.S)和_alltraps(kern/trapentry.S)构造了trap frame之后，进入trap(kern/trap.c)，因此在这里需要检测是否该次trap是由用户态陷入到内核态的，若是，则执行后续的一些内核代码时，为避免并发错误，就需要先获得内核锁，以确保仅有一个CPU正在执行那些可能产生并发错误的内核代码。 Question# It seems that using the big kernel lock guarantees that only one CPU can run the kernel code at a time. Why do we still need separate kernel stacks for each CPU? Describe a scenario in which using a shared kernel stack will go wrong, even with the protection of the big kernel lock. 答案在Exercise 5中的讨论其实已经说得很清楚了，在获得内核锁之前需要由硬件切换到内核栈，在该CPU对应的内核栈中构造此次Trap的Trap frame，构造完成之后在trap(kern/trap.c)当中才去申请获得内核锁。倘若所有CPU共享内核栈，由于CPU能够并行地引发Trap，那么每个CPU在为它们当前正在执行的Environment构造Trap frame时就会产生混乱，从而引发错误。 Exercise 6 : Round-Robin Scheduling#轮循式调度策略很简单： 12345678910111213141516171819voidsched_yield(void){ uint32_t curenvIndex = (curenv?ENVX(curenv-&gt;env_id):0), offset; // curenv might be NULL! for(offset = 0; offset &lt; NENV; ++offset){ uint32_t realIndex = (curenvIndex + offset) % NENV; if(envs[realIndex].env_status == ENV_RUNNABLE){ env_run(&amp;envs[realIndex]); // switch to the first runnable environment.env_run will never return. } } if(curenv &amp;&amp; curenv-&gt;env_status == ENV_RUNNING){ // no envs are runnable,but the environment previously running on this CPU is still running. // It's okay to choose this environment. env_run(curenv); } // sched_halt never returns sched_halt();} Question# In your implementation of env_run() you should have called lcr3(). Before and after the call to lcr3(), your code makes references (at least it should) to the variable e, the argument to env_run. Upon loading the %cr3 register, the addressing context used by the MMU is instantly changed. But a virtual address (namely e) has meaning relative to a given address context–the address context specifies the physical address to which the virtual address maps. Why can the pointer e be dereferenced both before and after the addressing switch? 因为不仅高于KERNBASE之上的映射关系在任何Environment都是一样的，并且Read-Only Environment也是一样的。 Whenever the kernel switches from one environment to another, it must ensure the old environment’s registers are saved so they can be restored properly later. Why? Where does this happen? 这样才能在Environment发生切换的时候恢复到该Environment进入Trap前的一样状态。很明显，这种保存是发生在kern/trap.c:trap中的curenv-&gt;env_tf = *tf，当此次Trap是由用户态触发的时候，将trap frame完整保存到curenv-&gt;env_tf中，这样在env_pop_tf时，就能恢复现场了： Challenge : Extend More Complex Scheduling Policy#Fixed-Priority Scheduler#在Env中增加unsigned env_priority，值越小代表被调度的优先级越高： 123456789101112131415161718192021222324voidsched_yield(void){ uint32_t curenvIndex = (curenv?ENVX(curenv-&gt;env_id):0), offset; // curenv might be NULL! struct Env *envCandidate = NULL; for(offset = 0; offset &lt; NENV; ++offset){ uint32_t realIndex = (curenvIndex + offset) % NENV; if(envs[realIndex].env_status == ENV_RUNNABLE &amp;&amp; (!envCandidate || envs[realIndex].env_priority &lt; envCandidate-&gt;env_priority)){ envCandidate = &amp;envs[realIndex]; } } // switch to the greatest-priority runnable environment. if(curenv &amp;&amp; curenv-&gt;env_status == ENV_RUNNING &amp;&amp; (!envCandidate || curenv-&gt;env_priority &lt; envCandidate-&gt;env_priority)){ cprintf(\"envid@%04x with priority@%d will yield to envid@%04x with priority@%d\\n\", curenv-&gt;env_id, curenv-&gt;env_priority, curenv-&gt;env_id, curenv-&gt;env_priority); env_run(curenv); } if(envCandidate){ cprintf(\"envid@%04x with priority@%d will yield to envid@%04x with priority@%d\\n\", curenv?curenv-&gt;env_id:-1, curenv?curenv-&gt;env_priority:-1, envCandidate-&gt;env_id, envCandidate-&gt;env_priority); env_run(envCandidate); } // sched_halt never returns sched_halt();} 除此之外，还需要实现能够改变Environment的调度优先级的系统调用sys_env_set_priority，相应的，需要修改syscall.h，增加枚举值SYS_env_set_priority。 完整的实现和测试程序可参见Github:YanTang Qin的lab4WithPrioritySched分支: 将项目克隆至本地：git clone https://github.com/QinStaunch/MIT-6.828.git MIT-6.828 切换到lab4WithPrioritySched分支：git checkout lab4WithPrioritySched 将其与lab4分支比较可快速找到修改的地方：git diff lab4 Exercise 7#这部分的实现不难，篇幅原因，代码实现见Github:YanTang Qin的Master分支 Part B : Copy-on-Write Fork# 不同于Unix的fork，JOS在用户地址空间环境下来处理由于写时复制机制而产生的缺页异常，换而言之，最终这种缺页异常的处理会由内核态的page_fault_handler(kern/trap.c)最终转移到用户地址空间中指定的page fault handler(例如后面的Exercise要实现的pgfault(lib/fork.c))，并且在调用完用户地址空间中的page fault handler之后，还需要把控制最终转移回触发这次page fault的用户程序指令，而这是通过_pgfault_upcall(lib/pfentry.S)来实现的。整个的Control Flow如下所示(省略了一些函数调用)： 123456789101112+-----------------+ +------------------+ +----------------------------------+ +---------------------------+|procedure or task|=&gt;|processor hardware|=&gt;|pageFaultHandler(kern/trapentry.S)|=&gt;|_alltraps(kern/trapentry.S)|+-----------------+ +------------------+ +----------------------------------+ +---------------------------+ |+---------------------------------+ +----------------------------+ +-------------------+ || page_fault_handler(kern/trap.c) |&lt;=| trap_dispatch(kern/trap.c) |&lt;=| trap(kern/trap.c) |&lt;=======+---------------------------------+ +----------------------------+ +-------------------+ | V+--------------------------------+ +-------------------------------------------------+ ——| _pgfault_upcall(lib/pfentry.S) |=&gt;| _pgfault_handler(Specified By User Environment) | |-&gt; Happend in user address space.+--------------------------------+ +-------------------------------------------------+ —— Exercise 8#因此我们需要实现一个系统调用，它能够给该Environment绑定一个_pgfault_upcall函数： 12345678static intsys_env_set_pgfault_upcall(envid_t envid, void *func){ struct Env *thisEnv; if(envid2env(envid, &amp;thisEnv, 1) &lt; 0)return -E_BAD_ENV; thisEnv-&gt;env_pgfault_upcall = func; return 0;} Exercise 9#使用专门的User Exception Stack来处理page fault，为了能够在处理完page fault之后能够恢复现场(这一次不是通过调用env_run之后的env_pop_tf来恢复现场了，因为env_run用来进入_pgfault_upcall(lib/pfentry.S)用户程序了！)，我们需要在User Exception Stack上构造User Trap Frame。由于page fault可能递归触发，因此我们构造User Trap Frame时需要检测trap-time esp是否已经在User Exception Stack上了，并且针对这种情况，我们需要额外预留4字节的空间以便后续将trap-time eip保存到这预留的4字节空间中，只有这样才能在调用ret指令的时候，将trap-time eip从栈中弹出到%eip中，才能实现从触发此次page fault的指令开始执行的效果！ 你可能会有这样的疑问，为什么第一次在User Exception Stack上构造User Trap Frame时不需要预留4字节的空间？因为User Exception Stack栈顶的UTF的trap-time esp的值实际上是属于User Normal Stack的！因此我们保存的trap-time eip实际上后来被我们保存到了User Normal Stack上，而在调用ret指令之前，我们首先会把trap-time esp - 4恢复到寄存器%esp中，这样的话，当我们再调用ret指令时，栈指针实际上就指向了返回地址！ 下面是完整图解，如果你不是很明白，请多看几遍，否则后续的代码，你会感觉到很疑惑！ 123456789101112131415161718192021222324252627282930313233+------------------+ &lt;- UXSTACKTOP. ---| trap-time esp | |+------------------+ || trap-time eflags | |+------------------+ || trap-time eip | |+------------------+ &lt;- Start of struct PushRegs. || trap-time ecx | |+------------------+ || trap-time edx | \\+------------------+ \\ Last User-Trap-Frame| trap-time esp | /+------------------+ /| trap-time ebp | |+------------------+ || trap-time esi | |+------------------+ || trap-time edi | |+------------------+ &lt;- End of struct PushRegs. || tf_err:error code| |+------------------+ || fault_va | |+------------------+ &lt;- %esp(@) when handler is run. ---| | &lt;==+------------------+ | After we have called _pgfault_handler specified by user environment,| *trap-time esp | | we have to store *trap-time eip to address %esp(@) - 4.Up to this point,+------------------+ | upon we have restored necessary status or registers of the User-Trap-Frame| *trap-time eflags| | such as PushRegs and eflags register,we could use instruction \"ret\" to pop+------------------+ | the *trap-time eip we have stored before to register %eip.In other words,| *trap-time eip | === that is also the reason why we need to store *trap-time eip to %esp(@) -4.+~~~~~~~~~~~~~~~~~~+| ................ |+~~~~~~~~~~~~~~~~~~+ Exercise 9实际上就是要我们完成User trap frame的构造，以及把控制转移到用户程序_pgfault_upcall，以及完成从User Normal Stack到User Exceptiob Stack的切换： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253voidpage_fault_handler(struct Trapframe *tf){ uint32_t fault_va; // Read processor's CR2 register to find the faulting address fault_va = rcr2(); // Handle kernel-mode page faults.Beacuse it should never triger page fault in kernel-mode,just panic! if((tf-&gt;tf_cs &amp; 3) == 0){ panic(\":( Your kernel triger a page fault at va@0x%08x !Bad kernel\", fault_va); } // We've already handled kernel-mode exceptions, so if we get here, // the page fault happened in user mode. if(curenv-&gt;env_pgfault_upcall){ // exist env_pgfault_upcall. struct UTrapframe *utf; if(tf-&gt;tf_esp &gt;= (UXSTACKTOP - PGSIZE) &amp;&amp; tf-&gt;tf_esp &lt;= (UXSTACKTOP - 1)){ // the user environment is already running on the exception stack when an exception occurs. // Thus,we should start the new stack frame just under the tf-&gt;tf_esp.We have to push a word // at the top of the trap-time stack as a scratch space. utf = (struct UTrapframe *)(tf-&gt;tf_esp - 4 - sizeof(struct UTrapframe)); }else{ utf = (struct UTrapframe *)(UXSTACKTOP- sizeof(struct UTrapframe)); } // 1.We have to check whether the environment allocate a page with permissions PTE_W for its exception // stack and whether the exception stack overflows. // 2.Set size to 1 is enough here,because the user environment exception stack's size is only on page, // user_mem_assert function will definitely fail as long as the utf's virtual address is already lower // than UXSTACKTOP-PGSIZE.Actually,any value between 1 and sizeof(struct UTrapFrame) is okay here. // 3.if user_mem_assert fail,this function will not return,just invoke env_destroy and sys_yield. user_mem_assert(curenv, (void *)utf, 1, PTE_W); // now we can construct UTrapFrame. utf-&gt;utf_esp = tf-&gt;tf_esp; utf-&gt;utf_eflags = tf-&gt;tf_eflags; utf-&gt;utf_eip = tf-&gt;tf_eip; utf-&gt;utf_regs = tf-&gt;tf_regs; utf-&gt;utf_err = tf-&gt;tf_err; utf-&gt;utf_fault_va = fault_va; // then branch to curenv-&gt;env_pgfault_upcall. curenv-&gt;env_tf.tf_eip = (uintptr_t)curenv-&gt;env_pgfault_upcall; // Don't forget set stack pointer. curenv-&gt;env_tf.tf_esp = (uintptr_t)utf; env_run(curenv); // never return. } // Destroy the environment that caused the fault. cprintf(\"[%08x] user fault va %08x ip %08x\\n\", curenv-&gt;env_id, fault_va, tf-&gt;tf_eip); print_trapframe(tf); env_destroy(curenv);} Exercise 10#主要完成恢复现场的工作，细节部分在Exercise 9中已经讨论，这里不再赘述： 123456789101112131415161718192021222324252627282930.text.globl _pgfault_upcall_pgfault_upcall: // Call the C page fault handler. pushl %esp // function argument: pointer to UTF movl _pgfault_handler, %eax call *%eax addl $4, %esp // pop function argument // Now the C page fault handler has returned and you must return // to the trap time state. // Push trap-time %eip onto the trap-time stack. movl 0x28(%esp), %eax // UTrapFrame.utf_eip subl $4, 0x30(%esp) // UTrapFrame.utf_esp - 4 movl 0x30(%esp), %edx // Set register %edx to UTrapFrame.utf_esp - 4 movl %eax, (%edx) addl $0x8, %esp // Set %esp to the end of struct PushRegs,see more details at inc/trap.h popal // Restore the trap-time registers.(struct PushRegs) addl $0x4, %esp // now we are located at trap-time eip,so we have to increment %esp with 4. popfl // Restore eflags register. popl %esp // Just restore the adjusted trap-time stack pointer. ret // We are now on the trap-time stack,since we have saved trap-time eip above // trap-time esp,ret instruction will pop this trap-time eip to register %eip // which known as PC at this time.Thus,we can return to re-execute the instruction // that faulted. Exercise 11#实现不难，篇幅有限，具体实现见Github:YanTang Qin的Master分支 Exercise 12#实现不难，篇幅有限，具体实现见Github:YanTang Qin的Master分支 Challenge : Implement Shared-Memory sfork#【注：我在实现这个时，已经完成了LAB4，所以我是用IPC测试的】除了User Normal Stack需要被标记为Copy-On-Write之外，实现上简单来想就只需要复制Address Space，并且把Parent Environment和Child Environment都标记上PTE_W权限应该就没问题了，但是除此之外，这里有一个trick，如果仅仅只是这样的实现，make run-pingpongs会发生死锁： 可以发现thisenv没有更新，最后Environment 1000不断尝试通过IPC向Environment 1001发送数据，同时，Environment 1000也标记自己需要接受数据，这必然产生死锁！其根本原因就在于sfork是共享内存的，也就意味着在pingpongs调用sfork时把thisenv指向了Child Environment之后，不管是在parent environment还是child environment中，thisenv都是一直指向Child Environment。 解决办法也很简单，修改lib/ipc.c中int32_t ipc_recv(envid_t *from_env_store, void *pg, int *perm_store)，在其调用完sys_ipc_recv之后修改thienv的指向就可以了： 1234567891011121314151617int32_tipc_recv(envid_t *from_env_store, void *pg, int *perm_store){ int error; if(!pg)pg = (void *)UTOP; // see more details in kern/syscall.c:sys_ipc_try_send and sys_ipc_recv. if((error = sys_ipc_recv(pg)) &lt; 0){ if(from_env_store)*from_env_store = 0; if(perm_store)*perm_store = 0; return error; } thisenv = &amp;envs[ENVX(sys_getenvid())]; // (*)for lab4's challenge sfork(). if(from_env_store)*from_env_store = thisenv-&gt;env_ipc_from; if(perm_store)*perm_store = thisenv-&gt;env_ipc_perm; return thisenv-&gt;env_ipc_value;} 对于普通fork，直接用thisenv不会出错，因为普通fork实现了Copy-On-Write机制，而sfork是共享内存，因此需要加上thisenv = &amp;envs[ENVX(sys_getenvid())]才能确保IPC机制的正确性，但是不使用IPC时，parent environment调用sfork之后，thisenv指针也同样指向child environment，对此我没想到好的解决办法，因为是完全共享内存的，但是每次使用thisenv时，通过系统调用sys_getenvid来获得当前环境指针的方式是绝对不会出错的。 修改之后make run-pingpongs不再死锁，正常运行： 篇幅有限，sfork的具体实现见Github:YanTang Qin的Master分支。 Part C : Preemptive Multitasking and Inter-Process Communication(IPC)# Exercise 13#让JOS支持时钟中断，这样即便某个Environment没有自愿放弃CPU，也能够响应时钟中断从而Scheduler能够调度其它Environment运行，以防出现“饿死”的现象。 实现不难，篇幅有限，具体实现见Github:YanTang Qin的Master分支 但是千万记得要修改sched_halt()被注释掉的sti指令，这个疏漏导致我后来花了一个小时来排除bug！ Exercise 14#内核代码需要对时钟中断进行处理，调用之前实现的sched_yield即可： 1234if(tf-&gt;tf_trapno == (IRQ_OFFSET + IRQ_TIMER)){ lapic_eoi(); sched_yield();} Exercise 15#JOS实现IPC的方式是发送页面以及在struct Env中预留的一个可以存放需要传送的env_ipc_value： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657static intsys_ipc_try_send(envid_t envid, uint32_t value, void *srcva, unsigned perm){ struct Env *receiverEnv, *currentEnv; int32_t error, leastPerm = (PTE_U | PTE_P); // obtain current environment. envid2env(0, &amp;currentEnv, 0); assert(currentEnv); // Environment envid doesn't currently exist. if((error = envid2env(envid, &amp;receiverEnv, 0)) &lt; 0)return error; // Envid is not currently blocked in sys_ipc_recv or another enviironment managed to send first. if(!receiverEnv-&gt;env_ipc_recving)return -E_IPC_NOT_RECV; // Need to send page currently mapped at 'srcva'. if((uintptr_t)srcva &lt; UTOP){ struct PageInfo *pageInfo; pte_t *pte; // srcva is not page-aligned. if(((uintptr_t)srcva &amp; (PGSIZE - 1)))return -E_INVAL; // Permissions deny. if((int32_t)(leastPerm &amp; perm) != leastPerm || (perm &amp; (~PTE_SYSCALL)))return -E_INVAL; // srcva is not mapped in the caller's address space. if(!(pageInfo = page_lookup(currentEnv-&gt;env_pgdir, srcva, &amp;pte)))return -E_INVAL; // if(perm &amp; PTE_W),but srcva is read-only in the current environment's address space. if((perm &amp; PTE_W) &amp;&amp; !((*pte) &amp; PTE_W))return -E_INVAL; if((uintptr_t)receiverEnv-&gt;env_ipc_dstva &lt; UTOP){ if((error = page_insert(receiverEnv-&gt;env_pgdir, pageInfo, receiverEnv-&gt;env_ipc_dstva, perm)) &lt; 0)return error; } } // restore status. receiverEnv-&gt;env_ipc_recving = 0; receiverEnv-&gt;env_ipc_value = value; receiverEnv-&gt;env_ipc_from = currentEnv-&gt;env_id; receiverEnv-&gt;env_ipc_perm = perm; // Then we should mark the receiver environment as ENV_RUNNABLE. receiverEnv-&gt;env_status = ENV_RUNNABLE; // Return 0 from the paused sys_env_recv system call. // Howerver,the corresponding sys_ipc_recv function will never return,so we need to modify receiver's environment's trapframe. receiverEnv-&gt;env_tf.tf_regs.reg_eax = 0; // sys_ipc_try_send could return 0. return 0;}static intsys_ipc_recv(void *dstva){ if((uintptr_t)dstva &lt; UTOP &amp;&amp; (uintptr_t)dstva &amp; (PGSIZE - 1))return -E_INVAL; // Willing wo receive a page of data. struct Env *currentEnv; envid2env(0, &amp;currentEnv, 0); assert(currentEnv); currentEnv-&gt;env_status = ENV_NOT_RUNNABLE; currentEnv-&gt;env_ipc_recving = 1; currentEnv-&gt;env_ipc_dstva = dstva; sys_yield(); return 0; // eliminate compile error.} 并且需要实现lib中封装的ipc_send和ipc_recv: 12345678910111213141516171819202122232425262728293031int32_tipc_recv(envid_t *from_env_store, void *pg, int *perm_store){ int error; if(!pg)pg = (void *)UTOP; // see more details in kern/syscall.c:sys_ipc_try_send and sys_ipc_recv. if((error = sys_ipc_recv(pg)) &lt; 0){ if(from_env_store)*from_env_store = 0; if(perm_store)*perm_store = 0; return error; } thisenv = &amp;envs[ENVX(sys_getenvid())]; // for lab4's challenge sfork(). if(from_env_store)*from_env_store = thisenv-&gt;env_ipc_from; if(perm_store)*perm_store = thisenv-&gt;env_ipc_perm; return thisenv-&gt;env_ipc_value;}voidipc_send(envid_t to_env, uint32_t val, void *pg, int perm){ if(!pg)pg = (void *)UTOP; // see more details in kern/syscall.c:sys_ipc_try_send int error; // Keep trying until it succeeds. while((error = sys_ipc_try_send(to_env, val, pg, perm)) &lt; 0){ if(error != -E_IPC_NOT_RECV){ panic(\"sys_ipc_try_send:%e\", error); } sys_yield(); // To be CPU-friendly. }} TEST# 1234567891011121314151617181920212223dumbfork: OK (1.8s) Part A score: 5/5faultread: OK (1.6s) faultwrite: OK (2.1s) faultdie: OK (3.8s) faultregs: OK (2.0s) faultalloc: OK (3.1s) faultallocbad: OK (1.9s) faultnostack: OK (2.2s) faultbadhandler: OK (2.2s) faultevilhandler: OK (2.0s) forktree: OK (2.1s) Part B score: 50/50spin: OK (1.9s) stresssched: OK (2.5s) sendpage: OK (1.6s) pingpong: OK (2.0s) primes: OK (5.4s) Part C score: 25/25Score: 80/80 REFERENCES#【1】 Intel® 64 and IA-32 Architectures Software Developer’s Manual【2】 Liedtke, Jochen. Improving IPC by kernel design[J]. ACM SIGOPS Operating Systems Review, 1993, 27(5):175-188.PDF","link":"/2020/01/24/MIT-6-828-LAB4-Preemptive-Multitasking/"},{"title":"MIT-6.828-LAB5 File system,Spawn and Shell","text":"Contents# File system preliminaries Block Layout and struct File Design Philosophy of File System The File System Exercise 1 - Disk Access Question Exercise 2 - The Block Cache Challenge - Block Eviction Policy Exercise 3 - The Block Bitmap Exercise 4 - File Operations Exercise 5, 6 - The File System Interface Spawning Process Exercise 7 - Implement spawn Challenge - Implement Unix-style exec Exercise 8 - Sharing library state across fork and spawn The keyboard interface Exercise 9 - Responsing to externel interrupt Shell Exercise 10 - Implement I/O redirection REFERENCES File system preliminaries# Block Layout and struct File#JOS kernel实现的是简化版文件系统，相较于常规文件系统FILE-INODE(META DATA)-BLOCKS的模式，JOS kernel直接使用file的meta data来记录该文件所占用的Blocks信息，即FILE(META DATA)-BLOCKS的模式： struct File也存储在磁盘上，需要找到一个特定的File，就得有一个根File，它能够直接被文件系统获取而不用查找，这个根目录记录在Super Block，在具体实现中，编号为1的Block作为Super Block（Block 0存储boot loader，文件系统不使用block 0），除此之外，还需要记录每个Block的使用情况，将Block 2作为bitmap用来记录Block的占用空闲情况： JOS kernel直接将磁盘至多3GB空间直接加载到内存当中，并且将其映射到线性地址空间DISKMAP ~ DISKMAP + 3GB，换而言之，在文件系统的地址空间中，DISKMAP ~ DISKMAP + 3GB就是磁盘内容，这部分只有文件系统能够访问，不会与其它User Environment共享，并且由于文件系统地址空间中的Block与磁盘内容直接映射，因此能够直接直接通过线性地址计算出Block Number，从而找到需要加载的Sector，例如线性地址va，其对应的BLock Number为(va - DISKMAP) / PGSIZE，相应地，如果文件系统在va产生了page fault，就需要加载磁盘sector编号为BLKSECTORS * (va - DISKMAP) / PGSIZE为起始sector的共BLKSECTORS个sector即可。在JOS的文件系统中，Block size是4096 bytes，因此BLKSECTORS是4096 / 512 = 8。 Design Philosophy of File System#实际操作系统将文件系统作为内核代码实现，因此进程调用文件系统接口最终都会陷入内核态来处理，然而，在JOS中，整个文件系统本质上是一个特殊的User Environment，Normal User Environment调用的文件系统接口是通过IPC实现。换而言之，可以将JOS的文件系统看作一个Server，而Normal User Environment都是Client，Client通过IPC向Server发送请求，而Server则始终准备着接受来自Client的请求。 文件系统是JOS运行的第一个Environment，在kern/init.c:i386_init中直接创建文件系统。文件系统的main入口函数在fs/serv.c中，它完成的主要工作是： fs/serv.c:serve_init - openfile table的初始化，以及file descriptor的地址划分。 fs/fs.c:fs_init - 调用fs/bc.c:bc_init，校验Super Block和bitmap Block的合法性并记录它们的虚拟地址到全局变量super和bitmap。 fs/bc.c:bc_init - 正如Block Layout and struct File中所讨论的一样，当我们知晓了需要加载的Block的虚拟地址va之后，就能够得到它对应的Block Number为(va - DISKMAP) / PGSIZE，相应地，该虚拟地址对应地page就需要从disk中加载serctor编号为BLKSECTORS * (va - DISKMAP) / PGSIZE到BLKSECTORS * (va - DISKMAP) / PGSIZE + BLKSECTORS的sector到内存。因此我们需要设置page fault handler，就像我们在实现fork中做的一样。除此之外，bc.c还需要完成Super Block和bitmap Block的初始化。 fs/serv.c:serve - 接受Regular User Environment发送的请求，并且调用相应的handler来处理请求，再返回响应。但是文件系统同一时间只能够处理一个请求，效率不高。可以考虑多几个File system environment，但是这样需要对一些资源加锁，例如File descriptor，openfile table等，从而避免并发错误。 在提供给用户使用的接口方面，统一接口在lib/fd.c中，同时JOS将一些子系统抽象成Device，例如File Device，Pipe Device以及后面需要实现的Network Driver，Dev结构体包括了Dev id以及相应的处理函数指针: 123456789struct Dev { int dev_id; const char *dev_name; ssize_t (*dev_read)(struct Fd *fd, void *buf, size_t len); ssize_t (*dev_write)(struct Fd *fd, const void *buf, size_t len); int (*dev_close)(struct Fd *fd); int (*dev_stat)(struct Fd *fd, struct Stat *stat); int (*dev_trunc)(struct Fd *fd, off_t length);}; 通过Devices的抽象以及File Descriptor，统一了用户接口（在lib/fd.c中），并且提供了高度的可定制性和可插拔性。我绘制了一个示意图，Client与Server端都划分了三层： 注解： USER API - lib/fd.c DEVICE - For instance - devfile:lib/file.c; devpipe:lib/pipe.c; devcons:lib/console.c IPC - lib/ipc.c SERVER - fs/serv.c FILE SYSTEM - fs/fs.c 以devfile的read操作为例，其Control flow如下所示： 12345678910111213141516171819 Regular env FS env +---------------+ +---------------+ | read | | file_read | | (lib/fd.c) | | (fs/fs.c) |...|.......|.......|...|.......^.......|............... | v | | | | RPC mechanism | devfile_read | | serve_read | | (lib/file.c) | | (fs/serv.c) | | | | | ^ | | v | | | | | fsipc | | serve | | (lib/file.c) | | (fs/serv.c) | | | | | ^ | | v | | | | | ipc_send | | ipc_recv | | | | | ^ | +-------|-------+ +-------|-------+ | | +-------------------+ 任何操作都是通过File Descriptor作为媒介来实现的，并且File Descriptor是File System Environment与Regular User Environment共享的： 123456789struct Fd { int fd_dev_id; off_t fd_offset; int fd_omode; union { // File server files struct FdFile fd_file; };}; 通过Fd的dev_id能够找到相应的Devices，并且调用其处理函数，而fd_file则是OpenFile的索引，控制最终转移到File system时，能够通过fd_file拿到OpenFile，而OpenFile结构体中保留了File指针，在File System Environment的地址空间中，能通过该File指针获取到相应的struct File的引用： 123456struct OpenFile { uint32_t o_fileid; // file id struct File *o_file; // mapped descriptor for open file int o_mode; // open mode struct Fd *o_fd; // Fd page}; 文件系统环境和Regular User Environment之间的结构如下所示： The File System# Exercise 1 - Disk Access#正如上面所讨论的，文件系统是JOS创建的第一个environment，为了将其与Regular user environment区别，需要将其类型设置为ENV_TYPE_FS： 1ENV_CREATE(fs_fs, ENV_TYPE_FS); 并且需要为其赋予I/O权限: 123456789101112131415voidenv_create(uint8_t *binary, enum EnvType type){ struct Env *env; int32_t flag; if((flag = env_alloc(&amp;env, (envid_t)0)) &lt; 0){ panic(\"env_create:%e\", flag); } env-&gt;env_type = type; // If this is the file server (type == ENV_TYPE_FS) give it I/O privileges. if(type == ENV_TYPE_FS){ env-&gt;env_tf.tf_eflags |= FL_IOPL_3; } load_icode(env, binary); // restore this binary image to corresponding memory.} Question# 1.Do you have to do anything else to ensure that this I/O privilege setting is saved and restored properly when you subsequently switch from one environment to another? Why? 当然不用，eflags寄存器也会在发生switch的时候自动保存到env-&gt;env_tf中。即trap时会自动保存这些寄存器的值。 Exercise 2 - The Block Cache#设置page fault handler以便能够从disk加载fault va对应的Block到内存： 1234567891011121314151617181920212223242526272829303132333435static voidbc_pgfault(struct UTrapframe *utf){ void *addr = (void *) utf-&gt;utf_fault_va; uint32_t blockno = ((uint32_t)addr - DISKMAP) / BLKSIZE; int r; // Check that the fault was within the block cache region if (addr &lt; (void*)DISKMAP || addr &gt;= (void*)(DISKMAP + DISKSIZE)) panic(\"page fault in FS: eip %08x, va %08x, err %04x\", utf-&gt;utf_eip, addr, utf-&gt;utf_err); // Sanity check the block number. if (super &amp;&amp; blockno &gt;= super-&gt;s_nblocks) panic(\"reading non-existent block %08x\\n\", blockno); // Allocate a page in the disk map region, read the contents // of the block from the disk into that page. addr = (void *)ROUNDDOWN((uintptr_t)addr, PGSIZE); if((r = sys_page_alloc(0, addr, (PTE_U | PTE_P | PTE_W))) &lt; 0){ panic(\"sys_page_alloc:%e\", r); } if((r = ide_read(blockno * BLKSECTS, addr, BLKSECTS)) &lt; 0){ panic(\"ide_read:%e\", r); } // Clear the dirty bit for the disk block page since we just read the // block from disk if ((r = sys_page_map(0, addr, 0, addr, uvpt[PGNUM(addr)] &amp; PTE_SYSCALL)) &lt; 0) panic(\"in bc_pgfault, sys_page_map: %e\", r); // Check that the block we read was allocated. if (bitmap &amp;&amp; block_is_free(blockno)) panic(\"reading free block %08x\\n\", blockno);} 实现flush_block以便能够将内存中的Block同步回DISK，达到数据持久化的效果： 123456789101112131415161718192021222324voidflush_block(void *addr){ uint32_t blockno = ((uint32_t)addr - DISKMAP) / BLKSIZE; int r; if (addr &lt; (void*)DISKMAP || addr &gt;= (void*)(DISKMAP + DISKSIZE)) panic(\"flush_block of bad va %08x\", addr); // LAB 5: Your code here. addr = (void *)ROUNDDOWN((uintptr_t)addr, PGSIZE); // If the block isn't in the block cache,just not do anything. if(!va_is_mapped(addr) || !va_is_dirty(addr))return; // bit dirty was set,we should write it back to dist. if((r = ide_write(blockno * BLKSECTS, addr, BLKSECTS)) &lt; 0){ panic(\"ide_write:%e\", r); } // After we write back this dirty block to disk,we should clear the PTE_D bit. if((r = sys_page_map(0, addr, 0, addr, uvpt[PGNUM(addr)] &amp; PTE_SYSCALL)) &lt; 0){ panic(\"int flush_block, sys_page_map:%e\", r); }} Challenge - Block Eviction Policy#实现起来倒不难，但是我着实没明白PTE_A和dirty Block不是相互矛盾的吗，如果是dirty block，它的PTE_A也必然被设置了呀。其实JOS压根就不需要Eviction Policy，因为JOS的文件系统与DISK是一对一的，不存在Block满了之后，还能加载新的Block的情况，但是也可以说是为了不让文件系统占用过多的物理内存。我实现的仅仅是释放掉没有被访问过的Block的超简单策略： 12345678910111213141516171819202122232425262728293031323334353637383940// lab 5's challenge : implement eviction policy for block cache.voidevict_block_force(void *addr){ uint32_t blockno = ((uint32_t)addr - DISKMAP) / BLKSIZE; int r; if(addr &lt; (void *)DISKMAP || addr &gt;= (void *)(DISKMAP + DISKSIZE)){ panic(\"evict_block_force of bad va %08x\", addr); } // ignore boot sector,super block and bitmap block. // if the block isn't in the block cache,just not do anything. if(blockno &lt;= 2 || !va_is_mapped(addr))return; // flush this block if PTE_D flag was set before you evict this block to disk from memory. if(uvpt[PGNUM(addr)] &amp; PTE_D){ flush_block(addr); } // enture that addr was page-aligned,otherwise sys_page_unmap will return error -E_INVAL. addr = (void *)ROUNDDOWN(addr, PGSIZE); // evict this block to disk. if((r = sys_page_unmap(0, addr)) &lt; 0){ panic(\"evict_block_force:sys_page_unmap:%e\", r); }}// if only_not_accessed was true, this function will only evict those block// loaded into memory but has never been accessed.In contrast, it will evict// all block except for block number with 0,1,2.voidblock_evict_policy(bool only_not_accessed){ uint32_t blockno, nblocks = DISKSIZE / BLKSIZE; for(blockno = 3; blockno &lt; nblocks; ++blockno){ if((!only_not_accessed) || (!(uvpt[PGNUM(diskaddr(blockno))] &amp; PTE_A))){ evict_block_force(diskaddr(blockno)); if(!only_not_accessed)cprintf(\"[ALL BLOCKS EVICTION POLICY]block with blockno %d was evicted forcelly.\\n\"); else cprintf(\"[ONLY NOT ACCESSED EVICTION POLICY]block with block no %d was evicted.\\n\"); } }} Exercise 3 - The Block Bitmap#分配Block并且设置bitmap以追踪block使用情况： 12345678910111213141516intalloc_block(void){ // The bitmap consists of one or more blocks. A single bitmap block // contains the in-use bits for BLKBITSIZE blocks. There are // super-&gt;s_nblocks blocks in the disk altogether. uint32_t i; for(i = 0; i &lt; super-&gt;s_nblocks; ++i){ if(block_is_free(i)){ bitmap[i / 32] &amp;= ~(1 &lt;&lt; (i % 32)); // mark this bit as zero which means in use. return i; } } return -E_NO_DISK;} Exercise 4 - File Operations#file_block_walk有一个小trick，在注释中已说明： 12345678910111213141516171819202122232425static intfile_block_walk(struct File *f, uint32_t filebno, uint32_t **ppdiskbno, bool alloc){ uint32_t blockno; if(filebno &gt;= NDIRECT + NINDIRECT)return -E_INVAL; if(filebno &lt; NDIRECT){ *ppdiskbno = f-&gt;f_direct + filebno; return 0; } if(!(f-&gt;f_indirect)){ // get here means that we need to allocate an indirect block, // but alloc was 0. if(!alloc)return -E_NOT_FOUND; // Now we could allocate an indirect block by using alloc_block. if((blockno = alloc_block()) &lt; 0)return -E_NO_DISK; f-&gt;f_indirect = blockno; // claer the block we allocated above. memset(diskaddr(f-&gt;f_indirect), 0, BLKSIZE); flush_block(diskaddr(f-&gt;f_indirect)); } // There is a trick:f-&gt;f_indirect is an block number while f-&gt;direct is an virtual address. // That's why we need to convert f-&gt;f_indirect to virtual address firstly. *ppdiskbno = ((uint32_t *)diskaddr(f-&gt;f_indirect)) + (filebno - NDIRECT); return 0;} 以及通过索引返回该索引对应的block虚拟地址，注意这个索引是相对于这个特定的File而言的： 12345678910111213141516intfile_get_block(struct File *f, uint32_t filebno, char **blk){ int r; uint32_t *ppdiskno; // value of r might be 0, -E_INVAL, -E_NO_DISK. if((r = file_block_walk(f, filebno, &amp;ppdiskno, 1)) &lt; 0)return r; // *ppdiskno is zero means that we should allocate a blobk. if(!(*ppdiskno)){ if((r = alloc_block()) &lt; 0)return -E_NO_DISK; *ppdiskno = r; } *blk = (char *)diskaddr(*ppdiskno); return 0;} Exercise 5, 6 - The File System Interface#Exercise 5,6实际上就是实现图1-3所示的SERVER层的handler function，它需要调用File System提供的接口才能完成功能： 12345678910111213141516171819202122232425262728293031intserve_read(envid_t envid, union Fsipc *ipc){ struct Fsreq_read *req = &amp;ipc-&gt;read; struct Fsret_read *ret = &amp;ipc-&gt;readRet; if (debug) cprintf(\"serve_read %08x %08x %08x\\n\", envid, req-&gt;req_fileid, req-&gt;req_n); struct OpenFile *openFile; int r; if((r = openfile_lookup(envid, req-&gt;req_fileid, &amp;openFile)) &lt; 0)return r; if((r = file_read(openFile-&gt;o_file, ret-&gt;ret_buf, req-&gt;req_n, openFile-&gt;o_fd-&gt;fd_offset)) &lt; 0)return r; openFile-&gt;o_fd-&gt;fd_offset += r; return r;}intserve_write(envid_t envid, struct Fsreq_write *req){ if (debug) cprintf(\"serve_write %08x %08x %08x\\n\", envid, req-&gt;req_fileid, req-&gt;req_n); struct OpenFile *openFile; int r, t = 0; if((r = openfile_lookup(envid, req-&gt;req_fileid, &amp;openFile)) &lt; 0)return r; t = req-&gt;req_n &gt; PGSIZE?PGSIZE:req-&gt;req_n; if((r = file_write(openFile-&gt;o_file, req-&gt;req_buf, t, openFile-&gt;o_fd-&gt;fd_offset)) &lt; 0)return r; openFile-&gt;o_fd-&gt;fd_offset += r; return r;} Spawning Process# Exercise 7 - Implement spawn#spawn由parent environment为child environment进行初始化，因此不会有任何问题，但是要在用户态下实现Unix-style exec是很有难度的。 12345678910111213141516171819static intsys_env_set_trapframe(envid_t envid, struct Trapframe *tf){ // Remember to check whether the user has supplied us with a good // address! struct Env *theEnv; if(envid2env(envid, &amp;theEnv, 1) &lt; 0)return -E_BAD_ENV; // cprintf(\"this tf va@0x%p\\n\", tf); user_mem_assert(theEnv, tf, sizeof(struct Trapframe), PTE_U); // Clear IOPL bits. tf-&gt;tf_eflags &amp;= ~FL_IOPL_MASK; // Interrupts enabled. tf-&gt;tf_eflags |= FL_IF; // code protection level 3(CPL 3). tf-&gt;tf_cs |= GD_UT | 3; // set envid's trap frame to tf. theEnv-&gt;env_tf = *tf; return 0;} 其实这里我卡了很久，就是faultio测试用例无法通过，我确实花了非常多的时间来定位bug，解决bug，最后发现是问题在于CPU的Task State Segment设置有一点问题，我没有设置TSS的IO permission bit map的偏移量，从而产生问题。 I/O map base address field-contains a 16-bit offset from the base of the TSS to the I/O permission bit map and interrupt redirection bitmap.When present,these maps are stored in the TSS at the higher addresses.The I/O map base address points to the beginning of the I/O permission bit map and the end of the interrupt redirection bit map.See Chapter 13,”Input/Output,”in the Intel 64 and IA-32 Architectures Software Developer’s Manual,Volume 1,for more information about the I/O permission bit map.See Section 15.3,”Interrupt and Exception Handling in Virtual-8086 Mode,”for a detailed description of the interrupt redirection bit map. 换而言之，这个bug就是I/O Map Base设置为0所导致的，因此，解决这个bug只需要将I/O Base设置为sizof(struct Taskstate)即可： 修复I/O permission的bug，在trap_init_percpu(kern/trap.c)中设置: 1thiscpu-&gt;cpu_ts.ts_iomb = sizeof(struct Taskstate); Challenge - Implement Unix-style exec#在用户环境中实现exec的难点在哪里？我们需要做些什么？ 难点就是我们不能够直接将需要加载的代码和数据映射到当前Environment正在使用的虚拟页面上，如果这么做了，后续exec的代码就无法执行了，因为映射关系改变了，处理器执行指令进行地址转换的时候，会定位到未知的地方。因此我们需要找到一个暂存空间，将exec需要加载的代码和数据加载到这个暂存空间，然后通过系统调用陷入内核态，让内核代码为该执行exec的Environment完成最终代码和数据的装载（或者说新的内存映射）。总而言之，两个关键点，一是预留一个暂存空间用来临时存储exec需要装载的数据和代码，二是最终需要实现一个系统调用完成最终代码和数据的装载或者说新的内存映射（可以考虑在系统调用中用memmove直接将暂存空间的内容复制到调用exec的Environment的相应的地方） 上面是我的初始想法，实现了一版之后，出现了许多很难解决的问题，于是我参考了xv6的内核态下实现exec的流程，最终成功完成了这个challenge。原理简单来说就是创建临时的page directory，随后将exec指定的内容加载到内存并且映射到这个临时的page directory，完成装载之后再替换page directory并且释放旧的page directory，page table以及相应的page。 实现主要通过三个核心的系统调用： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127// allocate a new page as this environmnt's page directory and map// it to va temporarily.static intsys_exec_alloc_pgdir(void *va){ struct Env *currentEnv; struct PageInfo *pageInfo = NULL; pde_t *new_pgdir; envid2env(0, &amp;currentEnv, 1); assert(currentEnv); // step 1) we should check that whether the page correspondingly to pgdir_temp // is present or not.At the same time,we have to ensure that the virtual // address va is page-aligned. if(((uintptr_t)va &amp; (PGSIZE - 1)) || page_lookup(currentEnv-&gt;env_pgdir, va, NULL)){ cprintf(\"[DEBUG]sys_exec_alloc_pgdir:va is now mapped or va was not page aligned.\\n\"); return -E_INVAL; } // step 2) allocate a new page as this environment's page directory. if(!(pageInfo = page_alloc(ALLOC_ZERO))){ return -E_NO_MEM; } // step 3) map the new page to va temporarily. if(page_insert(currentEnv-&gt;env_pgdir, pageInfo, va, (PTE_W | PTE_P | PTE_U)) &lt; 0){ return -E_NO_MEM; } // step 4) copy this environment's old pgdir here just like what we have done before. // Don't forget to increment its ref counter. // Most importantly,it's necessary switch page directory for that we are now // in kernel mode. //cprintf(\"[INFO]Before cr3 is %p.\\n\", rcr3()); lcr3(PADDR(currentEnv-&gt;env_pgdir)); //cprintf(\"[INFO]After cr3 is %p.\\n\", rcr3()); memcpy(va, kern_pgdir, PGSIZE); ++pageInfo-&gt;pp_ref; //lcr3(PADDR(kern_pgdir)); //cprintf(\"[INFO]Finally cr3 is %p.\\n\", rcr3()); return 0;}// lab 5's challenge - implement Unix-Like exec.static intsys_exec_map(pde_t *pg_dir, void *srcva, void *dstva, int perm){ struct PageInfo *pageInfo = NULL; struct Env *currentEnv; int32_t leastPerm = (PTE_U | PTE_P); envid2env(0, &amp;currentEnv, 1); assert(currentEnv); // step 0) if((uintptr_t)srcva &gt;= UTOP || (uintptr_t)dstva &gt;= UTOP || ((uintptr_t)srcva &amp; (PGSIZE - 1)) || ((uintptr_t)dstva &amp; (PGSIZE - 1))){ cprintf(\"[DEBUG]sys_exec_map:step 0 failed.\\n\"); return -E_INVAL; } // step 1) check pg_dir present. if(!page_lookup(currentEnv-&gt;env_pgdir, pg_dir, NULL)){ cprintf(\"[DEBUG]sys_exec_map:pg_dir not present.\\n\"); return -E_INVAL; } // step 2) check source page present. if(!( pageInfo = page_lookup(currentEnv-&gt;env_pgdir, srcva, NULL))){ cprintf(\"[DEBUG]sys_exec_map:step 2 failed.\\n\"); return -E_INVAL; } // step 3) if((perm &amp; leastPerm) != leastPerm || (perm &amp; (~PTE_SYSCALL))){ cprintf(\"[DEBUG]sys_exec_map:step 3 failed,permisson denied.\\n\"); return -E_INVAL; } // step 4) map pageInfo to dstva. // cprintf(\"[DEBUG]pg_dir is %p and dstva is %p\\n\", pg_dir, dstva); return page_insert(pg_dir, pageInfo, dstva, perm);}// lab 5's challenge - implement Unix-Like exec.static intsys_exec_replace_pgdir(pde_t *pg_dir, uintptr_t esp, uintptr_t e_entry){ struct PageInfo *pageInfo = NULL; struct Env *currentEnv = NULL; pde_t *old_pgdir; pte_t *pt; uint32_t pdeno, pteno; physaddr_t pa; envid2env(0, &amp;currentEnv, 1); assert(currentEnv); if(!(pageInfo = page_lookup(currentEnv-&gt;env_pgdir, (void *)pg_dir, NULL))){ cprintf(\"[DEBUG]sys_exec_replace_pgdir:page_lookup:pageInfo is null.\\n\"); return -E_INVAL; } // save the old page directory. old_pgdir = currentEnv-&gt;env_pgdir; currentEnv-&gt;env_pgdir = (pde_t *)page2kva(pageInfo); // UVPT maps the env's own page table read-only. currentEnv-&gt;env_pgdir[PDX(UVPT)] = PADDR(currentEnv-&gt;env_pgdir) | PTE_P | PTE_U; // we have replaced page directory.However,we didn't free old page directory and page table, // that's what we are going to do next. for(pdeno = 0; pdeno &lt; PDX(UTOP); ++pdeno){ if(!(old_pgdir[pdeno] &amp; PTE_P)) continue; // find the pa and va of the page table. pa = PTE_ADDR(old_pgdir[pdeno]); pt = (pte_t *)KADDR(pa); // unmap all PTEs in this page table. for(pteno = 0; pteno &lt;= PTX(~0); ++pteno){ if(pt[pteno] &amp; PTE_P) page_remove(old_pgdir, PGADDR(pdeno, pteno, 0)); } // free the page table itself. old_pgdir[pdeno] = 0; page_decref(pa2page(pa)); } // free the page directory. pa = PADDR(old_pgdir); old_pgdir = 0; page_decref(pa2page(pa)); // modify some status of this environment. currentEnv-&gt;env_tf.tf_esp = esp; currentEnv-&gt;env_tf.tf_eip = e_entry; env_run(currentEnv); return 0; // never get here,just eliminate compiling error.} 除此之外，还需要修改一些地方，篇幅原因，完整实现可参考Github:YanTang Qin的lab5dev分支： git checkout lab5dev切换到lab5dev分支 git diff lab5 这样就能够快速找到我为实现exec所做的修改了。 下图是实现的效果。可以看到我的测试程序使用了fork+execl的模式，子进程会加载testshell这个程序执行，可以看到完全符合预期！ 以下是测试程序： 123456789101112131415161718192021222324voidumain(int argc, char **argv){ int r; cprintf(\"hello, world!\\n\"); cprintf(\"[BEFORE]parent environment %08x\\n\", thisenv-&gt;env_id); if((r = fork()) &lt; 0){ cprintf(\"[DEBUG]fork failed for %e.\\n\", r); return; } // printe by parent and child environment. cprintf(\"[COMMON]environment %08x\\n\", thisenv-&gt;env_id); if(r &gt; 0){ // parent environment. cprintf(\"[PARENT]hello\\n\"); }else if(r == 0){ // child environment. cprintf(\"[CHILD]world!\\n\"); if((r = execl(\"testshell\", \"testshell\", 0)) &lt; 0){ panic(\"[DEBUG]panic for %e\", r); } } cprintf(\"[PARENT]Oh!\\n\");} 有效输出结果（剔除了调试信息）： 123456789hello, world![BEFORE]parent environment 00001001[COMMON]environment 00001001[COMMON]environment 00001002[PARENT]hello[PARENT]Oh![CHILD]world!running sh -x &lt; testshell.sh | catshell ran correctly 可以看到，抛开并发运行带来的不确定性，输出结果完全符合预期。 Exercise 8 - Sharing library state across fork and spawn#123456789101112131415161718192021222324static intduppage(envid_t envid, unsigned pn){ int r; uintptr_t pn_va = pn * PGSIZE; if(uvpt[pn] &amp; PTE_SHARE){ if((r = sys_page_map(0, (void *)pn_va, envid, (void *)pn_va, uvpt[pn] &amp; PTE_SYSCALL)) &lt; 0){ panic(\"sys_page_map:%e\", r); } }else if((uvpt[pn] &amp; PTE_W) || (uvpt[pn] &amp; PTE_COW)){ if((r = sys_page_map(0, (void *)pn_va, envid, (void *)pn_va, (PTE_COW | PTE_P | PTE_U))) &lt; 0){ panic(\"sys_page_map:%e\", r); } if((r = sys_page_map(0, (void *)pn_va, 0, (void *)pn_va, (PTE_COW | PTE_P | PTE_U))) &lt; 0){ panic(\"sys_page_map:%e\", r); } }else{ if((r = sys_page_map(0, (void *)pn_va, envid, (void *)pn_va, PTE_P | PTE_U)) &lt; 0){ panic(\"sys_page_map:%e\", r); } } return 0;} 以及： 12345678910111213141516static intcopy_shared_pages(envid_t child){ uintptr_t pageVa; unsigned pn; int r; for(pageVa = UTEXT; pageVa &lt; UTOP; pageVa += PGSIZE){ pn = PGNUM(pageVa); if((uvpd[PDX(pageVa)] &amp; PTE_P) &amp;&amp; (uvpt[pn] &amp; PTE_P) &amp;&amp; (uvpt[pn] &amp; PTE_SHARE)){ if((r = sys_page_map(0, (void *)pageVa, child, (void *)pageVa, uvpt[pn] &amp; PTE_SYSCALL)) &lt; 0){ panic(\"copy_shared_pages:sys_page_map:%e\", r); } } } return 0;} The keyboard interface# Exercise 9 - Responsing to externel interrupt#在trap_dispatch中添加上trap number对应的相应即可： 123456789if(tf-&gt;tf_trapno == (IRQ_OFFSET + IRQ_KBD)){ kbd_intr(); return;}if(tf-&gt;tf_trapno == (IRQ_OFFSET + IRQ_SERIAL)){ serial_intr(); return;} Shell# Exercise 10 - Implement I/O redirection#理解了文件系统的结构和接口之后不难： 12345678910111213141516171819202122case '&lt;': // Input redirection // Grab the filename from the argument list if (gettoken(0, &amp;t) != 'w') { cprintf(\"syntax error: &lt; not followed by word\\n\"); exit(); } // Open 't' for reading as file descriptor 0 // (which environments use as standard input). // We can't open a file onto a particular descriptor, // so open the file as 'fd', // then check whether 'fd' is 0. // If not, dup 'fd' onto file descriptor 0, // then close the original 'fd'. if((fd = open(t, O_RDONLY)) &lt; 0){ fprintf(2, \"fail to open %s for reason %e\\n\", t, fd); exit(); } if(fd != 0){ dup(fd, 0); close(fd); } break; REFERENCES#【1】 Intel® 64 and IA-32 Architectures Software Developer’s Manual【2】 xv6 - a simple, Unix-like teaching operating system【3】 xv6 source book - xv6 is a re−implementation of Dennis Ritchie’s and Ken Thompson’s Unix Version 6 (v6).","link":"/2020/01/31/MIT-6-828-LAB5-File-system-Spawn-and-Shell/"}],"tags":[{"name":"No-tags","slug":"No-tags","link":"/tags/No-tags/"},{"name":"数据库","slug":"数据库","link":"/tags/数据库/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"设计模式","slug":"设计模式","link":"/tags/设计模式/"},{"name":"csapp","slug":"csapp","link":"/tags/csapp/"},{"name":"MIT6.828","slug":"MIT6-828","link":"/tags/MIT6-828/"},{"name":"操作系统","slug":"操作系统","link":"/tags/操作系统/"},{"name":"进程","slug":"进程","link":"/tags/进程/"},{"name":"线程","slug":"线程","link":"/tags/线程/"},{"name":"互斥","slug":"互斥","link":"/tags/互斥/"},{"name":"临界区","slug":"临界区","link":"/tags/临界区/"},{"name":"Mybatis","slug":"Mybatis","link":"/tags/Mybatis/"},{"name":"线程池","slug":"线程池","link":"/tags/线程池/"},{"name":"并发控制","slug":"并发控制","link":"/tags/并发控制/"},{"name":"Algorithms","slug":"Algorithms","link":"/tags/Algorithms/"}],"categories":[{"name":"Unclassified","slug":"Unclassified","link":"/categories/Unclassified/"},{"name":"数据库","slug":"数据库","link":"/categories/数据库/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"操作系统","slug":"操作系统","link":"/categories/操作系统/"},{"name":"MySQL","slug":"数据库/MySQL","link":"/categories/数据库/MySQL/"},{"name":"Java编程语言","slug":"Java/Java编程语言","link":"/categories/Java/Java编程语言/"},{"name":"csapp","slug":"操作系统/csapp","link":"/categories/操作系统/csapp/"},{"name":"MIT-6.828-OSE","slug":"操作系统/MIT-6-828-OSE","link":"/categories/操作系统/MIT-6-828-OSE/"},{"name":"设计模式","slug":"设计模式","link":"/categories/设计模式/"},{"name":"Framework","slug":"Framework","link":"/categories/Framework/"},{"name":"并发控制","slug":"Java/并发控制","link":"/categories/Java/并发控制/"},{"name":"Mybatis","slug":"Framework/Mybatis","link":"/categories/Framework/Mybatis/"},{"name":"algorithms","slug":"Java/algorithms","link":"/categories/Java/algorithms/"}]}